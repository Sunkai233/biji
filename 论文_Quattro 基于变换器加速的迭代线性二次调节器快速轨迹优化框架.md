# Quattro: 基于变换器加速的迭代线性二次调节器快速轨迹优化框架

**Yue Wang¹**，**Haoyu Wang¹,²** 和 **Zhaoxing Li¹**

**摘要** — 实时最优控制仍然是机器人技术中的一个基本挑战，特别是对于具有严格性能要求的非线性系统。作为代表性轨迹优化算法之一，迭代线性二次调节器(iLQR)由于其固有的串行计算特性而面临限制，这限制了机器人系统实时控制的效率和适用性。虽然现有的并行实现旨在克服上述限制，但它们通常需要额外的计算迭代和高性能硬件，导致只有适度的实际改进。在本文中，我们介绍了Quattro，这是一个基于变换器加速的iLQR框架，采用算法-硬件协同设计策略来预测中间反馈和前馈矩阵。它便于在资源受限的设备上进行有效的并行计算，而不牺牲准确性。在车杆和四旋翼系统上的实验表明，每次迭代的算法级加速分别可达5.3×和27×。当集成到模型预测控制(MPC)框架中时，与应用传统iLQR相比，Quattro实现了车杆2.8×和四旋翼17.8×的整体加速。变换器推理部署在FPGA上以最大化性能，与主流嵌入式CPU相比实现了高达20.8×的加速，与GPU相比功耗降低超过11×，硬件资源开销低。

（

#### 背景问题

在机器人领域，**实时控制**很难，特别是面对非线性系统（比如无人机、机械臂、车杆系统），既要高性能，又要快速反应。

- 经典方法之一是 **iLQR（迭代线性二次调节器）**，它能做轨迹优化，算出比较好的控制策略。
- 但问题是：iLQR **计算是串行的**，一步一步来，速度不够快。
- 有些人尝试并行化，但需要很多额外迭代和高性能硬件，实际提升有限。

------

#### 研究创新：Quattro

作者提出了一个新的框架 **Quattro**：

- 它用 **Transformer（变换器模型）来预测 iLQR 的中间结果**（反馈矩阵和前馈矩阵），这样不用一步步串行算，能并行化处理。
- 设计思路是 **算法+硬件协同**：既优化算法结构，又考虑硬件部署，适合资源有限的设备。

------

#### 实验结果

- 在 **车杆系统** 和 **四旋翼系统** 上实验：
  - 每次迭代的速度提升分别达到 **5.3 倍** 和 **27 倍**。
- 集成到 **MPC（模型预测控制）** 框架后：
  - 相比传统 iLQR，整体加速 **车杆 2.8 倍**，**四旋翼 17.8 倍**。
- 硬件实现：
  - 把 Transformer 部署到 **FPGA** 上：
    - 相比嵌入式 CPU，速度提升 **20.8 倍**。
    - 相比 GPU，功耗降低 **11 倍以上**。
    - 占用硬件资源很小。

------

#### 📌 一句话总结

**Quattro 用 Transformer 预测 iLQR 的中间计算，让原本串行的轨迹优化并行化。结果是在小型硬件上就能跑得比 CPU/GPU 更快、更省电，真正让实时最优控制更可行。**

）

## I. 引言

模型预测控制(MPC)在机器人技术中广泛用于轨迹优化，计算未来时间步的最优控制输入[1]，[2]，[3]，[4]。然而，非线性设置中的实时性能通常需要大量计算资源[5]。微分动态规划(DDP)在[6]，[7]中被重新发明，连同其迭代线性二次调节器(iLQR)变体，现在广泛用于机器人控制[8]，[9]，[10]，[11]。尽管具有优势，iLQR仍然依赖严重依赖处理器时钟频率的串行流水线[12]。与此同时，深度学习(DL)提供了大规模并行性[13]和高性能推理[14]，这使其非常适合解决iLQR的瓶颈。然而，很少有工作将DL与iLQR结合。这一差距突出了更快、更高效最优控制的令人兴奋的路径。

虽然iLQR应用高斯-牛顿近似来线性化系统动力学，使其成为DDP更高效但不够准确的变体，但它仍然本质上是串行的，无法利用多核计算。多重射击方法将问题分割成段[15]，[16]，使用多核CPU或GPU[17]，[18]，但引入额外项来处理段间缺陷[19]。这通常需要更多迭代才能收敛，降低了整体效率[12]。深度学习(DL)方法已经出现作为解决这些挑战的方法。例如，[20]使用神经网络来近似iLQR输出并加速计算，但网络没有捕获关键的序列依赖性并产生不太可靠的结果。变换器也出现在轨迹优化中，特别是在MPC中。Celestini等人应用基于变换器的模型生成接近最优的初始猜测，改善收敛性并降低计算成本[21]。Zinage等人提出TransformerMPC，预测非活跃约束并改进初始化[22]。虽然这些工作在MPC中显示出希望，变换器架构在iLQR中仍然探索不足。这一差距为更好地建模序列依赖性和加速基于iLQR的控制提供了机会。

深度学习在过去二十年中快速发展，为序列数据产生了强大的架构。循环神经网络(RNNs)[23]和长短期记忆(LSTM)网络[24]在许多时序任务中被证明有效，但在建模长程依赖性时经常遇到梯度消失或爆炸问题[25]。变换器[26]，[27]，[28]通过使用自注意力避免这些问题，在不需要RNN或LSTM的严格序列更新的情况下捕获扩展上下文[29]。这种设计与iLQR的迭代结构很好地吻合。变换器在高时序任务中潜力的一个主要例子是Nvidia的深度学习超级采样(DLSS)，其中基于变换器的方法以更高的帧率重建高保真游戏帧[30]。这一成功直接激发了我们对变换器驱动iLQR解决方案的追求。此外，深度学习加速器的最新进展使变换器架构的高效并行化成为可能[31]，[32]，[33]，为实时、高性能控制应用铺平了道路。

为了解决iLQR计算的串行性并克服现有并行化方法的低效率，我们介绍Quattro**(图1)，这是一个使用变换器模型生成反馈和前馈项的iLQR框架。通过并行产生这些中间值，Quattro减少计算时间同时保持准确性。我们在车杆[34]和四旋翼[35]控制问题上验证了这种方法，证明了框架的有效性。此外，基于FPGA的实现揭示了实质性的性能增益，强调了Quattro在实时应用中的潜力。

本文的贡献如下：
1) 我们介绍Quattro，这是一个用于iLQR的深度加速框架，通过定制的变换器模型本质上加速。它通过并行计算和即时推理补偿显著增强计算效率。
2) 我们在各种计算平台上验证Quattro在车杆和四旋翼系统上的性能，实现显著的加速和与传统iLQR相当的准确性。
3) 我们使用最新的加速器设计框架[36]在FPGA上实现定制的变换器内核，在性能、功耗和硬件开销之间实现最优平衡。据我们所知，这是首次专门为iLQR优化在FPGA上部署变换器模型。

本文其余部分组织如下：我们首先在第II节介绍问题背景，然后在第III节介绍提出框架的详细信息。实验和结果在第IV节中呈现，论文在第V节结束。

**我们的框架是开源的，可在以下网址获得：https://github.com/YueWang996/quattro-transformer-ilqr

（

#### 背景

在机器人控制里，常用的方法之一是 **MPC（模型预测控制）**：它会不断预测未来一段时间的轨迹，然后选择最优的控制动作。

- 其中很经典的算法是 **iLQR（迭代线性二次调节器）**，它能在非线性系统里做轨迹优化。
- 问题是：iLQR 的计算是 **串行的**，一步一步执行，不能很好利用多核 CPU 或 GPU。这样一来，它在实时性要求高的场景（比如无人机高速飞行）就会显得慢。

过去有一些并行化尝试（比如把问题拆成多个段同时计算），但这些方法通常需要更多的迭代才能收敛，整体效率反而下降。

------

#### 为什么用深度学习？

- **深度学习** 本身非常适合并行运算，GPU/TPU 加速也很成熟。
- 有些研究已经尝试用神经网络近似 iLQR 的结果，但很多没有抓住时序上的依赖关系，结果不够稳定。
- **变换器（Transformer）** 特别擅长建模长序列依赖（比 RNN/LSTM 更强），而 iLQR 恰好是一个迭代的序列计算过程。
- Nvidia 的 **DLSS** 技术就是一个典型例子：用 Transformer 在显卡上并行计算高质量画面，启发了作者用类似思路加速 iLQR。
- 另外，新的硬件（尤其是 FPGA 加速器）让 Transformer 在嵌入式场景也能高效运行。

------

#### Quattro 的思路

作者提出了 **Quattro** 框架：

- 用 Transformer 来预测 iLQR 中的关键中间量（反馈和前馈矩阵）。
- 这样就可以 **并行计算**，不再依赖串行的迭代步骤。
- 好处是：加快计算速度，同时保持和原版 iLQR 差不多的准确性。

------

#### 实验结果

他们在 **车杆系统**（经典控制基准问题）和 **四旋翼无人机** 上做实验：

- 在不同平台上（CPU/GPU/FPGA），Quattro 都比传统 iLQR 快很多，精度几乎不损失。
- 在 FPGA 上运行时：
  - 相比 CPU，速度快几十倍；
  - 相比 GPU，更省电（功耗低 11 倍以上）；
  - 占用硬件资源少，适合实际部署。

------

#### 贡献总结

1. **提出 Quattro 框架**：一个用 Transformer 加速的 iLQR 算法，支持并行计算和快速推理。
2. **验证效果**：在车杆和无人机实验上，显著加速，并保持与传统 iLQR 相当的准确性。
3. **硬件优化**：把 Transformer 部署到 FPGA 上，首次专门为 iLQR 做优化，实现了速度、能耗、硬件开销的平衡。

开源地址：👉 [GitHub: quattro-transformer-ilqr](https://github.com/YueWang996/quattro-transformer-ilqr?utm_source=chatgpt.com)

）

## II. 预备知识

### A. 系统动力学

系统动力学或系统模型描述了给定系统输入时系统状态如何变化。该模型可以在离散时间微分方程中定义

$$x_{i+1} = f(x_i, u_i)$$ (1)

其中$$x_i$$和$$u_i$$分别表示时间步$$i$$的状态和控制输入。可以定义成本函数来评估系统在未来N步的状态和输入性能：

$$J(X,U) = \sum_{i=0}^{N-1} l(x_i, u_i) + l_N(x_N)$$ (2)

其中$$l(x_i, u_i)$$是运行成本，$$l_N(x_N)$$是终端成本。这里，$$X := \{x_0, x_1, \cdots, x_N\}$$表示状态轨迹，$$U := \{u_0, u_1, \cdots, u_{N-1}\}$$表示输入轨迹。我们可以定义一个最优控制问题来求解最优$$U$$和相应的$$X$$，使得$$J(X,U)$$最小化：

$$\min_{X,U} J(X,U)$$
$$\text{s.t. } x_{i+1} = f(x_i, u_i), \text{ given } x_0, U_0.$$ (3)

### B. 迭代线性二次调节器

迭代线性二次调节器(iLQR)算法通过围绕标称轨迹重复近似动力学和成本来解决非线性最优控制问题。在每次迭代中，系统动力学被线性化，成本函数被近似到二阶。然后使用这些局部近似在反向过程中计算反馈和前馈控制修正，随后在前向过程中完善标称轨迹。由于反向过程本质上依赖于未来步骤的结果，该算法通过时间地平线顺序操作，本质上限制了并行实现。iLQR的更详细描述将在后续章节中呈现。

### C. 变换器架构和加速

变换器架构最初为自然语言处理中的序列建模开发[26]，[37]，依赖于具有自注意力机制的堆叠编码器-解码器层。与循环模型或像iLQR这样的序列算法不同，变换器同时处理所有序列元素，实现高效的并行计算。自注意力直接建模跨所有时间步的依赖性而无需循环，显著缩短信息路径长度并使捕获长程关系更容易[26]。

这种结构使变换器非常适合在GPU和张量处理单元(TPU)等并行硬件上加速，其中矩阵运算可以高效批处理[17]。将这种架构应用于iLQR减轻了反向过程中的大部分开销，这些开销可能限制标准动态规划方法中的并行性。通过学习近似iLQR中的完整控制轨迹，基于变换器的方法减少延迟和计算时间，这是对实时应用和在资源受限边缘设备上部署特别有益的优势。

变换器模型通常在FPGA平台而不是通用计算单元上加速，因为它们高度可定制并针对并行矩阵计算优化[38]。作为深度学习(DL)加速器之一，已经提出和开发了许多新颖架构[39]，[40]，[41]，[33]，以及更敏捷的开发方法[36]。值得注意的是，名为Allo[36]的新加速器设计语言(ADL)提供了一个框架，将基于Python的变换器模型直接转换为具有高度优化延迟和硬件开销的高级综合(HLS) C代码。然后可以将生成的HLS代码综合为寄存器传输级(RTL)电路，以作为加速器知识产权(IP)核心实现。

（

#### II. 预备知识（通俗版）

#### A. 系统动力学

这一节讲的是：**系统怎么随着输入变化**。

- 系统状态 = 系统当前的情况（位置、速度、姿态等），记作 $x_i$。
- 控制输入 = 我们施加的动作（比如无人机的推力、方向），记作 $u_i$。

状态更新方程：
 $x_{i+1} = f(x_i, u_i)$
 意思就是：**下一时刻的状态取决于当前状态和输入**。

我们还需要一个 **成本函数** 来衡量“飞得好不好”：
 $J(X,U) = \sum_{i=0}^{N-1} l(x_i, u_i) + l_N(x_N)$

- $l(x_i, u_i)$：飞行过程中的消耗（比如能耗、偏离目标）。
- $l_N(x_N)$：最后一步的结果好不好（比如到没到目标点）。

最优控制问题就是：
 👉 找到最优的控制序列 $U$，让轨迹 $X$ 的总成本最小。

------

#### B. 迭代线性二次调节器（iLQR）

**iLQR** 是一种解决非线性最优控制问题的算法。核心思想：

1. 把复杂的非线性系统，**在当前轨迹附近线性化**（近似为简单的线性系统）。
2. 把成本函数**近似为二次函数**（像抛物线一样）。
3. 在“反向过程”里，根据这些近似计算出 **反馈和前馈修正项**。
4. 在“前向过程”里，用这些修正项更新轨迹。

不断重复 → 最后得到一个比较好的轨迹和控制策略。

⚠️ 但问题是：
 反向过程必须顺序执行（一步依赖下一步的结果），**所以很难并行化**。这就是 iLQR 慢的原因。

------

#### C. 变换器架构和加速

**变换器（Transformer）** 最早是为语言任务设计的（比如翻译、ChatGPT），它有一个关键机制：

- **自注意力（Self-Attention）**：能同时看整个序列，直接捕捉长距离依赖。
- 不像 RNN/LSTM 一步步更新，Transformer 可以 **并行处理所有时间步**。

这带来两个好处：

1. **并行性强**：很适合 GPU/TPU 这样的硬件。
2. **捕捉长程关系更容易**：比如无人机飞行时，不只是下一步，还要考虑更远的动作影响。

把 Transformer 应用到 iLQR：

- 它能直接学习并近似整个控制轨迹，避免了逐步串行计算，
- 大幅度减少延迟和计算时间，
- 特别适合 **实时控制** 和 **资源受限的设备（比如嵌入式硬件）**。

进一步加速：

- 在 **FPGA**（可编程硬件）上实现 Transformer，能比通用 CPU/GPU 更高效。
- 新的工具（比如 **Allo 加速器设计语言 ADL**）可以直接把 Python 里的 Transformer 模型，自动转换成硬件电路代码（RTL），实现高性能低功耗的部署。

------

📌 **一句话总结**：
 这一节介绍了三件事：

1. **控制问题** = 找控制输入，让系统在未来走出最佳轨迹。
2. **iLQR** = 一种传统解法，但要串行算，速度慢。
3. **Transformer** = 能并行捕捉全局信息，用在 iLQR 上可以显著加速，还能在 FPGA 上高效部署。

）

## III. 变换器加速的iLQR

在本节中，我们重新审视iLQR计算过程，并解释变换器如何实现快速准确的iLQR计算。

### A. 系统推演

迭代线性二次调节器(iLQR)通过使用控制序列$$U_0$$的初始假设从初始状态$$x_0$$推演非线性系统动力学(1)开始。这产生状态的标称轨迹$$X$$。使用获得的状态-控制轨迹，轨迹的性能可以通过(2)中定义的成本函数$$J$$来测量。

### B. 反向过程

反向过程计算最优反馈和前馈控制修正。首先，非线性动力学围绕标称轨迹线性化为：

$$\delta x_{i+1} \approx A_i \delta x_i + B_i \delta u_i$$ (4)

其中矩阵$$A_i$$和$$B_i$$是系统动力学相对于状态$$x_i$$和输入$$u_i$$的雅可比矩阵。

成本围绕相同的标称轨迹近似到二阶：

$$\delta l_i \approx \frac{1}{2} \begin{bmatrix} \delta x_i \\ \delta u_i \end{bmatrix}^{\top} \begin{bmatrix} l_{xx} & l_{xu} \\ l_{ux} & l_{uu} \end{bmatrix} \begin{bmatrix} \delta x_i \\ \delta u_i \end{bmatrix} + \begin{bmatrix} l_x \\ l_u \end{bmatrix}^{\top} \begin{bmatrix} \delta x_i \\ \delta u_i \end{bmatrix}$$ (5)

接下来，遵循Bellman的最优性原理，我们定义代价函数$$V_i(x_i)$$：

$$V_i(x_i) = \min_{u_i} [l(x_i, u_i) + V_{i+1}(f(x_i, u_i))]$$ (6)

终端条件为$$V_N(x_N) := l_N(x_N)$$。

通过将这个代价函数局部展开到二阶，我们有：

$$\delta V_i(x_i) = s_i^{\top} \delta x_i + \frac{1}{2} \delta x_i^{\top} S_i \delta x_i$$ (7)

其中梯度和Hessian定义为：

$$s_i = \frac{\partial V_i}{\partial x_i}, \quad S_i = \frac{\partial^2 V_i}{\partial x_i^2}$$ (8)

我们类似地展开状态-动作成本$$Q_i(x_i, u_i)$$为：

$$\delta Q_i = \frac{1}{2} \begin{bmatrix} \delta x_i \\ \delta u_i \end{bmatrix}^{\top} \begin{bmatrix} Q_{xx} & Q_{xu} \\ Q_{ux} & Q_{uu} \end{bmatrix} \begin{bmatrix} \delta x_i \\ \delta u_i \end{bmatrix} + \begin{bmatrix} Q_x \\ Q_u \end{bmatrix}^{\top} \begin{bmatrix} \delta x_i \\ \delta u_i \end{bmatrix}$$ (9)

其中：

$$Q_x = l_x + A_i^{\top} s_{i+1}$$ (10a)

$$Q_u = l_u + B_i^{\top} s_{i+1}$$ (10b)

$$Q_{xx} = l_{xx} + A_i^{\top} S_{i+1} A_i$$ (10c)

$$Q_{uu} = l_{uu} + B_i^{\top} S_{i+1} B_i$$ (10d)

$$Q_{ux} = l_{ux} + B_i^{\top} S_{i+1} A_i = Q_{xu}^{\top}$$ (10e)

相对于输入变化$$\delta u_i$$最小化状态-动作成本得到最优控制修正：

$$\frac{d\delta Q_i}{du_i} = Q_u + Q_{ux} \delta x_i + Q_{uu} \delta u_i = 0$$ (11)

给出最优解：

$$\delta u_i^* = k_i + K_i \delta x_i$$ (12)

其中：

$$k_i = -Q_{uu}^{-1} Q_u, \quad K_i = -Q_{uu}^{-1} Q_{ux}$$ (13)

反向过程从终端状态到初始状态递归计算这些值。此外，代价函数的梯度和Hessian递归更新为：

$$s_i = Q_x + K_i^{\top} Q_{uu} k_i + K_i^{\top} Q_u + Q_{ux}^{\top} k_i$$ (14a)

$$S_i = Q_{xx} + K_i^{\top} Q_{uu} K_i + K_i^{\top} Q_{ux} + Q_{ux}^{\top} K_i$$ (14b)

### C. 前向过程

在前向过程中，使用步长$$\alpha$$的线搜索更新控制序列：

$$u_i^{new} = u_i + \alpha k_i + K_i (x_i^{new} - x_i)$$ (15)

其中$$x_i^{new}$$是此前向过程中新推演的状态。这产生新轨迹和更新的成本$$J^{new}$$。

前向过程后，通过比较成本函数的变化检查收敛性。如果改进小于预指定阈值（例如，$$|J^{new} - J| < \varepsilon$$），迭代停止。否则，过程重复反向和前向过程，直到收敛或达到预设的最大迭代限制。在实际实现中，可以并行测试几个步长：每个候选产生新的控制序列，为每个执行前向过程，从而防止如果特定步长被证明不成功时重复的前向过程计算[17]。

（

#### A. 系统推演（Forward Rollout）

iLQR 的第一步是：

- 给一个初始的控制猜测 $U_0$（比如随便设一组控制信号）。
- 从初始状态 $x_0$ 出发，用系统动力学方程一步步推算，得到一条轨迹 $X$（状态随时间的变化）。
- 然后计算这条轨迹的“好坏”，就是成本函数 $J$。

👉 可以理解为：**先试着走一遍，看看效果如何**。

------

#### B. 反向过程（Backward Pass）

接下来要改进控制策略。核心思想：

1. **线性化动力学**：
    在标称轨迹附近，把系统方程 $f(x,u)$ 近似成一个线性模型：
   $$
   \delta x_{i+1} \approx A_i \delta x_i + B_i \delta u_i
   $$
   （这里 $A_i$ 和 $B_i$ 就是雅可比矩阵，相当于“在这一点附近，系统对状态和输入的敏感度”）。

2. **二次近似成本函数**：
    把每一步的成本函数展开成二次函数（像抛物线一样）。

3. **Bellman 最优性原理**：
    定义“代价函数” $V_i(x_i)$，表示从当前状态到终点的最小可能花费。
    递推关系：
   $$
   V_i(x_i) = \min_{u_i}[ l(x_i, u_i) + V_{i+1}(f(x_i, u_i)) ]
   $$

4. **局部展开**：
    把 $V_i$ 展开成一阶项（梯度 $s_i$）和二阶项（Hessian $S_i$），方便后续迭代计算。

5. **计算控制修正**：
    解一阶条件，得到输入的最优修正：
   $$
   \delta u_i^* = k_i + K_i \delta x_i
   $$

   - $k_i$：前馈项（相当于“往前推一把”）。
   - $K_i$：反馈增益（根据状态误差修正控制）。

6. **递推更新**：
    从最后一步往前推，逐步计算出每个时间步的 $k_i$ 和 $K_i$。

👉 这一过程像是：**往回倒着算，推导出“每一步应该怎么改控制”**。

------

#### C. 前向过程（Forward Pass）

有了修正项 $k_i, K_i$ 之后，开始更新控制：

- 新控制输入：
  $$
  u_i^{new} = u_i + \alpha k_i + K_i (x_i^{new} - x_i)
  $$

  - $\alpha$：步长（类似学习率）。

- 用新控制重新推演一次轨迹，得到新的状态序列和成本 $J^{new}$。

然后：

- 如果成本改善明显，就接受这次更新；
- 如果改进不够，就继续迭代（再做反向+前向过程），直到达到精度要求或达到最大迭代次数。
- 实际实现时，可以同时并行测试不同的 $\alpha$，避免浪费计算。

👉 这一过程像是：**带着修改意见重新飞一遍，看效果好不好，如果不好就再调整**。

------

📌 **一句话总结**：
 iLQR 的核心流程就是 **先往前试飞（前向过程）→ 再往回推导修正（反向过程）→ 带着修正再试飞（前向过程）**，不断循环，直到找到一条近似最优的轨迹。

）

### D. 变换器的集成

反向过程递归计算增益并更新系统输入。加速算法的核心思想是减少序列计算。在iLQR中，由于系统动力学和成本函数的大量导数，递归反向过程最耗时[12]。

一个想法是用变换器模块$$\pi_{\theta}$$替换整个反向过程：

$$\hat{k}, \hat{K} = \pi_{\theta}(X)$$ (16)

虽然它可以显著加速计算，因为序列计算完全转换为并行计算，但这种纯端到端方法可能缺乏鲁棒性，因为它完全省略了反向过程中的关键二阶代价和敏感性信息。将显式反向过程信息（例如，代价Hessian或梯度）作为变换器的输入可以实现更明智和可靠的预测。

因此，在我们的框架中（如图2所示），我们不计算完整的反向过程，而是执行部分反向过程，计算增益矩阵$$k_{i:T-1} = \{k_i, \cdots, k_{T-1}\}$$和$$K_{i:T-1} = \{K_i, \cdots, K_{T-1}\}$$。其余增益矩阵由变换器模型预测：

$$\hat{k}_{0:i-1}, \hat{K}_{0:i-1} = \pi_{\theta}(X, k_{i:T-1}, K_{i:T-1})$$ (17)

通过这样做，它保留了最优控制的基本结构，从而提高整体解的鲁棒性和稳定性。

如图2所示，采用仅解码器变换器来预测iLQR增益矩阵，因为其因果结构自然地与最优控制中增益计算固有的序列和时间特征一致。基于编码器的变换器不太适合，因为其双向注意力结构不保持时间因果性，这对序列控制任务至关重要。类似地，完整的编码器-解码器变换器引入不必要的复杂性和计算开销，没有明显优势，因为这里的主要任务是建模序列依赖性而不是在不同输入-输出序列之间映射。因此，仅解码器变换器为建模iLQR增益预测的因果和序列性质提供了结构上更合适的选择。

为了同时输入状态和增益矩阵，我们为变换器模块添加了额外通道。增益矩阵作为单个输入矩阵堆叠。在状态嵌入和增益嵌入之后，它们被位置编码并连接，然后输入多头注意力。变换器的输出是扁平向量，重塑以提取增益矩阵$$\hat{k}_{0:i-1}$$和$$\hat{K}_{0:i-1}$$。连接预测增益和计算增益后，获得完整的反馈和前馈增益，用于计算前向过程。

（

#### D. 变换器的集成（怎么把 Transformer 融入 iLQR）

iLQR 最耗时的地方是 **反向过程**（Backward pass），因为要顺序地一步步递推，算很多导数（梯度、Hessian）。

研究者的想法：

- **不用自己算完所有反向步骤**，而是让 Transformer 来帮忙预测一部分结果。

具体做法：

1. **完全替换（不推荐）**

   - 直接用 Transformer 模块 $\pi_\theta$ 来输出所有增益矩阵：
     $$
     \hat{k}, \hat{K} = \pi_\theta(X)
     $$

   - 好处：完全并行，很快。

   - 坏处：丢掉了 iLQR 的二阶信息（梯度/Hessian），可能不稳定。

2. **部分替换（我们的方案）**

   - 先计算一部分增益矩阵（比如最后几步的 $k_i, K_i$）。

   - 让 Transformer 根据这些已知的结果 + 系统状态，去预测前面没算的部分：
     $$
     \hat{k}_{0:i-1}, \hat{K}_{0:i-1} = \pi_\theta(X, k_{i:T-1}, K_{i:T-1})
     $$

   - 好处：保留了 iLQR 的结构和稳定性，同时把最耗时的部分交给 Transformer 并行完成。

为什么只用 **解码器式 Transformer**？

- 解码器有 **因果结构**（只能看过去的，不看未来），符合控制问题的时序性。
- 编码器是双向注意力（看前后文），会破坏因果性，不适合控制任务。
- 编码器-解码器架构太复杂，计算反而更重，没有必要。

输入设计：

- 把 **状态信息** 和 **部分增益矩阵** 一起输入 Transformer。
- 输入前做嵌入 + 位置编码，让 Transformer 能理解时间顺序。
- 输出一个长向量，再 reshape 回增益矩阵的形式。
- 把预测的增益和实际算的增益拼接起来 → 得到完整的控制律。

👉 简单理解：**Transformer 帮 iLQR“补全”没算完的部分**，又快又稳。

）

### E. 可选输出混合器

为了避免变换器控制器（iLQR-TF）在平衡点附近由小残余增益引起的潜在振荡，我们在参考状态周围包含可选的轻量级线性二次调节器（LQR）。标准混合机制根据当前成本$$J$$在iLQR-TF和LQR输出之间平滑过渡。

定义两个阈值（$$\varepsilon_{low}$$，$$\varepsilon_{high}$$），混合权重计算为：

$$w_{blend} = \begin{cases}
0, & \|J\| \leq \varepsilon_{low}, \\
\frac{\|J\| - \varepsilon_{low}}{\varepsilon_{high} - \varepsilon_{low}}, & \varepsilon_{low} < \|J\| < \varepsilon_{high}, \\
1, & \|J\| \geq \varepsilon_{high}.
\end{cases}$$ (18)

最终混合控制输出为：

$$u^* = w_{blend} \cdot u_{iLQR-TF} + (1 - w_{blend}) \cdot u_{LQR}$$ (19)

这意味着当$$w_{blend} = 1$$时系统完全由iLQR-TF控制，当$$w_{blend} = 0$$时完全由LQR控制。

（

#### E. 可选输出混合器（让控制更稳定）

有时候 iLQR-TF 在“平衡点”附近（比如无人机悬停时）会因为一些小的残余增益而导致 **轻微抖动/振荡**。
 解决办法：在它旁边加一个更稳定的 **传统 LQR 控制器**，然后做 **混合输出**。

混合逻辑：

- 定义两个阈值：$\varepsilon_{low}$ 和 $\varepsilon_{high}$。
- 当成本 $J$ 很小（接近目标时，$\leq \varepsilon_{low}$）：完全用 **LQR**（更稳）。
- 当成本 $J$ 很大（远离目标时，$\geq \varepsilon_{high}$）：完全用 **iLQR-TF**（更强大）。
- 当在中间范围时：按比例平滑混合两者。

公式：
$$
u^* = w_{blend} \cdot u_{iLQR-TF} + (1 - w_{blend}) \cdot u_{LQR}
$$
👉 简单理解：**飞得远时靠 Transformer 算，快而强；飞得近时切换成传统 LQR，更稳不抖**。

）

## IV. 实验和分析

我们在两个基准控制问题上评估了iLQR-变换器框架：车杆系统和四旋翼，都使用MuJoCo[42]仿真。

### A. 数据收集

我们通过使用iLQR解决最优控制问题生成训练数据。具体来说，每个系统从不同的初始状态初始化，执行标准iLQR来计算增益（k，K）和输入序列U。我们将iLQR纳入MPC框架，为每个MPC步骤的每次iLQR迭代收集（X，k，K，U）。

对于低维车杆系统$$x \in \mathbb{R}^4$$，我们以0.01秒时间步长离散化动力学并仿真15秒。初始x位置和角度在[−0.5，0.5]上以0.05增量网格采样。

相比之下，对于高维四旋翼系统$$x \in \mathbb{R}^{12}$$，网格搜索是不实际的。相反，我们采用拉丁超立方采样(LHS)[43]来抽取2,000个初始状态。这些跨越$$pos_x$$，$$pos_y \in [−0.3，0.3]$$，$$pos_z \in [0.2，0.5]$$，$$roll$$，$$pitch \in [−0.2，0.2]$$，$$yaw \in [−0.5，0.5]$$，所有速度初始设置为零。这确保高维状态空间的广泛覆盖，同时限制初始速度。我们使用相同的仿真方法收集iLQR计算结果。

（

### 训练数据怎么来？

研究人员需要大量的样本来训练 **Transformer 加速的 iLQR**。这些样本就是：

- 系统的状态轨迹 $X$
- iLQR 算出来的控制增益 $(k, K)$
- 控制输入序列 $U$

收集方式：

1. 先给系统一个初始状态（比如一开始的位置、角度）。
2. 用标准的 iLQR 算法解出在这个状态下的最优控制。
3. 把每次迭代中的结果都存下来（包括轨迹、增益和输入）。
    👉 这样就得到了训练数据。

）

### B. 变换器模型和加速器设计

变换器模型使用PyTorch实现，并使用高性能计算集群训练。为了解决两个控制系统之间不同的复杂性，相应调整模型参数。对于车杆系统，采用三层仅解码器架构，每层包含4个注意力头和128的模型维度。前馈层的维度是256，捕获输入序列的特征。对于四旋翼系统，我们选择相同的变换器架构和参数。然而，由于复杂动力学，我们将前馈层从256扩展到512，以捕获更多输入特征和依赖性。

我们主要采用[36]中提出的最新敏捷变换器ADL框架来构建高效实用的硬件设计。这种方法汇集了形成完整变换器计算的几个基本内核组件。通过利用FPGA的并行矩阵乘法能力，我们专注于主要计算块的硬件加速，包括多头注意力、层归一化、残差连接和前馈网络。这些是解码器中计算最密集的部分。其他操作，如嵌入、位置编码和矩阵组合，由CPU处理，因为它们提供的并行处理机会有限。为了平衡延迟和硬件资源使用，我们在设计过程中应用了几个HLS指令，如流水线、展开、分区和使用双端口RAM。

**表I：FPGA开发实验设置**

| 项目           | 规格                                |
| -------------- | ----------------------------------- |
| FPGA设备系列   | AMD Kintex系列FPGA                  |
| 加速器设计语言 | Allo [36]                           |
| 主要编程语言   | Python，HLS C，Verilog HDL          |
| EDA工具        | Vitis，Vivado                       |
| 时钟频率       | 80 MHz（车杆）<br>200 MHz（四旋翼） |

### C. 预测准确性

对于车杆系统，我们调节车杆在x轴上停在位置0，并将杆角稳定在0弧度。图3显示预测增益矩阵$$\hat{k}$$和$$\hat{K} = \{K_1, K_2, K_3, K_4\}$$与从iLQR计算的实际增益紧密匹配。每个元素$$K_i$$对应给定时间步的反馈增益矩阵K分量。

我们进一步评估了中间增益矩阵不同预测长度的预测准确性。对于特定地平线，iLQR如第III-D节所述执行部分反向过程，变换器模型预测剩余增益序列，通过前向过程获得更新的输入序列$$U_{iLQR-TF}$$。我们测量此$$U_{iLQR-TF}$$与完整iLQR计算结果之间的MSE。图4中的虚线图显示了iLQR和变换器之间不同负载分配的MSE。

对于车杆系统（T = 30），每个样本的MSE值相对集中，随着计算的iLQR增益矩阵数量减少而逐渐增加。

对于四旋翼系统，预测地平线T = 50，变换器输入包括状态序列$$X \in \mathbb{R}^{T×12}$$和堆叠增益矩阵$$K_{stacked} \in \mathbb{R}^{T×52}$$（从$$k \in \mathbb{R}^{T×4}$$和$$K \in \mathbb{R}^{T×4×12}$$重塑）。图4（下图）说明MSE，由于与车杆系统相比增加的复杂性和维度而显示更高和更分散的值。然而，尽管由于较大增益矩阵上平方误差放大导致更高分散，大多数预测误差保持非常低（在$$10^{-1}$$和$$10^{-3}$$之间）。此外，对于变化的预测长度，MSE样本分布保持一致，表明可以利用更高比例的变换器预测数据来最大化并行化并提高整体计算效率。

### D. 计算加速和加速器性能

我们首先在Apple Silicon M4 Pro（10核CPU）上测试了框架。图4说明了iLQR和变换器之间不同分配的计算时间。随着我们减少iLQR执行的计算步骤，整体执行时间显著降低，利用了变换器的高度并行计算。对于车杆系统，每次迭代的平均计算从10.19毫秒减少到1.92毫秒（5.3×更快）。对于更复杂的四旋翼，迭代时间从246.25毫秒显著减少到9毫秒（27×更快），突出了我们方法在处理更大、计算密集系统方面的优势。

与[12]中另一种加速iLQR算法相比，该算法通常需要额外迭代才能收敛，我们的方法实现了与传统iLQR相当的迭代次数以达到最优解，从而证明了显著的整体时间节省。如图5上图所示，当使用5个iLQR步骤和25个变换器辅助步骤时，车杆系统的总仿真时间从10.5秒减少到3.7秒，实现2.8×加速。这与图4（上图）中观察到的时间节省紧密一致。在四旋翼控制场景中，对于具有10,000个总仿真步骤和500个MPC控制计算的仿真，我们的方法通过结合1步iLQR计算和49个后续变换器预测步骤，将计算时间从237秒（每个MPC步骤的纯iLQR计算）大幅减少到13.3秒。这导致17.8×加速。此外，与[44]中报告的最先进OCP求解器OSQP、ECOS和SCS相比，我们的方法分别实现了2.49×、3.63×和2.4×的加速。

表II显示我们的加速器在变换器推理中提供了预期性能。在车杆控制场景中，它实现了与Apple M4 Pro@3.5 GHz相似的速度，同时比NVIDIA RTX4070快1.55×，比Raspberry Pi中的Cortex-A72快17.67×。在四旋翼控制场景中，我们的加速器比M4 Pro CPU快1.8×，比Raspberry Pi快20.8×。虽然在四旋翼任务中推理时间接近RTX4070，但我们的加速器使用的功耗要少得多，车杆消耗仅1.15W，四旋翼消耗1.68W，相比之下GPU在两个任务中都稳定消耗13W。

在中档FPGA上硬件资源开销极低，除了主要用于存储模型参数的BRAM外，所有资源类型的平均利用率都保持在10%以下。在相同20nm工艺下，估计硅面积比典型CPU或GPU显著更小。

**表II：FPGA加速器性能指标**

| 指标                       | 车杆   | 四旋翼 |
| -------------------------- | ------ | ------ |
| **推理性能**               |        |        |
| 延迟 (ms)                  | 1.05   | 1.73   |
| 加速 (vs. 10核M4 Pro CPU)  | 0.99×  | 1.8×   |
| 加速 (vs. RTX4070 GPU)     | 1.55×  | 1.01×  |
| 加速 (vs. 四核Cortex-A72)  | 17.67× | 20.8×  |
| 功耗降低 (vs. RTX4070 GPU) | 11.3×  | 7.74×  |
| **资源利用率**             |        |        |
| BRAM使用率 (%)             | 24     | 41     |
| DSP使用率 (%)              | 4      | 9      |
| FF使用率 (%)               | 4      | 3      |
| LUT使用率 (%)              | 9      | 8      |

### E. 轨迹跟踪性能

我们的框架有效控制两个系统跟随期望轨迹。图5（下图）展示了变换器辅助（iLQR-TF）控制器在稳定车杆系统方面与真实iLQR控制器的性能紧密匹配。当系统接近线性区域时引入LQR使得平滑收敛到期望状态。

我们还使用iLQR-TF方法测试了四旋翼系统更复杂的8字轨迹跟踪。如图6所示，变换器辅助控制在各种预测长度下准确跟踪参考轨迹。预测轨迹始终与完整地平线iLQR（50步）计算的真实值紧密一致。

### F. 超参数探索

变换器模型预测的准确性取决于状态和增益输入序列的长度。如图4所示，性能随着切换到变换器前的初始iLQR步数而变化。为了平衡预测准确性和推理时间，我们为车杆系统选择5个iLQR步骤，为四旋翼选择1步。

我们进一步探索了关键变换器超参数，包括注意力头数量（$$n_{head}$$）和模型维度（$$d_{model}$$），以验证我们的设计选择。图7展示了结果。对于车杆系统，配置$$d_{model}=128$$和$$n_{head}=4$$实现了最低MSE（0.0053）和快速推理时间（0.9ms）。对于四旋翼，相同配置产生了最低推理时间（2.0ms）和良好的MSE（0.2051），突出了跨任务的一致权衡。

如图7所示，较小的模型通常在准确性和速度方面都表现更好，而将$$d_{model}$$或$$n_{head}$$增加到某一点以上会导致收益递减或更高延迟。选择的配置平衡了模型容量和运行效率：$$d_{model}=128$$提供足够表达力而没有过多成本，$$n_{head}=4$$允许有效的多重注意力。这些结果确认了轻量级架构对实时部署的适用性。

## V. 结论

在本文中，我们提出了Quattro，一个变换器加速的iLQR框架，通过控制增益的并行推理解决传统iLQR算法中的串行瓶颈。通过预测中间计算变量，Quattro在显著减少计算时间的同时保持最优控制的结构。我们在车杆和四旋翼系统上的实验表明，Quattro实现了高达27×的每次迭代加速和在MPC框架内17.8×的端到端加速。基于FPGA的部署进一步显示了相对于边缘CPU的17-20×加速和相对于GPU的高达1.55×加速，同时功耗降低11.3×和硬件开销极低。虽然更大的变换器模型可以产生甚至更高的预测准确性（有时超过原始iLQR），但它们引入更高的延迟和硬件开销。因此，我们选择平衡准确性、效率和可用性的轻量级配置（$$d_{model}=128$$，$$n_{head}=4$$）。这些结果确认了基于变换器的实时最优控制加速的潜力。

未来工作包括将Quattro扩展到更复杂的机器人系统，研究自适应提示调整，以及探索与基于学习的控制集成以在动态环境中获得更大鲁棒性。

## 参考文献

[1] G. Bledt, M. J. Powell, B. Katz, J. Di Carlo, P. M. Wensing, and S. Kim, "Mit cheetah 3: Design and control of a robust, dynamic quadruped robot," in 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, 2018, pp. 2245–2252.

[2] S. H. Jeon, S. Kim, and D. Kim, "Online optimal landing control of the mit mini cheetah," in 2022 International Conference on Robotics and Automation (ICRA). IEEE, 2022, pp. 178–184.

[3] G. Romualdi, S. Dafarra, G. L'Erario, I. Sorrentino, S. Traversaro, and D. Pucci, "Online non-linear centroidal mpc for humanoid robot locomotion with step adjustment," in 2022 International Conference on Robotics and Automation (ICRA). IEEE, 2022, pp. 10 412–10 419.

[4] B. Lindqvist, S. S. Mansouri, A.-a. Agha-mohammadi, and G. Nikolakopoulos, "Nonlinear mpc for collision avoidance and control of uavs with dynamic obstacles," IEEE robotics and automation letters, vol. 5, no. 4, pp. 6001–6008, 2020.

[5] D. G. Nguyen, S. Park, J. Park, D. Kim, J. S. Eo, and K. Han, "An mpc approximation approach for adaptive cruise control with reduced computational complexity and low memory footprint," IEEE Transactions on Intelligent Vehicles, vol. 9, no. 2, pp. 3154–3167, 2023.

[6] Y. Tassa, T. Erez, and E. Todorov, "Synthesis and stabilization of complex behaviors through online trajectory optimization," in 2012 IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE, 2012, pp. 4906–4913.

[7] Y. Tassa, N. Mansard, and E. Todorov, "Control-limited differential dynamic programming," in 2014 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2014, pp. 1168–1175.

[8] M. Neunert, F. Farshidian, A. W. Winkler, and J. Buchli, "Trajectory optimization through contacts and automatic gait discovery for quadrupeds," IEEE Robotics and Automation Letters, vol. 2, no. 3, pp. 1502–1509, 2017.

[9] M. Neunert, M. Stäuble, M. Giftthaler, C. D. Bellicoso, J. Carius, C. Gehring, M. Hutter, and J. Buchli, "Whole-body nonlinear model predictive control through contacts for quadrupeds," IEEE Robotics and Automation Letters, vol. 3, no. 3, pp. 1458–1465, 2018.

[10] T. A. Howell, B. E. Jackson, and Z. Manchester, "Altro: A fast solver for constrained trajectory optimization," in 2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, 2019, pp. 7674–7679.

[11] J. Zhu, J. J. Payne, and A. M. Johnson, "Convergent ilqr for safe trajectory planning and control of legged robots," in 2024 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2024, pp. 8051–8057.

[12] B. Plancher and S. Kuindersma, "A performance analysis of parallel differential dynamic programming on a gpu," in Algorithmic Foundations of Robotics XIII: Proceedings of the 13th Workshop on the Algorithmic Foundations of Robotics 13. Springer, 2020, pp. 656–672.

[参考文献继续列出至[44]，由于篇幅限制，这里省略其余引用]