# 大语言模型中的提示工程系统综述：技术与应用

*License*: arXiv.org perpetual non-exclusive license
*arXiv*: 2402.07927v2 [cs.AI] 16 Mar 2025
*Authors*: Pranab Sahoo, Ayush Kumar Singh, Sriparna Saha, Vinija Jain, Samrat Mondal, Aman Chadha
*Affiliations*:  

1. 印度理工学院帕特纳分校计算机科学与工程系  
2. 斯坦福大学  
3. 亚马逊 AI
   *Emails*: {pranab_2021cs25, ayush_2211ai27, sriparna, samrat}@iitp.ac.in, [hi@vinija.ai](mailto:hi@vinija.ai), [hi@aman.ai](mailto:hi@aman.ai)

*注*: 本工作与作者在亚马逊的职位无关。

## 摘要

提示工程已成为扩展大型语言模型（LLMs）和视觉-语言模型（VLMs）能力的一项不可或缺的技术。该方法通过任务特定的指令（称为提示）来增强模型效能，而无需修改核心模型参数。提示允许在不更新模型参数的情况下，将预训练模型无缝集成到下游任务中，仅通过给定的提示引发所需模型行为。提示可以是提供上下文以引导模型的自然语言指令，也可以是激活相关知识的学得向量表示。这一新兴领域已在多种应用中取得成功，从问答到常识推理。然而，针对多样化的提示工程方法和技术的系统化组织和理解仍显不足。本文通过提供近期提示工程进展的结构化概述，按应用领域进行分类，填补了这一空白。对于每种提示方法，我们提供了提示方法论、其应用、涉及的模型以及使用的数据集的总结。我们还深入探讨了每种方法的优势和局限性，并包括一个分类图和表格，总结了数据集、模型和每种提示技术的关键点。这种系统分析有助于更好地理解这一快速发展领域，并通过揭示开放性挑战和机遇促进未来研究。

**关键词**：提示工程，大型语言模型，视觉-语言模型，人工智能

## 1 引言

提示工程已成为增强预训练大型语言模型（LLMs）和视觉-语言模型（VLMs）能力的一项关键技术。它涉及战略性地设计任务特定指令（称为提示），以在不更改模型参数的情况下引导模型输出。提示工程的重要性尤其体现在其对 LLMs 和 VLMs 可适应性的变革性影响上。通过精心设计的指令微调模型输出，提示工程使这些模型能够在多样化任务和领域中表现出色。这种适应性不同于传统范式，后者通常需要针对特定任务进行模型重新训练或广泛微调。这是提示工程的变革性潜力，突破了人工智能的界限，为充满可能性的未来打开了大门。在不断演变的景观中，持续的研究不断揭示提示工程中的创新方法和应用。提示工程的重要性在于其引导模型响应的能力，增强了 LLMs 在各个领域的适应性和适用性。当代提示工程技术涵盖了从零样本（zero-shot）和少样本（few-shot）提示等基础方法到更复杂的“代码链”（chain of code）提示等一系列方法。提示工程的概念最初在 LLMs 中被研究和推广 [Liu et al., 2023; Tonmoy et al., 2024; Chen et al., 2023]，随后扩展到 VLMs [Wu et al., 2023; Bahng et al., 2022]。尽管在 LLMs 和 VLMs 的提示工程方面已有广泛文献，但仍存在显著的空白，特别是在以应用为中心的提示工程技术的系统化概述方面。随着提示工程的最新进展，迫切需要一篇全面的综述，提供对当代研究应用和进展的细致理解。本文深入探讨了提示工程的不断演变景观，分析了按应用领域分类的 41 种不同技术。通过系统化的审查方法，我们仔细研究了各种前沿提示方法的复杂性。我们的分析涵盖了其应用、使用的语言模型以及实验中涉及的数据集，提供了对提示工程演变景观的详细而细致的分析。此外，我们讨论了这些技术的优缺点，提供了对其比较效能的见解。我们提供了一个全面的分类图，展示了这些技术如何在 LLMs 能力的广阔景观中导航（见图 2），并提供了一个表格，总结了数据集、使用的模型和评估指标（见表 1）。从语言生成和问答到代码生成和推理任务，提示工程赋予了 LLMs 实现我们从未想象可能的功能。通过弥合文献中的现有空白，本综述旨在为研究人员和实践者提供有价值的资源，提供对最新发展的见解，并促进对提示工程演变景观的更深入理解。本文的结构如下：第 2 节按应用领域展示了从基础到高级的提示工程技术，第 3 节提供了结论以及未来研究方向的考虑。

![图 1：提示工程组件的视觉分解：训练于数十亿参数的 LLMs，指令和上下文作为塑造提示的关键元素，以及用户输入界面。](attachment://figure1.png)

## 2 提示工程

在本节中，我们根据应用领域组织了提示工程技术，并提供了从零样本提示到最新进展的提示技术演变的简要概述。

### 2.1 无需广泛训练的新任务

#### 零样本提示

零样本提示为利用大型 LLMs 提供了一种范式转变。该技术消除了对广泛训练数据的需求，而是依靠精心设计的提示来引导模型处理新任务 [Radford et al., 2019]。具体来说，模型在提示中接收任务描述，但缺乏用于训练特定输入-输出映射的标记数据。然后，模型利用其预先存在的知识，根据给定的提示为新任务生成预测。

#### 少样本提示

少样本提示为模型提供了一些输入-输出示例，以诱导对给定任务的理解，与零样本提示不同，后者不提供任何示例 [Brown et al., 2020]。即使提供少量高质量示例，也能显著改善模型在复杂任务上的性能，优于无示例的情况。然而，少样本提示需要额外的 token 来包含示例，这对于较长的文本输入可能成为限制。此外，提示示例的选择和构成可能会显著影响模型行为，偏向于常见词语的偏见可能仍然影响少样本结果。虽然少样本提示增强了复杂任务的能力，尤其是在 GPT-3 等大型预训练模型中，但精心设计提示对于实现最佳性能和缓解意外模型偏见至关重要。

### 2.2 推理与逻辑

#### 思维链（Chain-of-Thought, CoT）提示

LLMs 在面对复杂推理任务时常常表现不佳，限制了其潜力。为了弥补这一差距，Wei 等人 [2022] 提出了思维链（CoT）提示技术，通过提示 LLMs 以促进连贯的、逐步的推理过程。其主要贡献在于提出并探索了 CoT 提示，展示了其在引发 LLMs 更结构化和深思熟虑的响应方面的有效性，与传统提示相比。通过一系列实验，作者展示了 CoT 提示的独特品质，强调其引导 LLMs 通过逻辑推理链的能力。这导致响应反映了对给定提示的更深入理解。例如，提示会展示多步数学文字问题的推理过程和最终答案，模仿人类如何将问题分解为逻辑中间步骤。作者通过为 PaLM 540B 使用 CoT 提示，在数学和常识推理基准测试中实现了最先进的性能，达到了 90.2% 的准确率。

#### 自动思维链（Auto-CoT）提示

手动创建高质量的 CoT 示例既耗时又次优。Zhang 等人 [2022] 提出了自动思维链（Auto-CoT），通过“让我们一步步思考”的提示自动指导 LLMs 生成推理链。认识到单个生成链中可能出现的错误，Auto-CoT 通过多样化采样增强了鲁棒性。它对各种问题进行采样，并为每个问题生成多个不同的推理链，形成最终的示范集。这种自动化的多样化采样最大限度地减少了错误，并增强了少样本学习，消除了劳动密集型手动创建推理链的需要。Auto-CoT 展示了增强的性能，在算术和符号推理任务上分别比 CoT 范式提高了平均 1.33% 和 1.5% 的准确率，使用 GPT-3。

#### 自一致性（Self-Consistency）

Wang 等人 [2022] 提出了自一致性，这是一种解码策略，相比于 CoT 提示中的贪婪解码，增强了推理性能。对于具有多种有效路径的复杂推理任务，自一致性通过从语言模型的解码器中采样生成多样化的推理链。然后，通过边缘化这些采样链，识别出最一致的最终答案。这种方法利用了需要深入分析的问题通常涉及更大推理多样性的观察，从而得出解决方案。自一致性与思维链提示的结合在多个基准测试中显著提高了准确率，例如在 GSM8K 上提高了 17.9%，在 SVAMP 上提高了 11.0%，在 AQuA 上提高了 12.2%，在 StrategyQA 上提高了 6.4%，在 ARC-challenge 上提高了 3.9%，相比于基线思维链提示。

#### 逻辑思维链（LogiCoT）提示

逻辑推理能力对于 LLMs 解决跨领域的复杂、多步问题至关重要。现有的方法，如 CoT 提示，鼓励逐步推理但缺乏有效的验证机制。Zhao 等人 [2023] 提出了逻辑思维链（LogiCoT）提示，这是一种神经符号框架，利用符号逻辑原理以连贯和结构化的方式增强推理。具体来说，LogiCoT 应用归谬法（reductio ad absurdum）验证模型生成的每个推理步骤，并提供针对性反馈以修正错误步骤。LogiCoT 通过思考-验证-修正循环减少逻辑错误和幻觉。在 Vicuna-33b 和 GPT-4 上进行的实验表明，LogiCoT 在 GSM8K 数据集上分别提高了 0.16% 和 1.42%，在 AQuA 数据集上分别提高了 3.15% 和 2.75%，相比于 CoT。

#### 符号链（Chain-of-Symbol, CoS）提示

由于依赖自然语言，LLMs 在涉及复杂空间关系任务时常常表现不佳，因为自然语言容易出现歧义和偏见。为了克服这一限制，Hu 等人 [2023] 提出了符号链（CoS），使用压缩符号代替自然语言。CoS 提供了显著优势：清晰简洁的提示、增强 LLMs 的空间推理能力以及改进的人类可解释性。CoS 面临挑战，如可扩展性、泛化性、与其他技术的整合以及基于符号的 LLM 推理可解释性。值得注意的是，CoS 的实施显著提升了 ChatGPT 的性能，在 Brick World 任务上将准确率从 31.8% 提高到 92.6%。此外，CoS 将提示 token 减少了高达 65.8%，在保持高准确率的同时简化了流程。

#### 思维树（Tree-of-Thoughts, ToT）提示

Yao 等人 [2023a] 和 Long [2023] 提出了思维树（ToT）框架，以增强复杂任务的提示能力，这些任务需要探索和前瞻推理。ToT 通过管理中间推理步骤（称为“思维”）的树结构扩展了 CoT 提示。每个思维表示一个朝向最终解决方案的连贯语言序列。这种结构允许语言模型通过评估思维在解决问题中的进展来进行深思熟虑的推理。ToT 集成了模型生成和评估思维的能力与广度优先或深度优先搜索等搜索算法。这使得可以在推理链中进行系统探索，前瞻扩展有前景的方向，并在解决方案错误时回溯。ToT 在 24 点游戏任务中表现出色，成功率达到 74%，而 CoT 仅为 4%。此外，在单词级任务中，ToT 的成功率达到 60%，优于 CoT 的 16%。

#### 思维图（Graph-of-Thoughts, GoT）提示

人类思维过程的非线性特性挑战了传统的 CoT 提示的顺序方法。Yao 等人 [2023b] 提出了“思维图”（GoT）提示，这是一个基于图的框架，改进了传统的顺序方法，以更好地适应人类思维的非线性特性。该框架允许动态交互、回溯和评估想法，允许从不同分支聚合和组合思维，摆脱了思维树的线性结构。主要贡献包括将推理过程建模为有向图，提供具有多种转换操作的模块化架构。该框架被提出为一种多功能且动态的语言模型提示方法，捕捉人类思维过程的复杂性并增强模型能力。GoT 推理模型在 CoT 基线上展示了显著提升，在 GSM8K 上使用 T5-base 和 T5-large 分别提高了 3.41% 和 5.08% 的准确率。在 ScienceQA 上，GoT 使用 T5-base 和 T5-large 分别比最先进的 Multimodal-CoT 提高了 6.63% 和 1.09% 的准确率。

#### 系统 2 注意力（System 2 Attention, S2A）提示

基于 Transformer 的 LLMs 的软注意力机制容易纳入不相关的上下文信息，负面影响 token 生成。为解决这一问题，Weston 和 Sukhbaatar [2023] 提出了系统 2 注意力（S2A），利用 LLMs 的推理能力选择性地关注相关部分，通过重新生成输入上下文来实现。S2A 使用两步过程，通过上下文再生和使用精炼上下文的响应生成来增强注意力和响应质量。在事实问答、长篇生成和数学文字问题等任务上评估了 S2A 的有效性。在事实问答中，S2A 达到了 80.3% 的准确率，显示出事实性的显著提升。在长篇生成中，它提高了客观性，得分为 3.82（满分 5 分）。

#### 思维线程（Thread of Thought, ThoT）提示

Zhou 等人 [2023] 提出了思维线程（ThoT），一种旨在增强 LLMs 在混乱上下文中的推理能力的提示技术。受人类认知的启发，ThoT 将广泛的上下文系统地检查为可管理的片段进行增量分析，采用两阶段方法：LLM 首先总结并检查每个片段，然后精炼信息以生成最终响应。ThoT 的灵活性使其成为一个多功能的“即插即用”模块，增强了不同模型和提示方法的推理能力。在问答和对话数据集上的评估显示，在混乱上下文中性能显著提高，分别为 47.20% 和 17.8%。

#### 表格链（Chain-of-Table）提示

像 CoT、PoT 和 ToT 这样的方法通过自由形式文本或代码表示推理步骤，在处理复杂表格场景时面临挑战。Wang 等人 [2024] 提出了一个开创性的提示技术，称为表格链（Chain-of-Table）。该方法通过动态生成和执行常见的 SQL/DataFrame 操作来进行逐步表格推理。这一迭代过程增强了中间结果，使 LLMs 能够通过逻辑可视化的推理链进行预测。显著的是，表格链在两个基准表格数据集上持续提高了性能，在 TabFact 上提高了 8.69%，在 WikiTQ 上提高了 6.72%。

#### 自精炼（Self-Refine）提示

Madaan 等人 [2023] 提出的自精炼提示通过自我生成反馈迭代精炼输出，模仿人类修订过程，从而增强 LLM 性能。虽然 LLMs 可以处理广泛的任务，但它们常常在复杂目标、模糊目标或多步推理任务中表现不佳，导致初始响应存在不准确或逻辑缺陷。受人类迭代精炼的启发，自精炼使 LLMs 通过结构化的三步过程改进输出：生成初始响应，提示模型批评自己的输出，并根据反馈精炼响应。这一循环持续进行，直到满足预定义的停止标准，使模型产生更准确且与上下文相关的结果。与仅依赖单步响应的传统提示方法不同，自精炼促进了增量改进，特别适用于需要细致推理的任务。实验结果显示出显著的性能提升，GPT-4 在代码优化任务中提高了 8.7 分，在代码可读性任务中提高了 13.9 分，在情感反转任务中提高了 21.6 分，展示了其在增强 LLMs 推理和适应性方面的潜力，适用于各种领域。

#### 代码提示

预训练代码增强了 LLMs 的推理能力，但其背后的机制仍知之甚少。为了研究这一点，Puerto 等人 [2024] 考察了输入表示对 LLM 推理的影响，具体探索了将自然语言（NL）问题重新表述为代码是否能触发条件推理能力。这导致了代码提示的引入，这是一种将 NL 任务重新表述为结构化代码的技术，使文本+代码 LLMs 能够直接进行提示，而无需依赖外部代码执行。在三个推理基准测试（ConditionalQA、BoardgameQA 和 ShARC）上的实验表明，代码提示显著优于传统基于文本的提示。平均而言，GPT 3.5 实现了 8.42 的 F1 分数增益，而 Mistral 在三个数据集上平均提高了 4.22。

#### 自协调思维链（ECHO）提示

虽然思维链提示增强了 LLMs 的推理能力，但像 Auto-CoT 这样自动化生成示范的方法面临来自误导性相似性（类似示例中的错误推理）和无效多样性（不相关或过于多样的模式）的挑战。为解决这些问题，Mekala 等人 [2024] 提出了 ECHO，这是一个自协调提示框架，将多样化的推理路径统一为连贯的模式，平衡自动化和鲁棒性。ECHO 通过三个关键阶段运行：(1) 问题聚类，使用 Sentence-BERT 嵌入和 k-means 将问题分组为簇；(2) 示范采样，从每个簇中选择代表性问题并使用零样本 CoT 生成推理；(3) 示范统一，使用动态提示机制迭代精炼推理模式以对齐推理路径。此过程最大限度地减少了多样性引起的噪声，同时保留适应性。ECHO 在 10 个推理基准测试（算术、常识、符号）上平均比 Auto-CoT 高出 2.8%，并表现出更高的效率。它在使用 50% 更少示例时保持了性能，仅下降 -0.8%，而 Few-Shot-CoT 下降了 -1.3%。该方法在 Mixtral-8x7B 上比 Auto-CoT 提高了 2.3%，尽管仍落后于 GPT-3.5，这一差距归因于推理理据的质量差异。

#### 逻辑思维（Logic-of-Thought）提示

LLMs 常常表现出不忠实的推理，生成结论与中间推理步骤不一致。逻辑思维提示 [Liu et al., 2024] 是一种神经符号框架，通过用来自命题逻辑的逻辑信息丰富提示来缓解这一问题。LoT 在三个阶段运行：(1) 逻辑提取，期间 LLMs 从输入文本中识别命题和逻辑关系；(2) 逻辑扩展，其中基于 Python 的模块应用形式逻辑定律（例如对偶性）推断额外的表达式；(3) 逻辑翻译，将扩展的逻辑重新渲染为自然语言并附加到原始提示中，以确保上下文保真。此外，逻辑思维设计为与 CoT、自一致性和 ToT 等其他提示策略无缝整合。报告的评估表明，逻辑思维在 ReClor 基准测试上将 CoT 准确率提高了 4.35%，在 LogiQA 上结合自一致性的 CoT 提示提高了 5%，在 ProofWriter 数据集上进一步提升了 ToT 提示性能 8%。此外，通过在整个过程中保留自然语言表示，逻辑思维避免了其他神经符号系统（如 SatLM）中可能损害性能的符号提取错误。

#### 实例自适应提示（Instance-Adaptive Prompting, IAP）

Yuan 等人 [2024] 通过引入实例自适应提示（IAP），解决了零样本 CoT 推理中静态任务级提示（例如“让我们一步步思考”）的泛化限制，这是一个基于显着性驱动的框架，旨在动态调整提示以适应单个实例。通过对注意力层的信息流分析，作者识别出不同的模式：有效推理与浅层中从问题到提示的强烈语义流以及深层中从整合的问题-提示表示到推理的流相关。相比之下，碎片化或弱流表明推理性能次优。IAP 通过两种自适应策略优化推理保真度。第一种，IAP-ss（顺序替换），通过迭代测试提示直到满足预定义的显着性阈值来提高效率。第二种，IAP-mv（多数投票），通过聚合同多个提示的显着性分数来确定共识答案，以优先考虑鲁棒性。实证评估强调了 IAP 的广泛适用性：在数学推理任务（GSM8K、SVAMP）中，IAP-mv 分别将 LLaMA-3-8B 和 Qwen-14B 的性能提高了 +1.82% 和 +3.31%，相比于静态提示。在因果判断任务上，IAP 实现了 19.25% 的准确率，优于基线的 16.04%，并在 MMLU 常识推理任务上使用 Qwen-14B 比 Self-Discover 高出 +21.7%。

#### 端到端 DAG 路径（End-to-End DAG-Path, EEDP）提示

端到端 DAG 路径（EEDP）提示 [Hong et al., 2024] 解决了传统图展平方法（例如邻接列表和边列表）在图相关任务中长距离推理的局限性。EEDP 的关键见解是，传统展平表示常常丢失对有效推理至关重要的长距离依赖关系。为了缓解这一问题，EEDP 优先考虑连接图端点（入度或出度为零的节点）的主干路径，同时保留邻接列表以维护局部上下文信息。EEDP 框架通过三个关键阶段运行：(1) 使用广度优先搜索（BFS）将输入图预处理为有向无环图（DAGs），以消除循环；(2) 提取端点之间的层次路径；(3) 使用差分指针算法压缩共享路径段，有效将分子图的 token 长度减少了 55%。EEDP 在边缘预测连接性预测（EPCP）和边缘预测距离预测（EPDP）任务上进行了评估，使用了教育（Merged_1000）和分子（ZINC_test_2500）数据集。评估结果显示，相比传统基线，EPCP 在 Merged_1000 上提高了 +10.21% 的准确率，在 ZINC_test_2500 上提高了 +16.76%。类似地，EPDP 在 Merged_1000 上提高了 +4.73% 的准确率，在 ZINC_test_2500 上提高了 +30.13%。

#### 思维层（Layer-of-Thoughts, LoT）提示

LLMs 在许多推理任务中表现出色，但在精确度-召回率权衡和可解释性方面常常面临挑战，特别是在复杂的法律检索场景中。思维层（LoT）提示 [Fungwacharakorn et al., 2024] 引入了一个层次框架，利用约束层次结构来结构化推理过程，从而增强检索准确性和可解释性。在法律文档检索的背景下，LoT 将推理组织为“层思维”（概念阶段）和“选项思维”（部分解决方案），应用顺序约束以迭代过滤和精炼候选响应。例如，该框架采用三层过程：(1) 关键词过滤层（KFL），提取 LLM 生成的关键词以使用至少 k 个等指标初步过滤文档；(2) 语义过滤层（SFL），根据多级相关性标准和聚合指标优先级排序文档；(3) 最终确认层（FCL），根据原始查询验证剩余候选者。通过整合硬约束（必需）和软约束（优先），LoT 不仅提供了可解释的推理，还超越了最先进的模型，例如在日本民法检索中实现了 0.835 的 F2 分数（精确度 0.838，召回率 0.839），相比 JNLP 的 0.807，在德国交通法背景下达到了近乎完美的召回率（0.966）。

#### 叙述思维（Narrative-of-Thought, NoT）提示

时间推理仍然是 LLMs 的重大挑战，特别是在从无序事件推断全局时间关系方面。为了评估这种能力，Zhang 等人 [2024] 引入了时间图生成（TGG）基准，旨在评估 LLMs 构建表示事件时间线的有向无环图（DAGs）的熟练程度。实验结果显示，小型 LLMs（<10B）比 GPT-3.5/4 落后约 50%，即使 GPT-4 也因对齐约束而面临困难。为了克服这些限制，作者提出了叙述思维（NoT），这是一种无需额外模型训练即可增强时间推理的提示策略。NoT 包括三个核心组件：(1) 结构表示，将事件封装在 Python 类中并通过代码补全处理；(2) NoT 提示模板，生成时间上基于的叙述以指导时间图的构建；(3) 叙述感知示范，利用 GPT-4 生成的少样本示例，优化简洁性和准确性。结果表明，NoT 显著提高了小型 LLMs 的性能，LLaMA3-8B 实现了 42.2 的 F1 分数，接近 GPT-3.5 的 45.7，同时表现出更高的结构连贯性。

#### 思维缓冲（Buffer of Thoughts, BoT）提示

现有提示方法常常难以平衡复杂推理中的通用性、效率和鲁棒性。为解决这一问题，Yang 等人 [2024] 引入了思维缓冲（BoT），这是一个通过可重用的高级推理模式增强 LLMs 的框架。BoT 克服了单查询方法（例如依赖手动示例）和多查询方法（例如计算效率低下）的局限性，引入了一个元缓冲区，从多样化任务中提炼“思维模板”，以及一个动态缓冲区管理器，随着新问题的解决持续精炼它们。BoT 检索特定任务的思维模板（例如结构化的问题解决方法）并自适应地实例化它们，模仿人类类比推理，消除手动提示设计和递归探索的需要。在 10 个基准测试上的实验展示了其最先进的性能，在 24 点游戏上提高了 11%，在几何形状上提高了 20%，在一步将死任务上提高了 51%，同时仅使用了 Tree-of-Thoughts 等多查询方法 12% 的计算成本。值得注意的是，BoT 增强了小型模型，Llama3-8B + BoT 在准确率上超过了 Llama3-70B，显示出其在规模化高效推理方面的潜力。

#### 对比去噪思维链（Contrastive Denoising with Noisy Chain-of-Thought, CD-CoT）提示

对比去噪思维链（CD-CoT）[Zhou et al., 2024] 解决了思维链提示中的“噪声推理”问题，即无关或错误的中间推理步骤降低了 LLM 性能。NoRa（噪声推理）数据集突显了这一问题，显示 LLMs 在有缺陷推理的情况下通常比无示例时表现更差，因为它们倾向于模仿错误推理。现有方法如自我校正和自一致性提供了有限的解决方案，因为自我校正在无外部反馈时失效，而自一致性选择常见答案而无法解决推理缺陷。CD-CoT 通过对比噪声推理和干净推理来缓解这一问题，重述有缺陷的示例，选择最佳推理路径，并对最一致的答案进行投票。实验表明，CD-CoT 平均提高了 17.8% 的准确率，显著优于基线，并增强了 LLMs 在推理密集型任务中的鲁棒性。

#### 逆向思维链（Reverse Chain-of-Thought, R-CoT）提示

Deng 等人 [2024] 提出了逆向思维链（R-CoT）流水线，这是一种增强 LMMs 几何推理的新方法，解决了数据集质量低、多样性不足和保真度不足等问题。R-CoT 在两个阶段运行：GeoChain，生成高保真几何图像，带有详细的几何关系（例如中线、半径）逐步描述；逆向问答（Reverse A&Q），使用 LLMs 从推理链中推导问题，确保准确的多步问题生成。通过优先考虑答案感知的问题合成，R-CoT 缓解了视觉幻觉和推理错误。生成的 GeoMM 数据集包括按复杂性分类的 20 个几何形状，包含现有数据集（如 MAVIS 和 GeomVerse）中常常缺失的关系问题。GeoMM 结合了高保真图像和多样化的问答对，丰富了几何定理和线操作。实验结果表明，R-CoT 训练的模型实现了最先进的性能，8B 参数模型在 MathVista 上比 GPT-4o 高出 12.5%，在 GeoQA 上高出 14.5%，而较小模型（2B、7B）也设定了新基准。

#### 草稿链（Chain of Draft, CoD）提示

草稿链（CoD）[Xu et al., 2025] 是一种旨在增强复杂推理任务效率的新提示策略。与强调详细逐步推理的传统 CoT 提示不同，CoD 在每一步生成简洁、信息密集的输出，模仿人类问题解决策略，仅记录关键见解。虽然 CoT 提高了推理准确性，但往往导致冗长的输出和增加的计算成本。CoD 通过约束每一步推理的词语使用量来缓解这一问题，降低了延迟和 token 消耗，同时不牺牲准确性。这种以效率为导向的方法对于计算资源和响应时间至关重要的现实应用特别有价值。在算术、常识和符号推理基准测试上的实验结果表明，CoD 在准确性上匹配甚至优于 CoT，同时显著降低了 token 使用量和延迟。在某些情况下，CoD 实现了相似的准确性，同时输出 token 减少了 80%，平均延迟降低了 76.2%，展示了其作为传统提示策略的轻量级但有效的替代方案的潜力。

### 2.3 减少幻觉

#### 检索增强生成（Retrieval Augmented Generation, RAG）

LLMs 革新了文本生成，但其依赖有限的静态训练数据阻碍了准确响应，特别是在需要外部知识的任务中。传统提示方法不足以应对，需要昂贵的重新训练。检索增强生成（RAG）[Lewis et al., 2020] 作为一种新颖的解决方案出现，将信息检索无缝融入提示过程。RAG 分析用户输入，构建目标查询，并在预构建的知识库中搜索相关资源。检索到的片段被纳入原始提示，丰富了上下文背景。增强的提示使 LLM 能够生成创意且事实准确的响应。RAG 的敏捷性克服了静态限制，使其成为需要最新知识的任务的游戏规则改变者。RAG 在 ODQA 基准测试上优于 seq2seq 模型和任务特定架构，在 TriviaQA 上达到 56.8% 的精确匹配分数，在 Natural Questions 上达到 44.5%。

#### ReAct 提示

与之前将推理和行动分开处理的研究不同，ReAct [Yao et al., 2022] 使 LLMs 能够同时生成推理轨迹和任务特定行动。这一交错过程增强了推理和行动之间的协同作用，促进模型诱导、跟踪和更新行动计划，同时处理异常。ReAct 应用于多样化的语言和决策任务，展示了其优于最先进基线的有效性。特别是在问答（HotpotQA）和事实验证（Fever）中，ReAct 通过与简单的 Wikipedia API 交互，解决了幻觉和错误传播问题，产生了更可解释的任务解决轨迹。此外，在交互式决策基准如 ALFWorld 和 WebShop 中，ReAct 超越了模仿和强化学习方法，分别实现了 34% 和 10% 的显著成功率，仅使用最少的上下文示例。

#### 验证链（Chain-of-Verification, CoVe）提示

为解决 LLMs 中的幻觉问题，Dhuliawala 等人 [2023] 提出了验证链（CoVe），这是一个系统化的四步过程，包括模型生成基线响应、规划验证问题以检查其工作、独立回答问题，并结合验证生成修订响应。通过这种深思熟虑的多步方法验证其工作，LLM 增强了逻辑推理能力并减少了错误，即使面对矛盾信息。CoVe 模仿人类验证以增强 LLM 输出的连贯性和精确性。在列表问题、问答和长篇生成上的实验表明，CoVe 减少了幻觉，同时保持事实 [Sahoo et al., 2024]。专注的验证问题帮助模型识别和纠正其不准确性。

#### 笔记链（Chain-of-Note, CoN）提示

检索增强语言模型（RALMs）通过融入外部知识增强大型语言模型，以减少事实幻觉。然而，检索信息的可靠性无法保证，可能导致误导性响应。标准 RALMs 难以评估其知识充足性，并且在缺乏信息时往往无法以“未知”响应。为解决这些挑战，Yu 等人 [2023] 提出了一种新方法，通过处理噪声、不相关的文档并准确应对未知场景来提高 RALMs 的鲁棒性。CoN 系统地评估文档相关性，强调关键且可靠的信息以过滤无关内容，从而生成更精确且与上下文相关的响应。在多样化的开放域问答数据集上的测试展示了显著的改进，包括在噪声检索文档上的精确匹配分数平均提高了 +7.9，在超出预训练知识的问题拒绝率上提高了 +10.5。

#### 知识链（Chain-of-Knowledge, CoK）提示

传统提示技术对于 LLMs 处理基本任务非常有效。然而，由于复杂推理挑战，其效能下降，常常导致不可靠的输出，受到事实幻觉和不透明思维过程的困扰。这种限制源于其依赖固定知识源、无效的结构化查询生成以及缺乏逐步校正，无法充分引导 LLM。受人类问题解决的启发，CoK [Li et al., 2023d] 将复杂任务系统地分解为协调良好的步骤。该过程始于全面的推理准备阶段，建立上下文并框定问题。随后，它进入动态知识适应阶段，从内部知识库、外部数据库和给定提示等各种来源精心收集证据。

### 2.4 用户交互

#### 主动提示（Active Prompting）

Diao 等人 [2023] 提出了主动提示（Active-Prompt），作为适应 LLMs 多样化推理任务的解决方案。他们通过提出主动提示来增强 LLMs 在复杂问答任务上的性能，通过任务特定示例提示结合思维链（CoT）推理。与依赖固定的人工注释示例集的现有 CoT 方法不同，主动提示引入了一种机制，用于确定对注释最具影响的问题。受基于不确定性的主动学习的启发，该方法使用各种指标来表征不确定性，并选择最不确定的问题进行注释。主动提示在 text-davinci-002 和 code-davinci-002 上分别比自一致性平均提高了 7.0% 和 1.8%，在八个复杂推理任务上展示了最先进的成果。

### 2.5 微调与优化

#### 自动提示工程师（Automatic Prompt Engineer, APE）

虽然为 LLMs 制作有效提示传统上是专家注释者的繁重任务，Zhou 等人 [2022] 提出了自动提示工程师（APE），作为一种自动生成和选择指令的创新方法。APE 摆脱了静态、手工设计提示的限制，动态生成并选择针对特定任务的最有效提示。这种巧妙的方法分析用户输入，制作候选指令，然后利用强化学习选择最佳提示，动态适应不同上下文。在多样化的 BIG-Bench 套件和 CoT 推理任务上的广泛测试显示，APE 的能力超过了人类创作的提示，在 24 个任务中的 19 个中表现更好，并显著提升了 LLMs 的推理能力。这一自动提示工程的突破为 LLMs 以更高效率和适应性处理更广泛任务铺平了道路，释放了其在多样化应用中的全部潜力。

### 2.6 基于知识的推理与生成

#### 自动推理与工具使用（Automatic Reasoning and Tool-use, ART）

有限的推理能力和缺乏外部工具使用阻碍了 LLMs 在复杂任务中的潜力。Paranjape 等人 [2023] 提出了自动推理与工具使用（ART），以解决这一关键障碍，使 LLMs 能够通过多步过程推理并无缝整合外部专长。ART 弥合了推理差距，使 LLMs 能够处理复杂问题并扩展到简单文本生成之外。通过整合用于专业知识和计算的外部工具，ART 释放了前所未有的多功能性，并为 LLM 输出注入了现实世界的相关性。这使 LLMs 能够为科学研究、数据分析甚至决策支持等多样化领域做出贡献。超越传统提示技术，ART 通过结构化程序自动化推理步骤，消除了繁重的手工制作需求。其动态工具整合确保了顺畅的协作，暂停生成以纳入外部工具输出并无缝恢复流程。在具有挑战性的基准（Big-Bench 和 MMLU）上的实证证据展示了 ART 的有效性，超越了传统提示，甚至在某些情况下与手工制作的示范相匹配。

### 2.7 提高一致性与连贯性

#### 对比思维链（Contrastive Chain-of-Thought, CCoT）提示

传统 CoT 提示常常忽略了一个关键因素：从错误中学习。对比思维链（CCoT）提示 [Chia et al., 2023] 解决了这一问题，提供有效和无效的推理示范以及原始提示。想象一个地图，标出了正确路径和需要避免的错误转弯——这是对比 CoT 的优势！这种双重视角方法在 SQuAD 和 COPA 等推理基准测试上进行了测试，推动 LLMs 进行逐步推理，与传统 CoT 相比，在战略和数学推理评估中提高了 4-16%，结合自一致性技术进一步提高了约 5%。然而，关于该技术的问题仍然存在，例如为多样化问题自动生成对比示范以及其在推理之外的其他 NLP 任务中的适用性。

### 2.8 管理情感与语气

#### 情感提示（Emotion Prompting）

虽然 LLMs 在各种任务上展示了令人印象深刻的能力，但它们理解心理和情感线索的能力仍不确定。Li 等人 [2023a] 通过提出情感提示（EmotionPrompt）解决了 LLMs 理解情感线索的不确定性。受语言对人类表现影响的心理学研究的启发，他们在提示中附加了 11 个情感刺激句子，以增强 LLM 的情感智能。实验结果表明，这些刺激的无缝整合显著提高了 LLMs 在各种任务中的性能。情感提示在指令归纳中展示了 8.00% 的相对改进，在 BIG-Bench 任务中实现了 115% 的惊人提升，凸显了其在增强 LLMs 处理情感信号能力方面的效能。涉及 106 名参与者的评估显示，使用情感提示与标准提示相比，在生成任务的性能、真实性和责任感指标上平均提高了 10.9%。

### 2.9 代码生成与执行

#### 草稿提示（Scratchpad Prompting）

尽管基于 Transformer 的语言模型在生成基本编程任务代码方面表现出色，但在需要精确推理的复杂、多步算法计算中遇到挑战。针对这一问题，Nye 等人 [2021] 提出了一个以任务设计为中心而非模型修改的新方法，引入了“草稿”概念。该提案使模型能够在提供最终答案之前生成任意中间 token 序列。草稿提示技术在（主要为基本 Python 编程）MBPP-aug 上表现优异，成功率为 46.8%。结合 CodeNet 和单行数据集实现了最高性能，正确最终输出的比例为 26.6%，完美轨迹为 24.6%。草稿提示技术面临限制，包括固定上下文窗口大小为 512 个 token 以及对监督学习的依赖以利用草稿。

#### 思维程序（Program of Thoughts, PoT）提示

由于容易出现算术错误、无法处理复杂方程以及表达广泛迭代的低效性，语言模型在解决数学表达式方面表现不佳。为了增强语言模型的数值推理能力，Chen 等人 [2022] 提出了思维程序（PoT）提示，倡导使用外部语言解释器进行计算步骤。PoT 使 Codex 等模型通过可执行的 Python 程序表达推理，与涉及数学文字问题和财务问题的数据集上的 CoT 提示相比，平均性能提高了约 12%。

#### 结构化思维链（Structured Chain-of-Thought, SCoT）提示

LLMs 在代码生成方面展示了令人印象深刻的熟练程度。广泛使用的 CoT 提示涉及在生成代码之前生成中间自然语言推理步骤。尽管在自然语言生成中有效，但 CoT 提示在代码生成任务中的准确性较低。Li 等人 [2023c] 提出了结构化思维链（SCoT），这是一种专门为代码生成量身定制的创新提示技术。通过将程序结构（顺序、分支和循环结构）纳入推理步骤，SCoT 提示增强了 LLMs 生成结构化源代码的性能。这种方法明确引导 LLMs 从源代码的角度考虑需求，相比 CoT 提示提高了其在代码生成中的整体有效性。作者在 ChatGPT 和 Codex 上验证了 SCoT 在三个基准（HumanEval、MBPP 和 MBCPP）上的有效性，展示了比 CoT 提示高出高达 13.79% 的优越性能。

#### 代码链（Chain of Code, CoC）提示

虽然 CoT 提示在增强语言模型（LMs）的语义推理技能方面非常有效，但在处理需要数值或符号推理的问题时表现不佳。Li 等人 [2023b] 提出了代码链（CoC），作为改进 LM 推理的扩展，通过利用代码编写处理逻辑和语义任务。CoC 鼓励 LMs 将语义子任务格式化为灵活的伪代码，允许解释器捕获未定义行为并使用“LMulator”模拟它们。实验表明，CoC 优于思维链和其他基线，在 BIG-Bench Hard 上实现了 84% 的准确率，提高了 12%。CoC 对大型和小型模型均有效，通过融入“代码思考”方法扩展了 LMs 正确回答推理问题的能力。

### 2.10 优化与效率

#### 提示优化（Optimization by Prompting, OPRO）

在各个领域，优化是一个基本过程，常常涉及迭代技术。Yang 等人 [2023] 提出了提示优化（OPRO），这是一种利用 LLMs 作为优化器的新方法。与传统方法不同，OPRO 利用自然语言提示迭代生成基于问题描述的解决方案，实现了对不同任务的快速适应和优化过程的定制。LLMs 在优化方面的潜力通过经典问题如线性回归和旅行推销员问题的案例研究得到展示。此外，它探索了优化提示以最大化自然语言处理任务的准确性，突出了 LLMs 的敏感性。实验表明，在小型训练集上优化提示的准确性有效转化为测试集上的高性能。OPRO 带来了显著的性能提升，由 OPRO 优化的最有效提示在 GSM8K 数据集上比人类设计的提示高出高达 8%，在具有挑战性的 Big-Bench 任务上高出高达 50%。

### 2.11 理解用户意图

#### 重述与响应（Rephrase and Respond, RaR）提示

Deng 等人 [2023] 的研究关注了探索 LLMs 中一个常常被忽视的维度：人类思维框架与 LLMs 之间的差异，并引入了重述与响应（RaR）。RaR 允许 LLMs 在单一提示中重述和扩展问题，展示了改进的理解和响应准确性。包含重述和响应 LLMs 的两步 RaR 变体在各种任务中实现了显著的性能增强。研究强调，与随意提出的人类查询相比，重述的问题有助于增强语义清晰度和解决固有的歧义。这些发现为理解和增强 LLMs 在各种应用中的效能提供了宝贵的见解。

### 2.12 元认知与自我反思

#### 退后一步（Take a Step Back）提示

针对复杂多步推理的持续挑战，Zheng 等人 [2023] 提出了退后一步提示技术，专为 PaLM-2L 等高级语言模型量身定制。这种创新方法使模型能够进行抽象，从具体实例中提取高级概念和基本原理。退后一步提示方法涉及两步程序，整合抽象和推理。通过在 STEM、知识问答和多跳推理等推理密集型任务中的广泛实验，应用退后一步提示到 PaLM-2L 的结果展示了推理能力的显著增强。显著的性能提升在 MMLU 物理和化学任务中提高了 7%，在 TimeQA 上提高了 27%，在 MuSiQue 上提高了 7%。

## 3 结论

在人工智能领域，提示工程已成为一股变革性力量，释放了 LLMs 的巨大潜力。本综述论文旨在作为系统分类 41 种不同提示工程技术的基础资源，根据其目标功能进行分类，激励进一步研究并赋能提示工程演变景观中的创新者。分析涵盖了应用、模型和数据集，阐明了每种方法的优势和局限性。此外，我们添加了一个图表和表格以突出重要要点。尽管取得了显著的成功，挑战依然存在，包括偏见、事实不准确性和可解释性差距，需要进一步调查和缓解策略。提示工程的未来潜力巨大，新兴趋势如元学习和混合提示架构有望放大能力。然而，道德考虑至关重要，强调负责任的开发和部署，以确保积极融入我们的生活。

![图 2：LLMs 中提示工程技术的分类，按应用领域组织，为跨多样化上下文定制提示提供了细致的框架。](attachment://figure2.png)

**表 1：基于应用、提示获取、提示轮次、语言模型、数据集和指标的 LLM 常见提示技术总结**

| 应用领域             | 提示技术 | 比较范围 | 提示获取 | 提示轮次                              | 语言模型                                             | 数据集                             | 指标 |
| -------------------- | -------- | -------- | -------- | ------------------------------------- | ---------------------------------------------------- | ---------------------------------- | ---- |
| 无需训练数据的新任务 | 零样本   | 手动     | 单轮     | GPT-2                                 | 算术，符号                                           | 准确率，ROUGE 分数                 |      |
|                      | 少样本   | 手动     | 单轮     | GPT-3                                 | NaturalQS, WebQS, TriviaQA                           | 准确率                             |      |
| 推理与逻辑           | CoT      | 手动     | 多轮     | PaLM 540B                             | GSM8K                                                | 准确率                             |      |
|                      | LogiCoT  | 手动     | 多轮     | Vicuna-33b, GPT-4                     | GSM8K, AQuA, SocialQA                                | 准确率                             |      |
|                      | CoS      | 手动     | 多轮     | gpt-3.5-turbo, GPT-4                  | SPARTUN                                              | 准确率，精确度，召回率             |      |
|                      | Auto-CoT | LM 生成  | 多轮     | GPT-3                                 | 算术，符号                                           | 准确率                             |      |
|                      | 自一致性 | 手动     | 单轮     | PaLM 540B                             | 算术，常识                                           | 准确率                             |      |
|                      | ToT      | 基于检索 | 多轮     | GPT-4                                 | 24 点游戏，创意写作                                  | 成功率                             |      |
|                      | GoT      | 基于检索 | 多轮     | T5-large                              | GSM8K, ScienceQA                                     | ROUGE 分数                         |      |
|                      | S2A      | 手动     | 单轮     | Llama 2-70B                           | 问答，GSM8K                                          | 准确率                             |      |
|                      | ThoT     | 混合     | 多轮     | gpt-3.5-turbo, Llama 2-70b-chat       | PopQA, EntityQ, MTCR                                 | 精确匹配（EM）分数                 |      |
|                      | 表格链   | 手动     | 多轮     | GPT 3.5, LLaMA 2                      | TabFact, WikiTQ                                      | BLEU, ROUGE 分数                   |      |
|                      | 自精炼   | 手动     | 多轮     | GPT-3.5, GPT-4                        | 7 个多样化任务（例如对话响应，数学推理）             | 任务特定（准确率，人类偏好）       |      |
|                      | 代码提示 | LM 生成  | 多轮     | GPT 3.5, Mixtral                      | CondQA, ShaRC, BGQA                                  | F1                                 |      |
|                      | ECHO     | 混合     | 多轮     | gpt-3.5-Turbo-0301                    | 算术，常识，符号                                     | 准确率                             |      |
|                      | 逻辑思维 | LM 生成  | 多轮     | GPT 3.5-turbo, GPT-4                  | ReClor, LogiQA, RuleTaker, ProofWriter, FOLIO        | 准确率                             |      |
|                      | IAP      | 手动     | 多轮     | LLaMA-3-8B-Instruct, Qwen-14B-Chat    | 数学，逻辑，常识                                     | 准确率                             |      |
|                      | EEDP     | 手动     | 单轮     | GPT-4-turbo                           | Merged 1000, ZINC test 2500                          | 准确率                             |      |
|                      | LoT      | LM 生成  | 多轮     | GPT-4o                                | 日本民法，规范句子                                   | 精确度，召回率，F2                 |      |
|                      | NoT      | LM 生成  | 单轮     | GPT-3.5, GPT-4, Mistral-7B, LLaMA3-8B | ProScript, Schema-11, WikiHow Script                 | F1, GED                            |      |
|                      | BoT      | LM 生成  | 多轮     | Llama3-8B, Llama3-70B                 | 10 个推理密集型任务（例如 24 点游戏，几何形状）      | 准确率                             |      |
|                      | CD-CoT   | 手动     | 单轮     | gpt-3.5-turbo-0613, Gemini-Pro（等）  | 多个任务（例如 BIG-Bench 子集，常识问答等）          | 准确率，解决率，人类偏好           |      |
|                      | R-CoT    | 手动     | 单轮     | GPT4o, R-CoT-8B（等）                 | GeoMM, MathVista, GeoQA                              | 准确率                             |      |
|                      | CoD      | 混合     | 单轮     | GPT-4o, Claude 3.5 Sonnet             | 算术，常识，符号                                     | 准确率                             |      |
| 减少幻觉             | CoVe     | 基于检索 | 多轮     | Llama 65B                             | Wikidata, QUEST, MultiSpanQA                         | 精确度，F1                         |      |
|                      | ReAct    | 基于检索 | 多轮     | PaLM-540B, GPT-3                      | HotpotQA, FEVER                                      | 精确匹配（EM），准确率             |      |
|                      | RAG      | 基于检索 | 单轮     | RAG-Token, RAG-Seq                    | MSMARCO, SearchQA                                    | ROUGE, BLEU 分数                   |      |
|                      | CoN      | LM 生成  | 多轮     | Llama 2, DPR                          | NQ, TriviaQA, WebQ                                   | 精确匹配（EM），F1 分数            |      |
|                      | CoK      | LM 生成  | 多轮     | gpt-3.5-turbo-0613                    | HotpotQA, FEVER, MedMCQA, MMLU 物理和生物            | 精确匹配（EM），准确率             |      |
| 用户交互             | 主动提示 | 手动     | 单轮     | code-davinci-002, text-davinci-003    | 算术，常识，符号                                     | 不一致性，熵方差，自我置信度分数   |      |
| 微调与优化           | APE      | LM 生成  | 单轮     | text-curie-001, text-davanci-002      | BBII, TruthfulQA                                     | 执行准确率，对数概率，高效分数估计 |      |
| 基于知识的推理与生成 | ART      | 混合     | 多轮     | GPT-3 (175B)                          | BigBench, MMLU                                       | 准确率                             |      |
| 提高一致性与连贯性   | CCoT     | LM 生成  | 多轮     | gpt-3.5-turbo-0301                    | 算术，事实问答                                       | 准确率                             |      |
| 管理情感与语气       | 情感提示 | 手动     | 单轮     | GPT-4                                 | BIG-Bench，指令归纳                                  | 准确率                             |      |
| 代码生成与执行       | SCoT     | 混合     | 多轮     | ChatGPT, Codex                        | HumanEval, MBPP, MBCPP                               | pass@k                             |      |
|                      | PoT      | 手动     | 单轮     | gpt-3.5-turbo                         | GSM8K, SVAMP, FinQA                                  | 精确匹配（EM）分数                 |      |
|                      | CoC      | 手动     | 单轮     | text-davinci-003, gpt-3.5-turbo       | BIG-Bench Hard                                       | 准确率                             |      |
|                      | 草稿提示 | 手动     | 单轮     | GPT-3                                 | MBPP, MBPP-aug                                       | 准确率                             |      |
| 优化与效率           | OPRO     | 手动     | 单轮     | PaLM 2-L-IT, text-bison               | GSM8K, BIG-Bench Hard                                | 准确率                             |      |
| 理解用户意图         | RaR      | 手动     | 单轮     | GPT-4-0613                            | 知识，符号                                           | 准确率，公平分数，语言建模分数     |      |
| 元认知与自我反思     | 退后一步 | 手动     | 单轮     | PaLM2-L, GPT-4                        | MMLU-物理，MMLU-化学，TimeQA，SituatedQA，StrategyQA | 准确率                             |      |

## 参考文献

1. **Bahng 等人 (2022)**
   Bahng, H., Jahanian, A., Sankaranarayanan, S., 和 Isola, P. 探索视觉提示以适应大规模模型。*arXiv 预印本 arXiv:2203.17274*，2022。
2. **Brown 等人 (2020)**
   Brown, T. B., Mann, B., Ryder, N., 等。语言模型是少样本学习者。*2020*。
3. **Chen 等人 (2022)**
   Chen, W., Ma, X., Wang, X., 和 Cohen, W. W. 思维程序提示：为数值推理任务解耦计算与推理。*arXiv 预印本 arXiv:2211.12588*，2022。
4. **Chen 等人 (2023)**
   Chen, B., Zhang, Z., Langrené, N., 和 Zhu, S. 释放大型语言模型提示工程的潜力：全面综述。*arXiv 预印本 arXiv:2310.14735*，2023。
5. **Chia 等人 (2023)**
   Chia, Y. K., Chen, G., Tuan, L. A., Poria, S., 和 Bing, L. 对比思维链提示。*arXiv 预印本 arXiv:2311.09277*，2023。
6. **Deng 等人 (2023)**
   Deng, Y., Zhang, W., Chen, Z., 和 Gu, Q. 重述与响应：让大型语言模型为自己提出更好的问题。*arXiv 预印本 arXiv:2311.04205*，2023。
7. **Deng 等人 (2024)**
   Deng, L., Liu, Y., Li, B., 等。R-CoT：用于大型多模态模型几何推理的逆向思维链问题生成。*2024*。
8. **Dhuliawala 等人 (2023)**
   Dhuliawala, S., Komeili, M., Xu, J., 等。验证链减少大型语言模型中的幻觉。*arXiv 预印本 arXiv:2309.11495*，2023。
9. **Diao 等人 (2023)**
   Diao, S., Wang, P., Lin, Y., 和 Zhang, T. 主动提示与大型语言模型的思维链。*arXiv 预印本 arXiv:2302.12246*，2023。
10. **Fungwacharakorn 等人 (2024)**
    Fungwacharakorn, W., Thanh, N. H., Zin, M. M., 和 Satoh, K. 思维层提示（LoT）：利用基于 LLM 的检索与约束层次结构。*2024*。
11. **Hong 等人 (2024)**
    Hong, B., Wu, J., Liu, J., 等。用于大型语言模型的端到端图展平方法。*2024*。
12. **Hu 等人 (2023)**
    Hu, H., Lu, H., Zhang, H., 等。符号链提示在大型语言模型中引发规划。*2023*。
13. **Lewis 等人 (2020)**
    Lewis, P., Perez, E., Piktus, A., 等。检索增强生成用于知识密集型 NLP 任务。*神经信息处理系统进展*，33：9459–9474，2020。
14. **Li 等人 (2023a)**
    Li, C., Wang, J., Zhang, Y., 等。大型语言模型理解并可通过情感刺激增强。*arXiv 预印本 arXiv:2307.11760*，2023。
15. **Li 等人 (2023b)**
    Li, C., Liang, J., Zeng, A., 等。代码链：使用语言模型增强的代码仿真器进行推理。*arXiv 预印本 arXiv:2312.04474*，2023。
16. **Li 等人 (2023c)**
    Li, J., Ge, G., Li, Y., 和 Jin, Z. 用于代码生成的结构化思维链提示。*arXiv 预印本 arXiv:2305.06599*，2023。
17. **Li 等人 (2023d)**
    Li, X., Zhao, R., Chia, Y. K., 等。知识链：通过异构源的动态知识适应为大型语言模型提供基础。*2023*。
18. **Liu 等人 (2023)**
    Liu, P., Yuan, W., Fu, J., 等。预训练、提示与预测：自然语言处理提示方法的系统综述。*ACM 计算综述*，55(9)：1–35，2023。
19. **Liu 等人 (2024)**
    Liu, T., Xu, W., Huang, W., 等。逻辑思维：为大型语言模型的完整推理注入逻辑。*2024*。
20. **Long (2023)**
    Long, J. 大型语言模型引导的思维树。*arXiv 预印本 arXiv:2305.08291*，2023。
21. **Madaan 等人 (2023)**
    Madaan, A., Tandon, N., Gupta, P., 等。自精炼：通过自我反馈进行迭代精炼。*2023*。
22. **Mekala 等人 (2024)**
    Mekala, R. R., Razeghi, Y., 和 Singh, S. ECHO 提示：指导模型重述查询以改进上下文学习。*2024*。
23. **Nye 等人 (2021)**
    Nye, M., Andreassen, A. J., Gur-Ari, G., 等。展示你的工作：使用语言模型进行中间计算的草稿。*arXiv 预印本 arXiv:2112.00114*，2021。
24. **Paranjape 等人 (2023)**
    Paranjape, B., Lundberg, S., Singh, S., 等。ART：用于大型语言模型的自动多步推理与工具使用。*arXiv 预印本 arXiv:2303.09014*，2023。
25. **Puerto 等人 (2024)**
    Puerto, H., Tutek, M., Aditya, S., 等。代码提示引发文本+代码 LLMs 的条件推理能力。*2024*。
26. **Radford 等人 (2019)**
    Radford, A., Wu, J., Child, R., 等。语言模型是无监督多任务学习者。*OpenAI 博客*，1(8)：9，2019。
27. **Sahoo 等人 (2024)**
    Sahoo, P., Meharia, P., Ghosh, A., 等。大型语言、图像、视频和音频基础模型中幻觉的全面综述。*计算语言学协会：EMNLP 2024 论文集*，页 11709–11724，2024。
28. **Tonmoy 等人 (2024)**
    Tonmoy, S. M., Zaman, S. M., Jain, V., 等。大型语言模型中幻觉缓解技术的全面综述。*arXiv 预印本 arXiv:2401.01313*，2024。
29. **Wang 等人 (2022)**
    Wang, X., Wei, J., Schuurmans, D., 等。自一致性改进语言模型中的思维链推理。*arXiv 预印本 arXiv:2203.11171*，2022。
30. **Wang 等人 (2024)**
    Wang, Z., Zhang, H., Li, C.-L., 等。表格链：用于表格理解的推理链中演变表格。*2024*。
31. **Wei 等人 (2022)**
    Wei, J., Wang, X., Schuurmans, D., 等。思维链提示引发大型语言模型中的推理。*神经信息处理系统进展*，35：24824–24837，2022。
32. **Weston 和 Sukhbaatar (2023)**
    Weston, J., 和 Sukhbaatar, S. 系统 2 注意力（你可能也需要）。*arXiv 预印本 arXiv:2311.11829*，2023。
33. **Wu 等人 (2023)**
    Wu, C., Yin, S., Qi, W., 等。视觉 ChatGPT：与视觉基础模型的交谈、绘画和编辑。*2023*。
34. **Xu 等人 (2025)**
    Xu, S., Xie, W., Zhao, L., 和 He, P. 草稿链：写得更少，思考更快。*2025*。
35. **Yang 等人 (2023)**
    Yang, C., Wang, X., Lu, Y., 等。大型语言模型作为优化器。*arXiv 预印本 arXiv:2309.03409*，2023。
36. **Yang 等人 (2024)**
    Yang, L., Yu, Z., Zhang, T., 等。思维缓冲：使用大型语言模型进行思维增强推理。*神经信息处理系统进展*，2024。
37. **Yao 等人 (2022)**
    Yao, S., Zhao, J., Yu, D., 等。ReAct：在语言模型中协同推理与行动。*arXiv 预印本 arXiv:2210.03629*，2022。
38. **Yao 等人 (2023a)**
    Yao, S., Yu, D., Zhao, J., 等。思维树：使用大型语言模型进行深思熟虑的问题解决。*arXiv 预印本 arXiv:2305.10601*，2023。
39. **Yao 等人 (2023b)**
    Yao, Y., Li, Z., 和 Zhao, H. 超越思维链，大型语言模型中的有效思维图推理。*arXiv 预印本 arXiv:2305.16582*，2023。
40. **Yu 等人 (2023)**
    Yu, W., Zhang, H., Pan, X., 等。笔记链：增强检索增强语言模型的鲁棒性。*2023*。
41. **Yuan 等人 (2024)**
    Yuan, X., Shen, C., Yan, S., 等。实例自适应零样本思维链提示。*2024*。
42. **Zhang 等人 (2022)**
    Zhang, Z., Zhang, A., Li, M., 和 Smola, A. 大型语言模型中的自动思维链提示。*arXiv 预印本 arXiv:2210.03493*，2022。
43. **Zhang 等人 (2024)**
    Zhang, X. F., Beauchamp, N., 和 Wang, L. 叙述思维：通过叙述叙述改进大型语言模型的时间推理。*2024*。
44. **Zhao 等人 (2023)**
    Zhao, X., Li, M., Lu, W., 等。通过逻辑增强大型语言模型的零样本思维链推理。*2023*。
45. **Zheng 等人 (2023)**
    Zheng, H. S., Mishra, S., Chen, X., 等。退后一步：通过抽象引发大型语言模型中的推理。*arXiv 预印本 arXiv:2310.06117*，2023。
46. **Zhou 等人 (2022)**
    Zhou, Y., Muresanu, A. I., Han, Z., 等。大型语言模型是人类级别的提示工程师。*arXiv 预印本 arXiv:2211.01910*，2022。
47. **Zhou 等人 (2023)**
    Zhou, Y., Geng, X., Shen, T., 等。思维线程解开混乱上下文。*arXiv 预印本 arXiv:2311.08734*，2023。
48. **Zhou 等人 (2024)**
    Zhou, Z., Tao, R., Zhu, J., 等。语言模型能否在带有噪声推理的思维链提示中进行鲁棒推理？*神经信息处理系统进展*，37：123846–123910，2024。