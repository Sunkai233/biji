# transformerä»£ç å®ä¾‹1

### {

### è‡ªå®šä¹‰ Transformer Block ç¤ºä¾‹

```python
import torch
import torch.nn as nn

class TransformerBlock(nn.Module):
    def __init__(self, embed_dim, num_heads, ff_dim, dropout=0.1):
        super(TransformerBlock, self).__init__()
        # å¤šå¤´æ³¨æ„åŠ›
        self.attention = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout)
        # å‰é¦ˆå±‚
        self.ffn = nn.Sequential(
            nn.Linear(embed_dim, ff_dim),
            nn.ReLU(),
            nn.Linear(ff_dim, embed_dim)
        )
        # å±‚å½’ä¸€åŒ–
        self.norm1 = nn.LayerNorm(embed_dim)
        self.norm2 = nn.LayerNorm(embed_dim)
        # dropout
        self.dropout = nn.Dropout(dropout)

    def forward(self, x):
        # x: [seq_len, batch_size, embed_dim]
        attn_output, _ = self.attention(x, x, x)  
        x = self.norm1(x + self.dropout(attn_output))  # æ®‹å·®è¿æ¥ + norm
        ffn_output = self.ffn(x)
        x = self.norm2(x + self.dropout(ffn_output))   # æ®‹å·®è¿æ¥ + norm
        return x
```

ğŸ‘‰ è¿™æ ·ä½ å°±æœ‰äº†ä¸€ä¸ªåŸºæœ¬çš„ **Transformer Encoder Block**ã€‚
 å¦‚æœè¦å †å å¤šä¸ªï¼Œå¯ä»¥ç”¨ `nn.ModuleList` åŒ…ä¸€å±‚ã€‚

### }

### {

## æ–‡æœ¬ Token ç¤ºä¾‹

```python
import torch
import torch.nn as nn

# å‡è®¾è¯è¡¨å¤§å°ä¸º 10000ï¼Œæ¯ä¸ª token æ˜ å°„åˆ° 512 ç»´å‘é‡ç©ºé—´
vocab_size = 10000
embed_dim = 512

# nn.Embedding å°±æ˜¯ä¸€ä¸ªæŸ¥è¡¨å±‚ï¼ŒæŠŠç´¢å¼•è½¬æˆå‘é‡
embedding = nn.Embedding(vocab_size, embed_dim)

# æ¨¡æ‹Ÿä¸€ä¸ªå¥å­ï¼šå‡è®¾åˆ†è¯åå¯¹åº”çš„ token id æ˜¯ [1, 5, 9, 7]
# è¿™é‡ŒåŠ äº† batch ç»´åº¦ï¼Œæ‰€ä»¥ shape = [batch=1, seq_len=4]
input_ids = torch.tensor([[1, 5, 9, 7]])  

# è¾“å…¥ embeddingï¼Œå¾—åˆ° token embeddings
# shape: [batch, seq_len, embed_dim] = [1, 4, 512]
token_embeddings = embedding(input_ids)
print(token_embeddings.shape)  # torch.Size([1, 4, 512])
```

------

## å›¾åƒ Token ç¤ºä¾‹ï¼ˆViTï¼‰

```python
# å‡è®¾è¾“å…¥å›¾åƒ shape: [B, C, H, W]
B, C, H, W = 1, 3, 32, 32
image = torch.randn(B, C, H, W)  # éšæœºä¸€å¼  32x32 å½©è‰²å›¾

patch_size = 16
embed_dim = 512

# unfold(2, 16, 16): åœ¨ H ç»´åº¦ä¸Šæ»‘çª—åˆ‡ patch
# unfold(3, 16, 16): åœ¨ W ç»´åº¦ä¸Šæ»‘çª—åˆ‡ patch
# è¾“å‡º shape: [B, C, H/16, W/16, 16, 16]
patches = image.unfold(2, patch_size, patch_size).unfold(3, patch_size, patch_size)

# æŠŠ patch å±•å¹³æˆå‘é‡
# flatten(2)ï¼šä»ç¬¬ 2 ç»´å¼€å§‹å±•å¹³ï¼Œå¾—åˆ°æ¯ä¸ª patch çš„åƒç´ å‘é‡
# shape: [B, C, num_patches_h, num_patches_w, patch_size*patch_size]
patch_tokens = patches.flatten(2)

# ä¸€ä¸ª patch çš„ç»´åº¦æ˜¯ C * patch_size^2
patch_dim = C * patch_size * patch_size

# ç”¨çº¿æ€§å±‚æŠŠ patch å‘é‡æ˜ å°„åˆ° embedding ç©ºé—´
linear_proj = nn.Linear(patch_dim, embed_dim)

# æ³¨æ„è¦ reshape æˆ [B, num_patches, patch_dim] å†æŠ•å½±
tokens = linear_proj(patch_tokens.view(B, -1, patch_dim))
print(tokens.shape)  # torch.Size([1, 4, 512]) (å› ä¸º 32/16=2, 2*2=4 ä¸ª patch)
```

------

## æ—¶é—´åºåˆ— Token ç¤ºä¾‹

```python
# å‡è®¾æ—¶é—´åºåˆ—ï¼šbatch=2, é•¿åº¦=100, ç‰¹å¾ç»´åº¦=1
time_series = torch.randn(2, 100, 1)

# æˆ‘ä»¬æŠŠåºåˆ—åˆ‡æˆçª—å£ï¼Œæ¯ä¸ªçª—å£é•¿åº¦=10
window_size = 10
num_windows = time_series.shape[1] // window_size  # = 10

# reshape: [batch, num_windows, window_size*feature_dim]
tokens = time_series.view(2, num_windows, -1)  # æ¯ä¸ªçª—å£æ˜¯ä¸€ä¸ª token
print(tokens.shape)  # torch.Size([2, 10, 10])

# æŠ•å½±åˆ° embedding ç©ºé—´
embed_dim = 64
proj = nn.Linear(window_size, embed_dim)
tokens = proj(tokens)
print(tokens.shape)  # torch.Size([2, 10, 64])
```

------

## ä½ç½®ç¼–ç  (Positional Encoding)

```python
class PositionalEncoding(nn.Module):
    def __init__(self, embed_dim, max_len=5000):
        super().__init__()
        
        # åˆå§‹åŒ–ä¸€ä¸ªä½ç½®ç¼–ç çŸ©é˜µ [max_len, embed_dim]
        pe = torch.zeros(max_len, embed_dim)
        
        # position: æ¯ä¸ªä½ç½®çš„ç´¢å¼•ï¼Œä» 0 åˆ° max_len-1
        # shape: [max_len, 1]
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        
        # div_term: æ§åˆ¶æ­£å¼¦/ä½™å¼¦å‡½æ•°çš„é¢‘ç‡
        # ç”¨å…¬å¼ 10000^(2i/d_model)ï¼Œè¿™é‡Œå– log å†å– exp
        div_term = torch.exp(
            torch.arange(0, embed_dim, 2).float() * 
            (-torch.log(torch.tensor(10000.0)) / embed_dim)
        )
        
        # å¶æ•°ä½ç½®ç”¨ sin
        pe[:, 0::2] = torch.sin(position * div_term)
        # å¥‡æ•°ä½ç½®ç”¨ cos
        pe[:, 1::2] = torch.cos(position * div_term)
        
        # å¢åŠ  batch ç»´åº¦ [max_len, 1, embed_dim]
        self.pe = pe.unsqueeze(1)
        
    def forward(self, x):
        # x shape: [seq_len, batch, embed_dim]
        # è¿”å›ï¼šè¾“å…¥åŠ ä¸Šä½ç½®ç¼–ç 
        return x + self.pe[:x.size(0)]

# æµ‹è¯•
embed_dim = 512
pos_encoding = PositionalEncoding(embed_dim)
x = torch.zeros(10, 2, embed_dim)  # seq_len=10, batch=2
out = pos_encoding(x)
print(out.shape)  # torch.Size([10, 2, 512])
```

------

âœ… æ€»ç»“ï¼š

1. **æ–‡æœ¬ token**ï¼šç”¨ `nn.Embedding`ã€‚
2. **å›¾åƒ token**ï¼šåˆ‡ patch â†’ flatten â†’ `nn.Linear`ã€‚
3. **æ—¶é—´åºåˆ— token**ï¼šåˆ‡çª—å£ â†’ flatten â†’ `nn.Linear`ã€‚
4. **ä½ç½®ç¼–ç **ï¼šç”¨ `sin/cos` ç»™åºåˆ—åŠ ä¸Šé¡ºåºä¿¡æ¯ã€‚

### }

### {

### PhysicsSolver ä¸­çš„ **P-Attention** æ”¹é€ äº†**Attention**æœºåˆ¶ï¼Œä½¿å…¶æ›´é€‚åˆ PDE åœºæ™¯ï¼š 

1. **è¾“å…¥ä¸åŒ**    - æ™®é€š Attention è¾“å…¥æ˜¯è‡ªç„¶è¯­è¨€åºåˆ—æˆ–æ—¶é—´åºåˆ—ã€‚   - P-Attention è¾“å…¥çš„æ˜¯ **ç‰©ç†è¾“å…¥ï¼ˆ$t,x,v$ï¼‰+ æ•°æ®è¾“å…¥** çš„æ··åˆåµŒå…¥ã€‚

2. **å½’ä¸€åŒ–æ–¹å¼ä¸åŒ**    - æ ‡å‡† Attention çš„åˆ†æ¯æ˜¯ $\sqrt{d_k}$ã€‚   - P-Attention ç”¨çš„æ˜¯ $||QK^T||_{l_2}$ï¼ˆL2 èŒƒæ•°å½’ä¸€åŒ–ï¼‰ã€‚   - è¿™æ ·å¯ä»¥æ›´ç¨³å®šåœ°å¤„ç† **é«˜ç»´è¿ç»­æ—¶ç©ºæ•°æ®**ï¼Œé¿å…æ•°å€¼è¿‡å¤§æˆ–è¿‡å°ã€‚     

   åœ¨pythonä½¿ç”¨torchæ¡†æ¶ä¸‹ï¼Œæ˜¯æ€ä¹ˆå®ç°çš„



#### æ ¸å¿ƒæ€è·¯

1. **è¾“å…¥å¤„ç†**

   - å‡è®¾æˆ‘ä»¬å·²ç»æœ‰äº† `phys_embed`ï¼ˆç‰©ç†è¾“å…¥ embeddingï¼Œä¾‹å¦‚ $[t, x, v]$ ç»è¿‡ MLPï¼‰
   - å’Œ `data_embed`ï¼ˆè§‚æµ‹/çŠ¶æ€æ•°æ® embeddingï¼‰ã€‚
   - å°†äºŒè€…æ‹¼æ¥åå¾—åˆ° `input_embed`ã€‚

2. **Q, K, V ç”Ÿæˆ**

   - ç”¨ `nn.Linear` ç”Ÿæˆ Q, K, V çŸ©é˜µã€‚

3. **P-Attention æ ¸å¿ƒ**

   - æ™®é€š Attention:

     ```python
     attn_scores = (Q @ K.transpose(-2, -1)) / math.sqrt(d_k)
     attn_weights = softmax(attn_scores, dim=-1)
     ```

   - P-Attention æ”¹é€ :

     ```python
     raw_scores = Q @ K.transpose(-2, -1)
     norm = torch.norm(raw_scores, p=2, dim=-1, keepdim=True) + 1e-8
     attn_scores = raw_scores / norm
     attn_weights = F.softmax(attn_scores, dim=-1)
     ```

------

#### PyTorch å®ç°

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class PAttention(nn.Module):
    def __init__(self, embed_dim, num_heads=1):
        super().__init__()
        self.embed_dim = embed_dim
        self.num_heads = num_heads
        assert embed_dim % num_heads == 0, "embed_dim å¿…é¡»èƒ½æ•´é™¤ num_heads"
        self.head_dim = embed_dim // num_heads
        
        # Q, K, V projection
        self.q_proj = nn.Linear(embed_dim, embed_dim)
        self.k_proj = nn.Linear(embed_dim, embed_dim)
        self.v_proj = nn.Linear(embed_dim, embed_dim)
        self.out_proj = nn.Linear(embed_dim, embed_dim)

    def forward(self, phys_embed, data_embed):
        """
        phys_embed: [B, N, Dp]  ç‰©ç†è¾“å…¥ (t,x,v)
        data_embed: [B, N, Dd]  æ•°æ®è¾“å…¥
        """
        # æ‹¼æ¥è¾“å…¥
        x = torch.cat([phys_embed, data_embed], dim=-1)  # [B, N, Dp+Dd]
        
        B, N, _ = x.shape
        
        # çº¿æ€§å˜æ¢
        Q = self.q_proj(x).view(B, N, self.num_heads, self.head_dim).transpose(1, 2)  # [B, H, N, d]
        K = self.k_proj(x).view(B, N, self.num_heads, self.head_dim).transpose(1, 2)  # [B, H, N, d]
        V = self.v_proj(x).view(B, N, self.num_heads, self.head_dim).transpose(1, 2)  # [B, H, N, d]
        
        # è®¡ç®—æ³¨æ„åŠ›åˆ†æ•° (æœªå½’ä¸€åŒ–)
        raw_scores = torch.matmul(Q, K.transpose(-2, -1))  # [B, H, N, N]
        
        # ä½¿ç”¨ L2 èŒƒæ•°å½’ä¸€åŒ– (ä»£æ›¿ sqrt(d_k))
        norm = torch.norm(raw_scores, p=2, dim=-1, keepdim=True) + 1e-8
        attn_scores = raw_scores / norm
        
        # softmax å¾—åˆ°æƒé‡
        attn_weights = F.softmax(attn_scores, dim=-1)  # [B, H, N, N]
        
        # åŠ æƒæ±‚å’Œ
        context = torch.matmul(attn_weights, V)  # [B, H, N, d]
        
        # æ‹¼å›
        context = context.transpose(1, 2).contiguous().view(B, N, self.embed_dim)
        
        return self.out_proj(context)
```

------

#### ä½¿ç”¨ç¤ºä¾‹

```python
B, N, Dp, Dd = 4, 16, 3, 8  # batch=4, åºåˆ—é•¿=16, ç‰©ç†ç»´åº¦=3, æ•°æ®ç»´åº¦=8
phys_embed = torch.randn(B, N, Dp)  # (t, x, v)
data_embed = torch.randn(B, N, Dd)

p_attn = PAttention(embed_dim=Dp+Dd, num_heads=2)
output = p_attn(phys_embed, data_embed)

print(output.shape)  # [4, 16, 11] (Dp+Dd)
```

### }

### {

### æ€ä¹ˆåœ¨ PyTorch é‡ŒæŠŠ Transformer èå…¥ iLQR æ¡†æ¶

#### å®ç°æ€è·¯

1. **iLQR åŸå§‹æµç¨‹**
   - Forward passï¼šç»™å®šè¾“å…¥åºåˆ— $u_{0:T-1}$ï¼Œæ¨¡æ‹Ÿç³»ç»ŸåŠ¨åŠ›å­¦ï¼Œå¾—åˆ° $x_{0:T}$ã€‚
   - Backward passï¼šé€’æ¨è®¡ç®—åé¦ˆ/å‰é¦ˆå¢ç›Š $K_t, k_t$ã€‚è¿™æ˜¯æœ€è€—æ—¶çš„éƒ¨åˆ†ã€‚
2. **æ”¹é€ åçš„æµç¨‹**
   - **éƒ¨åˆ†åå‘è¿‡ç¨‹**ï¼šåªè®¡ç®—ååŠæ®µçš„ $k_{i:T-1}, K_{i:T-1}$ã€‚
   - **Transformer è¡¥å…¨**ï¼šè¾“å…¥ $(X, k_{i:T-1}, K_{i:T-1})$ï¼Œé¢„æµ‹ $\hat{k}*{0:i-1}, \hat{K}*{0:i-1}$ã€‚
   - æ‹¼æ¥å¾—åˆ°å®Œæ•´çš„ $k_{0:T-1}, K_{0:T-1}$ï¼Œç”¨äº forward controlã€‚
3. **Transformer æ¨¡å—è®¾è®¡**
   - ä»…è§£ç å™¨ï¼ˆcausal maskï¼‰ï¼Œä¿æŒå› æœæ€§ã€‚
   - è¾“å…¥ï¼š
     - çŠ¶æ€ $X = (x_0, \ldots, x_T)$
     - å·²çŸ¥å¢ç›Š $k_{i:T-1}, K_{i:T-1}$
   - åµŒå…¥ååŠ ä½ç½®ç¼–ç ï¼Œè¾“å…¥å¤šå¤´æ³¨æ„åŠ›ã€‚
   - è¾“å‡º reshape å› $(\hat{k}, \hat{K})$ã€‚

### ğŸš€ PyTorch å®ç°ï¼šiLQR-Transformer å¢ç›Šé¢„æµ‹æ¨¡å—

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

###############################################
# ä½ç½®ç¼–ç æ¨¡å—ï¼šè®© Transformer çŸ¥é“æ—¶é—´é¡ºåº
###############################################
class PositionalEncoding(nn.Module):
    def __init__(self, d_model, max_len=5000):
        """
        d_model: ç‰¹å¾ç»´åº¦
        max_len: åºåˆ—æœ€å¤§é•¿åº¦
        """
        super().__init__()
        
        # åˆ›å»º [max_len, d_model] çš„ä½ç½®ç¼–ç çŸ©é˜µ
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len).unsqueeze(1)  # [max_len, 1]
        div_term = torch.exp(torch.arange(0, d_model, 2) * 
                             (-torch.log(torch.tensor(10000.0)) / d_model))
        
        # å¶æ•°ä½ç½®ç”¨ sinï¼Œå¥‡æ•°ä½ç½®ç”¨ cos
        pe[:, 0::2] = torch.sin(position * div_term)  
        pe[:, 1::2] = torch.cos(position * div_term)
        
        # æ‰©å±• batch ç»´åº¦ï¼Œä¾¿äºç›´æ¥åŠ åˆ°è¾“å…¥ä¸Š
        pe = pe.unsqueeze(0)  # [1, max_len, d_model]
        
        # æ³¨å†Œä¸º bufferï¼Œæ¨¡å‹ä¿å­˜æ—¶ä¸€å¹¶ä¿å­˜ï¼Œä½†ä¸ä¼šä½œä¸ºå‚æ•°æ›´æ–°
        self.register_buffer('pe', pe)

    def forward(self, x):
        """
        x: [B, T, d_model] è¾“å…¥åºåˆ—
        è¿”å›: åŠ ä¸Šä½ç½®ç¼–ç åçš„è¾“å…¥
        """
        return x + self.pe[:, :x.size(1)]


###############################################
# iLQR Transformerï¼šé¢„æµ‹ç¼ºå¤±çš„å¢ç›ŠçŸ©é˜µ (k, K)
###############################################
class iLQRTransformer(nn.Module):
    def __init__(self, state_dim, k_dim, K_dim, d_model=128, nhead=4, num_layers=3):
        """
        state_dim: çŠ¶æ€ç»´åº¦ (x_t å¤§å°)
        k_dim: å‰é¦ˆå¢ç›Šå‘é‡çš„ç»´åº¦
        K_dim: åé¦ˆå¢ç›ŠçŸ©é˜µçš„å±•å¹³ç»´åº¦
        d_model: Transformer ç‰¹å¾ç»´åº¦
        nhead: æ³¨æ„åŠ›å¤´æ•°
        num_layers: Transformer è§£ç å™¨å±‚æ•°
        """
        super().__init__()
        
        # çŠ¶æ€åµŒå…¥å±‚ï¼ŒæŠŠåŸå§‹çŠ¶æ€æ˜ å°„åˆ° d_model ç»´åº¦
        self.state_embed = nn.Linear(state_dim, d_model)
        
        # å¢ç›ŠåµŒå…¥å±‚ï¼ŒæŠŠ k, K æ˜ å°„åˆ° d_model ç»´åº¦
        self.k_embed = nn.Linear(k_dim, d_model)
        self.K_embed = nn.Linear(K_dim, d_model)
        
        # ç”¨äºæ‹¼æ¥åçš„å¢ç›Šæ˜ å°„åˆ° d_model
        self.gain_proj = nn.Linear(2 * d_model, d_model)
        
        # ä½ç½®ç¼–ç 
        self.pos_encoder = PositionalEncoding(d_model)
        
        # Transformer è§£ç å™¨
        decoder_layer = nn.TransformerDecoderLayer(
            d_model=d_model,    # ç‰¹å¾ç»´åº¦
            nhead=nhead,        # å¤šå¤´æ³¨æ„åŠ›å¤´æ•°
            batch_first=True    # [B, T, d_model] æ ¼å¼
        )
        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_layers)
        
        # è¾“å‡ºå±‚ï¼šæŠŠ Transformer è¾“å‡ºè½¬å›å¢ç›ŠçŸ©é˜µ
        self.out_k = nn.Linear(d_model, k_dim)
        self.out_K = nn.Linear(d_model, K_dim)

    def forward(self, X, k_partial, K_partial):
        """
        X: [B, T, state_dim]    ç³»ç»ŸçŠ¶æ€åºåˆ— (å…¨æ—¶åŸŸ)
        k_partial: [B, T-i, k_dim]   å·²çŸ¥ä¸€éƒ¨åˆ†çš„å‰é¦ˆå¢ç›Š
        K_partial: [B, T-i, K_dim]   å·²çŸ¥ä¸€éƒ¨åˆ†çš„åé¦ˆå¢ç›Š
        è¿”å›: é¢„æµ‹çš„ (k, K)ï¼Œè¡¥å…¨æœªè®¡ç®—éƒ¨åˆ†
        """
        B, T, _ = X.shape
        
        # === Step1. çŠ¶æ€åµŒå…¥ ===
        x_embed = self.state_embed(X)   # [B, T, d_model]
        
        # === Step2. éƒ¨åˆ†å¢ç›ŠåµŒå…¥ ===
        k_embed = self.k_embed(k_partial)   # [B, T-i, d_model]
        K_embed = self.K_embed(K_partial)   # [B, T-i, d_model]
        
        # æ‹¼æ¥ (k, K)ï¼Œå¹¶æŠ•å½±å› d_model
        gain_embed = torch.cat([k_embed, K_embed], dim=-1)  # [B, T-i, 2*d_model]
        gain_embed = self.gain_proj(gain_embed)             # [B, T-i, d_model]
        
        # === Step3. ä½ç½®ç¼–ç  ===
        memory = self.pos_encoder(x_embed)   # çŠ¶æ€ä½œä¸º memory
        tgt = self.pos_encoder(gain_embed)   # å¢ç›Šä½œä¸ºç›®æ ‡
        
        # === Step4. å› æœ maskï¼Œä¿è¯è§£ç å™¨åªèƒ½çœ‹è¿‡å» ===
        tgt_len = tgt.size(1)
        tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgt_len).to(tgt.device)
        
        # === Step5. Transformer è§£ç å™¨ ===
        out = self.transformer_decoder(tgt, memory, tgt_mask=tgt_mask)  # [B, T-i, d_model]
        
        # === Step6. è¾“å‡ºé¢„æµ‹çš„å¢ç›Š ===
        pred_k = self.out_k(out)  # [B, T-i, k_dim]
        pred_K = self.out_K(out)  # [B, T-i, K_dim]
        
        return pred_k, pred_K


###############################################
# ğŸ” ä½¿ç”¨ç¤ºä¾‹
###############################################
if __name__ == "__main__":
    B, T, state_dim = 8, 20, 6   # batch=8, æ—¶é—´é•¿åº¦=20, çŠ¶æ€ç»´åº¦=6
    k_dim, K_dim = 2, 4          # å‰é¦ˆå¢ç›Š=2ç»´ï¼Œåé¦ˆå¢ç›Š=4ç»´ (å±•å¹³)
    
    # æ¨¡æ‹Ÿè¾“å…¥
    X = torch.randn(B, T, state_dim)       # ç³»ç»ŸçŠ¶æ€åºåˆ—
    k_partial = torch.randn(B, T//2, k_dim) # å·²çŸ¥ä¸€åŠå¢ç›Š
    K_partial = torch.randn(B, T//2, K_dim)
    
    # å®šä¹‰æ¨¡å‹
    model = iLQRTransformer(state_dim, k_dim, K_dim)
    
    # å‰å‘é¢„æµ‹
    pred_k, pred_K = model(X, k_partial, K_partial)
    
    print("é¢„æµ‹å‰é¦ˆå¢ç›Š pred_k å½¢çŠ¶:", pred_k.shape)  # [8, 10, 2]
    print("é¢„æµ‹åé¦ˆå¢ç›Š pred_K å½¢çŠ¶:", pred_K.shape)  # [8, 10, 4]
```

------

#### ğŸ”‘ ä»£ç è¦ç‚¹

- **éƒ¨åˆ†åå‘è¿‡ç¨‹**ï¼š`k_partial, K_partial` å°±æ˜¯ä½ å®é™…ç®—å‡ºæ¥çš„ååŠæ®µå¢ç›Šã€‚
- **Transformer é¢„æµ‹**ï¼š`pred_k, pred_K` æ˜¯æ¨¡å‹é¢„æµ‹çš„å‰åŠæ®µå¢ç›Šã€‚
- **æœ€ç»ˆæ‹¼æ¥**ï¼šæŠŠ `k_partial + pred_k` æ‹¼æ¥èµ·æ¥ï¼Œå°±å¾—åˆ°äº†å®Œæ•´çš„ $k_{0:T-1}, K_{0:T-1}$ã€‚

### }

### {

###  **Rel-CNN (å…³ç³»å·ç§¯ç¥ç»ç½‘ç»œ)** çš„ **PyTorch å®ç°**

### ğŸ”‘ è§£é‡Š

1. **RFC** â†’ ç›´æ¥ç”¨å·®å€¼/ç»å¯¹å€¼/äºŒå€¼åŒ–ç”Ÿæˆå…³ç³»ç‰¹å¾ã€‚
2. **LRFC** â†’ å­¦ä¹ å‹å…³ç³»ç‰¹å¾ï¼Œç”¨ Q/K æŠ•å½±åè®¡ç®—ç›¸ä¼¼åº¦ã€‚
3. **å±‚æ¬¡å·ç§¯** â†’ å…ˆé™ç»´ï¼Œå†å¤šå°ºåº¦å·ç§¯ï¼ˆé¿å…å‚æ•°çˆ†ç‚¸ï¼‰ã€‚
4. **LPGR Block** â†’ æ¯ä¸ªå—æå– â€œå±€éƒ¨æ¨¡å¼ + å…¨å±€å…³ç³»â€ï¼Œå¸¦æ®‹å·®ã€‚
5. **Rel-CNN** â†’ å¤šä¸ª LPGR Block å †å ï¼Œæœ€åç”¨å…¨è¿æ¥åˆ†ç±»ã€‚

### ğŸš€ PyTorch å®ç°ï¼šRel-CNN

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

######################################################
# 1. å…³ç³»ç‰¹å¾è®¡ç®—æ¨¡å—
######################################################
class RFC(nn.Module):
    """ 
    Relationship Feature based Convolution Filtering (å›ºå®šè§„åˆ™å…³ç³»ç‰¹å¾)
    è¾“å…¥: [B, T, D]ï¼ŒB=æ‰¹å¤§å°ï¼ŒT=æ—¶é—´é•¿åº¦ï¼ŒD=ç‰¹å¾ç»´åº¦
    è¾“å‡º: [B, T, T, D]ï¼Œå…³ç³»çŸ©é˜µ
    """
    def forward(self, x):
        # x: [B, T, D]
        B, T, D = x.size()
        
        # æ‰©å±•ç»´åº¦ä¾¿äºåš pairwise æ“ä½œ
        x1 = x.unsqueeze(2)  # [B, T, 1, D]
        x2 = x.unsqueeze(1)  # [B, 1, T, D]
        
        # å·®å€¼å…³ç³» p - q
        diff = x1 - x2       # [B, T, T, D]
        # ç»å¯¹å·® |p - q|
        abs_diff = torch.abs(diff)
        # äºŒå€¼åŒ–å…³ç³» (å·®å€¼æ˜¯å¦å°äºé˜ˆå€¼ï¼Œè¿™é‡Œç”¨å‡å€¼è¿‘ä¼¼ä»£æ›¿)
        binary = (abs_diff < abs_diff.mean()).float()
        
        # æ‹¼æ¥æ‰€æœ‰å…³ç³»ç‰¹å¾
        relation = torch.cat([diff, abs_diff, binary], dim=-1)  # [B, T, T, 3D]
        return relation


class LRFC(nn.Module):
    """ 
    Latent Relationship Feature Convolution (å­¦ä¹ å…³ç³»ç‰¹å¾)
    è¾“å…¥: [B, T, D]
    è¾“å‡º: [B, T, T] (ç›¸ä¼¼åº¦çŸ©é˜µ, æ¯ä¸ªç‰¹å¾ç»´åº¦ä¼šåšæˆä¸€ä¸ªé€šé“)
    """
    def __init__(self, D, d_latent=32):
        super().__init__()
        # å­¦ä¹ ä¸¤ä¸ªæŠ•å½±çŸ©é˜µ Q, K
        self.proj_q = nn.Linear(D, d_latent)
        self.proj_k = nn.Linear(D, d_latent)

    def forward(self, x):
        # x: [B, T, D]
        Q = self.proj_q(x)  # [B, T, d_latent]
        K = self.proj_k(x)  # [B, T, d_latent]

        # ç›¸ä¼¼åº¦è®¡ç®— (ç‚¹ç§¯å½¢å¼)
        sim = torch.matmul(Q, K.transpose(-2, -1))  # [B, T, T]
        # å½’ä¸€åŒ– (softmax)
        sim = F.softmax(sim, dim=-1)
        
        # è¾“å‡ºç›¸ä¼¼åº¦å…³ç³»ç‰¹å¾
        return sim.unsqueeze(-1)  # [B, T, T, 1]


######################################################
# 2. å±‚æ¬¡å·ç§¯æ¨¡å—
######################################################
class HierarchicalConv(nn.Module):
    """
    åˆ†å±‚å·ç§¯ï¼šå…ˆå…±äº«å·ç§¯é™ç»´ï¼Œå†å¤šå°ºåº¦å·ç§¯æå–æ¨¡å¼
    è¾“å…¥: [B, C, T, T] (C=é€šé“æ•°, åŒ…å«åŸå§‹ç‰¹å¾+å…³ç³»ç‰¹å¾)
    è¾“å‡º: [B, C_out, T, T]
    """
    def __init__(self, in_channels, hidden_channels=32, out_channels=64, kernel_sizes=[2,4,8]):
        super().__init__()
        
        # Step1: é™ç»´å·ç§¯ (å…±äº«æƒé‡å·ç§¯)
        self.reduce_conv = nn.Conv2d(in_channels, hidden_channels, kernel_size=1)
        
        # Step2: å¤šå°ºåº¦å·ç§¯ (ä¸åŒ kernel size æå–ä¸åŒå°ºåº¦ç‰¹å¾)
        self.multi_scale_convs = nn.ModuleList([
            nn.Conv2d(hidden_channels, out_channels, kernel_size=(k, k), padding="same")
            for k in kernel_sizes
        ])
    
    def forward(self, x):
        # å…ˆé™ç»´
        x = self.reduce_conv(x)  # [B, hidden, T, T]
        
        # å¤šå°ºåº¦å·ç§¯
        features = [conv(x) for conv in self.multi_scale_convs]  # list of [B, out, T, T]
        
        # æ‹¼æ¥æ‰€æœ‰å°ºåº¦ç‰¹å¾
        out = torch.cat(features, dim=1)  # [B, out_channels*len(kernel_sizes), T, T]
        return out


######################################################
# 3. Rel-CNN æ ¸å¿ƒæ¨¡å—: LPGR Block
######################################################
class LPGRBlock(nn.Module):
    """
    Local Pattern + Global Relationship Block
    """
    def __init__(self, D, use_lrfc=True):
        super().__init__()
        
        # å…³ç³»ç‰¹å¾
        self.rfc = RFC()
        self.lrfc = LRFC(D) if use_lrfc else None
        
        # å±‚æ¬¡å·ç§¯
        # è¾“å…¥é€šé“æ•° = åŸå§‹ç‰¹å¾(D) + RFCå…³ç³»ç‰¹å¾(3D) + LRFCå…³ç³»ç‰¹å¾(1)
        in_channels = D + 3*D + (1 if use_lrfc else 0)
        self.hier_conv = HierarchicalConv(in_channels=in_channels)
        
        # æ®‹å·®è¿æ¥ (ä¿è¯ç¨³å¥)
        self.residual = nn.Conv2d(D, self.hier_conv.multi_scale_convs[0].out_channels * len(self.hier_conv.multi_scale_convs), kernel_size=1)

    def forward(self, x):
        """
        x: [B, T, D] æ—¶é—´åºåˆ—è¾“å…¥
        è¿”å›: [B, C, T, T] ç‰¹å¾å›¾
        """
        B, T, D = x.size()
        
        # === Step1. å…³ç³»ç‰¹å¾ ===
        rfc_feat = self.rfc(x)      # [B, T, T, 3D]
        if self.lrfc:
            lrfc_feat = self.lrfc(x)   # [B, T, T, 1]
            relation_feat = torch.cat([rfc_feat, lrfc_feat], dim=-1)  # [B, T, T, 3D+1]
        else:
            relation_feat = rfc_feat   # [B, T, T, 3D]
        
        # === Step2. æ‹¼æ¥åŸå§‹è¾“å…¥ (å¹¿æ’­åˆ°çŸ©é˜µç»´åº¦)
        x_matrix = x.unsqueeze(2).repeat(1, 1, T, 1)  # [B, T, T, D]
        feat = torch.cat([x_matrix, relation_feat], dim=-1)  # [B, T, T, D+3D(+1)]
        
        # === Step3. è½¬æ¢ä¸ºå·ç§¯è¾“å…¥æ ¼å¼ [B, C, T, T]
        feat = feat.permute(0, 3, 1, 2)  # [B, C, T, T]
        
        # === Step4. å±‚æ¬¡å·ç§¯æå–ç‰¹å¾ ===
        out = self.hier_conv(feat)   # [B, C_out, T, T]
        
        # === Step5. æ®‹å·®è¿æ¥ ===
        res = self.residual(x_matrix.permute(0, 3, 1, 2))  # [B, C_out, T, T]
        out = out + res
        
        return out


######################################################
# 4. Rel-CNN æ•´ä½“æ¶æ„
######################################################
class RelCNN(nn.Module):
    def __init__(self, D, num_classes=5, num_blocks=3, use_lrfc=True):
        """
        D: è¾“å…¥ç‰¹å¾ç»´åº¦
        num_classes: åˆ†ç±»ç±»åˆ«æ•°
        num_blocks: LPGR å †å å±‚æ•°
        """
        super().__init__()
        
        # å †å å¤šä¸ª LPGR Block
        self.blocks = nn.ModuleList([LPGRBlock(D, use_lrfc=use_lrfc) for _ in range(num_blocks)])
        
        # åˆ†ç±»å¤´
        self.fc = nn.Linear(64*3, num_classes)  # å‡è®¾ HierarchicalConv è¾“å‡ºé€šé“æ•°=64*3
        
    def forward(self, x):
        """
        x: [B, T, D] è¾“å…¥æ—¶é—´åºåˆ—
        è¿”å›: åˆ†ç±»ç»“æœ [B, num_classes]
        """
        out = None
        for block in self.blocks:
            out = block(x)   # [B, C, T, T]
        
        # å…¨å±€æ± åŒ–ï¼ŒæŠŠ [B, C, T, T] â†’ [B, C]
        out = F.adaptive_avg_pool2d(out, (1,1)).squeeze(-1).squeeze(-1)
        
        # åˆ†ç±»å±‚
        logits = self.fc(out)
        return logits


######################################################
# ğŸ” ä½¿ç”¨ç¤ºä¾‹
######################################################
if __name__ == "__main__":
    B, T, D = 8, 20, 3  # batch=8ï¼Œåºåˆ—é•¿åº¦=20ï¼Œç‰¹å¾ç»´åº¦=3
    x = torch.randn(B, T, D)
    
    model = RelCNN(D, num_classes=5, num_blocks=2, use_lrfc=True)
    out = model(x)
    
    print("è¾“å…¥ x å½¢çŠ¶:", x.shape)      # [8, 20, 3]
    print("è¾“å‡º logits å½¢çŠ¶:", out.shape)  # [8, 5]
```

### }



