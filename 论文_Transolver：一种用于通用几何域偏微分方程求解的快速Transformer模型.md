```markdown

```



# Transolver：一种用于通用几何域偏微分方程求解的快速Transformer模型
吴海旭¹ 罗华坤¹ 王浩文¹ 王建民¹ 龙明盛¹  
¹清华大学软件学院、北京信息科学与技术国家研究中心  
吴海旭 <wuhx23@mails.tsinghua.edu.cn>；通信作者：龙明盛 <mingsheng@tsinghua.edu.cn>  
第41届国际机器学习大会论文集，奥地利维也纳，PMLR 235，2024年。版权所有 © 2024 作者。


## 摘要
Transformer模型已在多个领域推动了里程碑式的进展，近年来也被应用于偏微分方程（PDEs）求解。然而，由于偏微分方程通常需要离散化为具有复杂几何形状的大规模网格，Transformer模型难以直接从海量离散网格点中捕捉复杂的物理关联。突破表面繁杂的网格限制，本文提出Transolver模型，其核心思想更为根本：学习离散几何背后隐藏的内在物理状态。具体而言，我们设计了一种新的**物理注意力机制（Physics-Attention）**，能够自适应地将离散域划分为一系列形状灵活的可学习“切片”（slice），物理状态相似的网格点会被归为同一切片。通过对切片编码得到的“物理感知令牌”（physics-aware token）计算注意力，Transolver能够有效捕捉复杂几何下的精细物理关联，同时赋予模型原生的通用几何建模能力，且计算复杂度为线性。在6个标准基准测试中，Transolver均实现了当前最优性能，相对误差降低22%；此外，该模型在汽车、翼型设计等大规模工业仿真任务中也表现优异。代码已开源至：https://github.com/thuml/Transolver。

（

##### Transolver 的核心想法

Transolver不再死盯着表面的“网格点”，而是去学习 **网格点背后的物理状态**。

它的关键设计是 **物理注意力机制（Physics-Attention）**：

1. **自动切片**：模型会把离散的网格点“分组”，形成一系列灵活的小片区（slice）。
   - 同一片区里的点，物理状态（比如温度、速度、压力）相似。
2. **物理感知令牌**：每个片区会被编码成一个 **物理令牌**（就像语言模型里的词元token）。
3. **注意力计算**：模型不是直接在所有网格点上计算，而是在这些更高层的物理令牌之间做注意力计算。

）


## 1. 引言
偏微分方程求解在天气预报、工业设计、材料分析等众多实际应用中具有至关重要的意义（Roubíček, 2013）。作为一个基础科学问题，偏微分方程的解析解通常难以获取。因此，在实际应用中，偏微分方程通常会先离散化为网格，再通过数值方法求解——对于复杂结构，这一过程往往需要数小时甚至数天（Umetani & Bickel, 2018）。

近年来，深度模型已成为偏微分方程求解的有力工具（Lu et al., 2021; Li et al., 2021）。凭借强大的非线性建模能力，深度模型可通过训练从数据中学习偏微分方程相关任务的输入输出映射，在推理阶段求解速度远快于传统数值方法（Goswami et al., 2022; Wu et al., 2023）。作为基础模型的核心架构，Transformer模型（Vaswani et al., 2017）已在自然语言处理、计算机视觉等多个领域取得显著进展（Devlin et al., 2019; Brown et al., 2020; Dosovitskiy et al., 2021; Liu et al., 2021），近年来也被引入偏微分方程求解领域（Li et al., 2023c）。

然而，为实现精确仿真，偏微分方程通常需离散化为具有复杂几何形状的大规模网格。直接将Transformer应用于海量网格点时，会面临计算效率与关联学习两大难题（Liu et al., 2021; Katharopoulos et al., 2020b），使其难以成为理想的偏微分方程求解器。例如，计算行驶汽车的空气阻力（图1）时，模型需求解纳维-斯托克斯方程（Navier-Stokes equations），包括估计表面网格的压力与周围空间的流速，这带来两大挑战：  
1. 该问题需对成千上万不规则分布的网格点进行协同建模，而标准注意力机制的二次复杂度使其计算上不可行；  
2. 偏微分方程涉及多物理量间极为复杂的时空交互，直接从海量离散点中捕捉这些高阶、精细的关联难度极大。  

因此，如何高效捕捉离散域下的物理关联，是将Transformer转化为实用偏微分方程求解器的关键。

现有方法尝试通过引入线性注意力机制解决复杂度问题（Hao et al., 2023; Tran et al., 2023），但直接对海量网格点应用注意力，仍可能导致模型无法学习到有效关联（Wu et al., 2022）。此外，仅依赖单个网格点的特征，也不足以捕捉偏微分方程的复杂物理关联（Trockman & Kolter, 2022）——尤其在工业设计中，往往涉及极端复杂的多物理场交互。

另外，尽管“分块操作”（patchify）在视觉Transformer中被广泛用于通过局部信息增强单个像素特征（Dosovitskiy et al., 2021; Liu et al., 2021），但规则形状的分块无法适配非结构化几何，更无法捕捉不同离散网格下隐藏的复杂物理状态。

突破表面繁杂的网格限制，本文提出Transolver模型，其核心思想是学习复杂几何下的内在物理状态。我们设计的物理注意力机制将离散域划分为一系列可学习切片，物理状态相似的网格点被归为同一切片并编码为物理感知令牌。通过对这些令牌计算注意力，物理注意力机制能够有效捕捉离散域背后的复杂交互。如图1所示，学习到的切片可清晰反映偏微分方程的多样物理状态，例如达西流（Darcy flow）中的流固交互、弹性材料的不同挤压区域、翼型周围的激波与尾流、汽车的前后表面及上下空间等。该设计可原生适配复杂几何，且计算复杂度为线性。

我们在6个不同几何类型的标准基准测试与大规模工业仿真任务中进行了充分实验，Transolver均实现了当前最优性能，且相对误差显著降低。总体而言，本文的贡献如下：  
- 突破现有方法局限，提出通过学习离散域背后的内在物理状态求解偏微分方程，使模型摆脱复杂网格束缚，更聚焦于物理交互；  
- 提出Transolver模型与物理注意力机制，将离散域划分为可学习切片并对编码后的物理感知令牌计算注意力，计算复杂度为线性；  
- Transolver在6个标准基准测试中均实现当前最优性能（相对误差降低22%），且在汽车、翼型设计等大规模工业仿真中表现优异，展现出良好的效率、可扩展性与分布外泛化能力。

（

Transolver 的思路是：**不再死盯着复杂网格，而是直接去学习网格背后真正的“物理状态”。**

- 它提出了一个新的 **物理注意力机制（Physics-Attention）**。
- 这个机制会把网格点自动分成一系列 **可学习的切片（slice）**。
  - 每个切片内的点具有相似的物理状态（比如流场里速度相近的一块区域）。
- 每个切片会被编码成一个 **物理感知令牌（token）**，然后再用注意力机制去建模这些 token 的关系。

这样一来：

- **切片更贴近物理规律**：比如可以自然形成“流体-固体交互区”“材料的受力区”“飞机翼周围的激波区”等。
- **几何自适应**：不用担心几何形状规则不规则，它都能自适应地分片。
- **计算高效**：复杂度从平方降到了线性。

）


## 2. 相关工作
### 2.1 神经偏微分方程求解器
偏微分方程求解作为科学与工程领域的基础问题，长期以来备受关注。过去数百年间，有限元法、谱方法等经典数值方法被提出并广泛应用于实际（Wazwaz, 2002; Solín, 2005）。近年来，凭借强大的非线性建模能力，深度模型也被用作快速替代模型（surrogate）应用于偏微分方程求解（Karniadakis et al., 2021; Wang et al., 2023），大致可分为以下两类范式：

#### 物理知情神经网络（Physics-informed neural networks）
该范式将偏微分方程的约束（包括方程本身、初始条件与边界条件）转化为深度模型的目标函数（Weinan & Yu, 2017; Raissi et al., 2019; Wang et al., 2020a; 2020b）。训练过程中，模型输出会逐渐满足偏微分方程约束，从而实现对解析解的逼近。然而，该范式需要明确的偏微分方程形式化表达，难以应用于部分观测的实际场景。

#### 神经算子（Neural operators）
另一类范式通过学习神经算子来逼近偏微分方程相关任务的输入输出映射，例如根据历史观测预测未来流体状态、估计固体材料的内部应力等（Lu et al., 2021; Kovachki et al., 2023）。其中最具代表性的是傅里叶神经算子（FNO, Li et al., 2021）及其变体：  
- Li等人（2021）提出傅里叶神经算子，通过傅里叶域的线性投影逼近积分运算；  
- 后续研究将FNO与U-Net结合，提出U-NO（Rahman et al., 2023）与U-FNO（Wen et al., 2022），以实现多尺度建模；  
- WMT（Gupta et al., 2021）引入多尺度小波基，捕捉不同尺度下的复杂关联；  
- F-FNO（Tran et al., 2023）通过傅里叶域因式分解提升模型效率；  
- LSM（Wu et al., 2023）通过在学习到的 latent 空间中应用谱方法（Gottlieb & Orszag, 1977），解决偏微分方程的高维复杂度问题。

为适配非结构化网格，相关研究也提出了针对性方法：  
- GNO（Li et al., 2020b）采用图神经算子；  
- geo-FNO（Li et al., 2023b）利用几何傅里叶变换将非结构化输入域投影到均匀 latent 网格；  
- GINO（Li et al., 2023a）结合GNO与geo-FNO，实现局部与全局的协同建模；  
- 3D-GeoCA（Deng et al., 2024）通过引入预训练3D视觉骨干网络（Xue et al., 2023）优化模型初始化，进一步增强GNO性能。  

然而，由于傅里叶基的周期边界假设（Gottlieb & Orszag, 1977），geo-FNO在汽车等复杂网格中性能严重退化；图核方法也难以有效学习全局信息。

值得注意的是，作为深度学习的核心架构，Transformer也被应用于偏微分方程求解：  
- HT-Net（Liu et al., 2022）结合Swin Transformer（Liu et al., 2021）与多重网格法（Wesseling, 1995），捕捉多尺度空间关联；  
- FactFormer（Li et al., 2023d）利用低秩结构，通过多维因式分解注意力提升模型效率。  

但这些方法均假设偏微分方程离散化为均匀网格，难以适配非结构化网格。此外，为解决注意力的二次复杂度问题，OFormer（Li et al., 2023c）、GNOT（Hao et al., 2023）与ONO（Xiao et al., 2024）采用了Reformer（Kitaev et al., 2020）、Performer（Choromanski et al., 2021b）、伽辽金Transformer（Galerkin Transformer, Cao, 2021）等成熟的线性Transformer模型。但上述所有方法均直接对海量网格点应用注意力，而Transolver则对可学习切片捕捉的内在物理状态计算注意力，更擅长建模复杂物理关联。


### 2.2 几何深度学习
针对不规则几何的处理，研究人员提出了一系列技术，统称为**几何深度学习**（Bronstein et al., 2017）。图神经网络是其中的代表，通过在连通图上应用核函数实现表示学习（Hamilton et al., 2017; Gao & Ji, 2019; Pfaff et al., 2021）。此外，PointNet（Qi et al., 2017）与Point Transformer（Zhao et al., 2021）也被提出用于离散点云处理。然而，这些方法多针对计算机视觉或图形学任务，与本文的偏微分方程求解任务存在本质差异；且这些方法虽适配复杂几何，但Transolver通过学习物理敏感切片，更擅长捕捉繁杂网格下的物理信息。


## 3. 方法设计
为解决计算效率与关联建模两大难题，本文提出Transolver模型与物理注意力机制，用于学习偏微分方程任务中离散网格下内在物理状态的高阶关联。与学习网格点间的低阶关联不同，聚焦物理状态可使模型摆脱复杂几何束缚，同时提升物理求解精度与计算效率。

### 问题设定
考虑定义在输入域$\Omega \subset \mathbb{R}^{C_g}$上的偏微分方程，其中$C_g$表示输入空间的维度。为进行数值计算，首先将$\Omega$离散化为$N$个网格点，记为$g \in \mathbb{R}^{N \times C_g}$。任务目标是基于输入几何$g$与网格点上的观测物理量$u \in \mathbb{R}^{N \times C_u}$（部分任务中$u$可选），估计目标物理量。例如：  
- 流体预测任务中，输入包括观测网格与历史流速，目标是预测各网格点的未来流速；  
- 汽车/翼型设计任务中，输入仅包含离散网格结构，目标是估计表面及周围的物理量（如压力、流速）。

（

### 2.1 神经偏微分方程求解器

解偏微分方程（PDE）是科学和工程里的老大难问题。传统方法像 **有限元法**、**谱方法** 已经用了几百年，虽然可靠，但很耗时。

近年来，深度学习也开始参与进来，主要有两类思路：

#### （1）物理知情神经网络（PINNs）

- 核心思路：把偏微分方程的约束（比如方程本身、初始条件、边界条件）直接写进损失函数。
- 模型训练时，不仅要拟合数据，还要“满足物理规律”。
- 好处：理论上能直接逼近方程的解析解。
- 缺点：需要明确的方程形式，但很多真实场景下，我们可能拿不到完整的方程，只能观测到一些数据。

#### （2）神经算子（Neural Operators）

- 不直接管方程形式，而是学习一个 **算子**，即输入和输出之间的映射。
- 举例：根据历史流体状态预测未来；根据几何预测材料内部应力。
- 代表方法：
  - **傅里叶神经算子（FNO）**：在频域里做运算。
  - **U-NO / U-FNO**：结合 U-Net 处理多尺度信息。
  - **小波方法（WMT）**：用小波基函数捕捉多尺度关系。
  - **LSM**：在 latent 空间里做谱方法，解决高维问题。
- 针对非规则几何：
  - **GNO**：用图神经网络。
  - **geo-FNO**：通过几何变换映射到规则网格。
  - **GINO**：结合局部与全局建模。
  - **3D-GeoCA**：用预训练 3D 视觉模型来增强效果。

问题是：

- 傅里叶方法通常假设“周期边界”，所以在复杂几何（比如汽车）上效果差。
- 图方法虽然能处理不规则几何，但很难抓到全局物理信息。

#### Transformer 在 PDE 求解中的尝试

Transformer 本身是深度学习的核心架构，也有人把它应用到 PDE：

- **HT-Net**：结合 Swin Transformer 和多重网格法，做多尺度建模。
- **FactFormer**：用低秩分解来减少注意力计算量。
- **OFormer、GNOT、ONO**：采用各种“线性 Transformer”改进版来降低复杂度。

但问题是：这些方法 **都还是在海量网格点上直接做注意力计算**，既算得慢，又难以捕捉深层物理关系。而 **Transolver** 不一样，它是对 **“切片”后的物理状态做注意力**，从根本上更适合建模复杂的物理现象。

------

### 2.2 几何深度学习

另一个方向是 **几何深度学习**，专门应对不规则几何。

- 代表方法：**图神经网络（GNNs）**，在点和边组成的图上做学习。
- 还有 **PointNet**、**Point Transformer**，主要用来处理点云（计算机视觉里常见）。

但这些方法主要是为图像/视觉设计的，并没有特别考虑 PDE 的物理规律。
 而 **Transolver** 的不同之处在于：它通过 **物理感知切片** 来分组网格点，更直接地学习物理交互，而不是仅仅处理几何结构。

------

## 3. 方法设计

Transolver 想解决的核心问题有两个：

1. **效率** —— 不能在成千上万个点上做平方复杂度的注意力。
2. **物理关联** —— 需要真正学到物理量之间的复杂关系。

于是它提出了 **物理注意力机制**：

- 不是直接建模点和点的关系，而是先学习点背后的 **物理状态**，再在更高层次上建模。
- 这样可以摆脱几何的复杂性，让模型关注真正的物理交互。

）


### 3.1 学习物理感知令牌
如前所述，偏微分方程求解的关键在于捕捉复杂的物理关联，但海量离散网格点可能导致注意力机制无法学习到可靠关联。透过表面网格可见，这些网格点是底层连续物理空间的有限离散采样——这一观察启发我们学习**内在物理状态**。

以汽车表面压力估计为例（图2），表面网格可被归为多个物理内部一致的子集（如前部、斜面、后部区域）。这一发现为偏微分方程相关任务求解提供了更根本的视角。

（图2：从Transolver切片中学习物理感知令牌。(a)离散域；(b)物理域，Slice 1~Slice M为切片，Token 1~Token M为对应物理感知令牌，Front/Back/Bevel分别表示汽车前部/后部/斜面区域）

从技术实现上，给定包含$N$个网格点坐标信息的网格集$g = \{g_i\}_{i=1}^N$与观测物理量$u$，首先通过线性层将其嵌入为深度特征$x = \{x_i\}_{i=1}^N$，其中每个网格点特征含$C$个通道（即$x_i \in \mathbb{R}^{1 \times C}$），同时包含几何与物理信息。

为捕捉整个输入域下的物理状态，我们提出**自下而上的范式**：基于每个网格点$g_i$的学习特征$x_i$，将其归属于$M$个潜在切片，形式化表达如下：  
$$
\begin{cases}
\{w_i\}_{i=1}^N = \left\{ \text{Softmax}\left( \text{Project}(x_i) \right) \right\}_{i=1}^N \\
s_j = \{w_{i,j}x_i\}_{i=1}^N
\end{cases} \tag{1}
$$
其中，$\text{Project}()$函数将$C$个通道投影为$M$个权重，经$\text{Softmax}()$后得到切片权重$w_i \in \mathbb{R}^{1 \times M}$；$w_{i,j}$表示第$i$个网格点归属于第$j$个切片的程度，且满足$\sum_{j=1}^M w_{i,j} = 1$；$s_j \in \mathbb{R}^{N \times C}$表示第$j$个切片特征，是$N$个网格点特征$x$的加权组合。需注意，特征相近的网格点会产生相似的切片权重，即更可能被归为同一切片。

为避免网格点分配过于均匀，我们沿切片维度（即新投影的$M$维）应用$\text{Softmax}()$，使学习到的切片权重具有低熵特性，确保捕捉到的物理状态包含有效信息。在实际实现中，$\text{Project}()$被配置为逐点线性层，可自然适配通用几何；对于结构化网格或均匀网格，也可实例化为局部卷积、无网格层以获取更优表示。

由于每个切片包含几何与物理特征相似的网格点，我们通过**空间加权聚合**将其进一步编码为物理感知令牌，形式化如下：  
$$
z_j = \frac{\sum_{i=1}^N s_{j,i}}{\sum_{i=1}^N w_{i,j}} = \frac{\sum_{i=1}^N w_{i,j}x_i}{\sum_{i=1}^N w_{i,j}} \tag{2}
$$
其中$z_j \in \mathbb{R}^{1 \times C}$。通过除以切片权重之和，对每个令牌特征$z_j$进行归一化。经物理内部一致的切片空间聚合编码后，每个令牌均包含特定物理状态的信息。


#### 注3.1（为何切片能学习物理内部一致的信息）
1. 如前所述，切片权重由网格特征投影得到，因此特征相似的网格点更可能被归为同一切片；  
2. 由于后续会对切片编码的令牌计算注意力，为降低最终损失，训练过程中切片权重会进一步优化，将物理状态相似的网格点归为同一切片。否则，令牌间的注意力会被区分度低、状态混合的令牌特征干扰，导致性能下降。


#### 注3.2（学习切片与划分计算区域的区别）
有限元法等经典数值方法通常将整个网格划分为多个计算区域以优化仿真效果（Solín, 2005），但该过程需大量专业知识与人工操作，且仅能覆盖空间局部区域，无法捕捉物理状态相似但空间距离较远的点（如汽车的挡风玻璃与车牌）。本文利用深度特征，通过自下而上的范式学习物理状态，得到的切片不受局部区域限制。如图1(e)所示，模型会将汽车的挡风玻璃、车牌、前灯归为同一切片——因为这些区域在行驶过程中均处于前部，与空气阻力高度相关，验证了切片学习的有效性。

（

## 通俗解释版 · 学习物理感知令牌

在解偏微分方程的时候，我们真正想捕捉的是 **底层的物理状态**，而不是那些数量庞大、分布复杂的网格点。因为网格点只是把连续空间“切碎”后的采样结果，本身很杂乱。

举个例子：
 在估算汽车表面压力时，汽车外壳会被离散成许多小网格。但从物理角度看，我们其实更关心 **汽车的前部、斜面、后部** 这些区域的整体状态，而不是每一个小网格的单独数值。

于是，Transolver 的核心做法是：
 把这些复杂网格 **自动分成一组“切片（slice）”**，每个切片代表一个内部物理状态相对一致的区域，然后再把切片转化成一个 **物理感知令牌（physics-aware token）**。

------

### 技术上是怎么做的？

1. **先提取每个网格点的特征**：

   - 输入：网格点坐标 $g_i$ 和观测到的物理量 $u$（比如速度、压力）。
   - 输出：通过线性层投影，得到特征向量 $x_i$（含几何 + 物理信息）。

2. **再把网格点“归类”到切片**：

   - 给每个点分配一组“切片权重” $w_i$（用 Softmax 做概率化）。
   - 权重表示“这个点属于每个切片的程度”。
   - 相似的点（几何位置、物理状态接近）会自然被分到同一个切片。

   公式上就是：

   - 每个点的特征投影成 $M$ 个权重。
   - Softmax 确保这些权重加起来等于 1。

3. **形成切片特征**：

   - 对应第 $j$ 个切片，把所有点的特征按权重加权平均。
   - 得到切片的表示 $s_j$，再进一步归一化，形成令牌 $z_j$。

   换句话说：**切片令牌就是“这群点的综合代表”**。

------

### 为什么切片能学到物理一致性？

- 因为点的特征越相似，分到同一个切片的可能性越高。
- 在训练时，模型会不断调整切片划分，让“物理相似的点”尽量聚在一起，否则注意力层处理时会被“混乱的令牌”拖后腿，性能下降。

）


### 3.2 Transolver模型
基于学习物理感知令牌的思想，我们通过改造Transformer的注意力机制（引入物理注意力），提出Transolver模型，以捕捉偏微分方程的复杂物理关联。

#### 物理注意力机制（Physics-Attention）
如3.1节所述，对于从输入嵌入得到的深度特征$x \in \mathbb{R}^{N \times C}$，首先基于学习到的切片权重$w \in \mathbb{R}^{N \times M}$，将其分解为$M$个物理内部一致的切片$s = \{s_j\}_{j=1}^M \in \mathbb{R}^{M \times (N \times C)}$；随后通过式(2)将$M$个切片聚合为$M$个物理感知令牌$z = \{z_j\}_{j=1}^M \in \mathbb{R}^{M \times C}$，以获取每个切片包含的特定物理信息。

如图3所示，通过对编码后的令牌计算注意力，捕捉不同物理状态间的复杂关联，形式化如下：  
$$
q, k, v = \text{Linear}(z), \quad z' = \text{Softmax}\left( \frac{qk^T}{\sqrt{C}} \right) v \tag{3}
$$
其中$q, k, v, z' \in \mathbb{R}^{M \times C}$。之后，通过“反切片”（deslicing）操作，将转换后的物理令牌$z' = \{z'_j\}_{j=1}^M$映射回网格点——利用切片权重重组令牌：  
$$
x'_i = \sum_{j=1}^M w_{i,j}z'_j \tag{4}
$$
其中$1 \leq i \leq N$，计算过程中每个令牌$z'_j$会广播到所有网格点。为简洁，将上述过程概括为$x' = \text{Physics-Attn}(x)$，其总体复杂度为$O(NMC + M^2C)$。由于$M$被设为常数且$M \ll N$，计算复杂度与网格点数量呈线性关系。

遵循注意力机制的常规设计（Vaswani et al., 2017），采用多头部物理注意力以增强模型能力——沿通道维度将输入特征划分为多个子空间，并行计算注意力后拼接结果。


#### 注3.3（作为可学习积分算子的注意力）
现有方法将偏微分方程求解任务定义为迭代更新过程（Li et al., 2020b），并证明标准注意力是输入域$\Omega$上积分算子的蒙特卡洛近似（Cao, 2021; Kovachki et al., 2023），可用于逼近每个迭代步骤的求解过程。本文中注意力被应用于切片编码的令牌，为深入理解物理注意力机制，下文将证明该设计同样等价于$\Omega$上的可学习积分。


#### 定理3.4（物理注意力等价于$\Omega$上的可学习积分）
给定输入函数$u: \Omega \to \mathbb{R}^C$与网格点$g^* \in \Omega$，物理注意力用于逼近积分算子$G$，其定义为：  
$$
G(u)(g^*) = \int_{\Omega} \kappa(g^*, \xi)u(\xi)d\xi \tag{5}
$$
其中$\kappa(\cdot, \cdot)$表示定义在$\Omega \times \Omega$上的核函数。

**证明**：通过构建网格域$\Omega$与切片域$\Omega_s$间的微分同胚投影，将积分变量从$\xi \in \Omega$替换为$\xi_s \in \Omega_s$，可将式(5)重写为$\Omega_s$上的积分，该积分可通过式(3)中的注意力进行逼近。完整证明见附录A。


#### 整体设计
遵循标准Transformer架构（Vaswani et al., 2017），通过将注意力机制替换为物理注意力，得到Transolver模型。假设模型包含$L$层，如图3所示，Transolver的第$l$层可形式化表达为：  
$$
\begin{cases}
\hat{x}_l = \text{Physics-Attn}\left( \text{LayerNorm}(x_{l-1}) \right) + x_{l-1} \\
x_l = \text{FeedForward}\left( \text{LayerNorm}(\hat{x}_l) \right) + \hat{x}_l
\end{cases} \tag{6}
$$
其中$l \in \{1, \cdots, L\}$，$x_l \in \mathbb{R}^{N \times C}$为第$l$层的输出；$x_0 \in \mathbb{R}^{N \times C}$为输入深度特征，由输入几何$g \in \mathbb{R}^{N \times C_g}$与初始观测$u \in \mathbb{R}^{N \times C_u}$通过线性嵌入层得到，即$x_0 = \text{Linear}(\text{Concat}(g, u))$（$C_g$为几何空间维度，$C_u$为观测物理量数量）。最后，对$x_L$应用线性投影，得到最终输出——即物理量$u$的预测结果。

（

##### 通俗解释版 · Transolver模型

在 3.1 里我们说过，Transolver 先把网格点分成 **切片（slice）**，再把它们压缩成 **物理感知令牌（token）**。接下来，就是要在这些令牌之间建模复杂的物理关系，这就是 **物理注意力机制（Physics-Attention）** 的作用。

------

##### 物理注意力机制（Physics-Attention）

1. **输入**：
   - 一堆网格点的特征向量 $x$。
   - 切片权重 $w$，说明每个点属于哪个切片的程度。
2. **切片 → 令牌**：
   - 先根据 $w$ 把点分成 $M$ 个切片。
   - 每个切片再聚合成一个令牌 $z_j$（就像一组点的“代表人”）。
3. **令牌间做注意力**：
   - 类似普通 Transformer 的做法，对这些令牌计算 **q, k, v**，再做加权组合。
   - 结果是新的令牌 $z'$，它包含了不同物理状态之间的交互信息。
4. **反切片（deslicing）**：
   - 把更新后的令牌 $z'$ 再分发回原来的网格点，得到新的点特征 $x'$。
   - 这样每个点的特征就同时包含了局部信息（自身 + 邻近点）和全局物理交互信息。

整个过程可以概括成：
 **网格点 → 切片 → 令牌 → 注意力 → 新令牌 → 回到网格点**。

而且因为令牌数 $M$ 远小于网格点数 $N$，计算复杂度从原来的平方级别（$O(N^2)$）降到线性级别（$O(N)$），大大提高了效率。

------

##### 多头物理注意力

和普通 Transformer 一样，Transolver 也用了 **多头注意力**：

- 把特征分成不同的子空间，分别计算注意力。
- 最后把结果拼接起来，增强模型的表达能力。

------

##### 数学上的理解（注意力 = 积分算子）

在数学上，解 PDE 常常可以写成某种 **积分运算**。
 以前有研究证明过：**标准注意力其实就是积分的近似**。

Transolver 的物理注意力也是一样的，只不过它不是直接在网格点上做，而是在 **切片令牌** 上做。这相当于：

- 先把输入空间映射到一个“切片空间”；
- 再在这个空间上做积分近似。

这样模型学到的不仅仅是“点和点的关系”，而是对物理空间上的 **可学习积分**。

）


## 4. 实验
我们通过大量实验评估Transolver的性能，包括6个标准基准测试与2个工业级设计任务，覆盖多种几何类型。

### 基准测试数据集
如表1所示，实验涵盖2D与3D空间下的点云、结构化网格、规则网格与非结构化网格。弹性力学（Elasticity）、塑性力学（Plasticity）、翼型（Airfoil）、管道（Pipe）、纳维-斯托克斯（Navier-Stokes）、达西流（Darcy）数据集由FNO（Li et al., 2021）与geo-FNO（Li et al., 2022）提出，已被广泛采用。此外，实验还包含汽车与翼型设计任务：  
- Shape-Net Car（Umetani & Bickel, 2018）：给定车辆形状，估计表面压力与周围空气流速；  
- AirfRANS（Bonnet et al., 2022）：包含美国国家航空咨询委员会（NACA）翼型的雷诺平均纳维-斯托克斯方程（RANS）高保真仿真数据。

**表1：实验基准测试数据集总结（含多种几何类型）**  
| 几何类型     | 基准测试任务                   | 维度    | 网格规模 |
| ------------ | ------------------------------ | ------- | -------- |
| 点云         | 弹性力学（Elasticity）         | 2D      | 972      |
| 结构化网格   | 塑性力学（Plasticity）         | 2D+时间 | 3,131    |
| 结构化网格   | 翼型（Airfoil）                | 2D      | 11,271   |
| 结构化网格   | 管道（Pipe）                   | 2D      | 16,641   |
| 规则网格     | 纳维-斯托克斯（Navier-Stokes） | 2D+时间 | 4,096    |
| 规则网格     | 达西流（Darcy）                | 2D      | 7,225    |
| 非结构化网格 | Shape-Net Car                  | 3D      | 32,186   |
| 非结构化网格 | AirfRANS                       | 2D      | 32,000   |


### 对比基线模型
我们将Transolver与20余种基线模型进行全面对比，包括：  
- 典型神经算子：FNO（2021）、U-NO（2023）、LSM（2023）等；  
- Transformer类偏微分方程求解器：GNOT（2023）、FactFormer（2023d）等；  
- 经典几何深度学习模型：PointNet（2017）、GraphSAGE（2017）、MeshGraphNet（2021）等。  

其中，LSM（Wu et al., 2023）与GNOT（Hao et al., 2023）是标准基准测试上的现有最优模型；GINO（Li et al., 2023a）与3D-GeoCA（Deng et al., 2024）是适用于大规模工业级仿真任务的先进深度模型。


### 实现细节
为保证公平性，设置模型层数$L=8$，隐藏特征通道数$C$根据输入数据的观测物理量数量设为128或256——确保模型参数规模与GNO（2023）、ONO（2024）等Transformer类模型相当。切片数量$M$根据隐藏维度从{32, 64}中选择，以平衡效率与性能。所有实验在单块NVIDIA A100 GPU上进行，且重复3次以确保结果可靠性。

除估计物理场的相对$L_2$误差外，还计算了实际设计任务中阻力系数与升力系数的误差及斯皮尔曼等级相关系数（Spearman’s rank correlation）。详细实现细节见附录B。


### 4.1 主要结果
#### 标准基准测试
为清晰对比Transolver与各类神经算子的性能，首先在6个广泛使用的标准数据集上进行实验——这些数据集可基于现有文献（Li et al., 2022; Wu et al., 2023; Hao et al., 2023）构建完整的性能排行榜。

如表2所示，Transolver在涵盖固体物理与流体物理、多种几何类型的6个标准基准测试中均实现当前最优性能。值得注意的是，Transolver在点云与结构化网格任务中性能提升显著（弹性力学25.6%、塑性力学29.4%、管道29.7%），验证了其处理复杂几何的有效性。

此外，OFormer、GNOT等先进Transformer类模型直接对网格点应用线性注意力，但在达西流基准测试中表现不佳。这是因为达西流任务需模拟流体在多孔介质中的压力分布，涉及介质边界处复杂的流固交互（Bungartz & Schäfer, 2006），而直接对海量网格点应用注意力会导致关联建模退化（Wu et al., 2022）。Transolver通过学习物理状态，可获取比单个网格点更丰富的几何令牌，并显著减少令牌数量，从而更有效地捕捉复杂流固交互。

**表2：标准基准测试性能对比（记录相对$L_2$误差，值越小性能越优）**  
| 模型                           | 点云（弹性力学） | 结构化网格（塑性力学） | 结构化网格（翼型） | 结构化网格（管道） | 规则网格（纳维-斯托克斯） | 规则网格（达西流） |
| ------------------------------ | ---------------- | ---------------------- | ------------------ | ------------------ | ------------------------- | ------------------ |
| FNO（Li et al., 2021）         | /                | /                      | /                  | /                  | 0.1556                    | 0.0108             |
| WMT（Gupta et al., 2021）      | 0.0359           | 0.0076                 | 0.0075             | 0.0077             | 0.1541                    | 0.0082             |
| U-FNO（Wen et al., 2022）      | 0.0239           | 0.0039                 | 0.0269             | 0.0056             | 0.2231                    | 0.0183             |
| geo-FNO（Li et al., 2022）     | 0.0229           | 0.0074                 | 0.0138             | 0.0067             | 0.1556                    | 0.0108             |
| U-NO（Rahman et al., 2023）    | 0.0258           | 0.0034                 | 0.0078             | 0.0100             | 0.1713                    | 0.0113             |
| F-FNO（Tran et al., 2023）     | 0.0263           | 0.0047                 | 0.0078             | 0.0070             | 0.2322                    | 0.0077             |
| LSM（Wu et al., 2023）         | 0.0218           | 0.0025                 | 0.0059             | 0.0050             | 0.1535                    | 0.0065             |
| Galerkin（Cao, 2021）          | 0.0240           | 0.0120                 | 0.0118             | 0.0098             | 0.1401                    | 0.0084             |
| HT-Net（Liu et al., 2022）     | /                | 0.0333                 | 0.0065             | 0.0059             | 0.1847                    | 0.0079             |
| OFormer（Li et al., 2023c）    | 0.0183           | 0.0017                 | 0.0183             | 0.0168             | 0.1705                    | 0.0124             |
| GNOT（Hao et al., 2023）       | 0.0086           | 0.0336                 | 0.0076             | 0.0047             | 0.1380                    | 0.0105             |
| FactFormer（Li et al., 2023d） | /                | 0.0312                 | 0.0071             | 0.0060             | 0.1214                    | 0.0109             |
| ONO（Xiao et al., 2024）       | 0.0118           | 0.0048                 | 0.0061             | 0.0052             | 0.1195                    | 0.0076             |
| Transolver（本文）             | **0.0064**       | **0.0012**             | **0.0053**         | **0.0033**         | **0.0900**                | **0.0057**         |
| 相对性能提升                   | 25.6%            | 29.4%                  | 10.2%              | 29.7%              | 24.7%                     | 12.3%              |

（注：最优结果加粗，次优结果下划线标注；“/”表示该基线模型不适用于该基准测试；“相对性能提升”指相对于次优模型的误差降低比例，计算方式为$1 - \frac{\text{本文模型误差}}{\text{次优模型误差}}$）


#### 实际设计任务
风洞测试是工业设计中的关键环节。如图4所示，为验证模型在复杂实际应用中的有效性，我们在模拟风洞场景中进行实验：  
- 汽车设计任务：模拟行驶中的汽车，记录其表面压力与周围空气流速，基于汽车表面几何估计这些物理场，并计算空气阻力；  
- 翼型设计任务：除不同翼型形状外，数据集还包含不同攻角与雷诺数的场景，更贴近实际飞行情况。  

这两项任务极具挑战性，需模型对混合几何类型进行多物理场仿真。

（图4：汽车与翼型设计任务。(a)Shape-Net Car：需估计行驶汽车的空气阻力；(b)AirfRANS：需估计飞行中飞机翼型的升力）

如表3所示，在这两项复杂任务中，Transolver在各类几何深度学习模型与神经算子中仍表现最优。除实现更精确的体积与表面物理场估计外，Transolver在设计导向指标（阻力系数、升力系数及斯皮尔曼等级相关系数）上也排名第一。需注意，斯皮尔曼等级相关系数衡量测试集中真实系数与模型估计系数的排名分布相关性，量化了模型对不同汽车/翼型设计的排序能力——该指标对形状优化至关重要。

此外，geo-FNO在Shape-Net Car任务中性能严重退化，原因是geo-FNO基于傅里叶基将输入几何投影到均匀latent网格，无法适配表面-体积混合几何；3D-GeoCA通过引入先进3D几何深度模型Point-BERT（Yu et al., 2022）作为特征编码器增强GNO性能，但即便如此，其性能仍不及Transolver。这些结果进一步验证了本文模型在偏微分方程求解中的优势。

**表3：实际设计任务性能对比（均为非结构化网格）**  
| 模型*                | Shape-Net Car（汽车） |                    |                        |                 | AirfRANS（翼型）   |                    |                        |                 |
| -------------------- | --------------------- | ------------------ | ---------------------- | --------------- | ------------------ | ------------------ | ---------------------- | --------------- |
|                      | 体积（相对$L_2$↓）    | 表面（相对$L_2$↓） | 阻力系数（相对$L_2$↓） | 阻力系数相关性↑ | 体积（相对$L_2$↓） | 表面（相对$L_2$↓） | 升力系数（相对$L_2$↓） | 升力系数相关性↑ |
| Simple MLP           | 0.0512                | 0.1304             | 0.0307                 | 0.9496          | 0.0081             | 0.0200             | 0.2108                 | 0.9932          |
| GraphSAGE（2017）    | 0.0461                | 0.1050             | 0.0270                 | 0.9695          | 0.0087             | 0.0184             | 0.1476                 | 0.9964          |
| PointNet（2017）     | 0.0494                | 0.1104             | 0.0298                 | 0.9583          | 0.0253             | 0.0996             | 0.1973                 | 0.9919          |
| Graph U-Net（2019）  | 0.0471                | 0.1102             | 0.0226                 | 0.9725          | 0.0076             | 0.0144             | 0.1677                 | 0.9949          |
| MeshGraphNet（2021） | 0.0354                | 0.0781             | 0.0168                 | 0.9840          | 0.0214             | 0.0387             | 0.2252                 | 0.9945          |
| GNO（2020a）         | 0.0383                | 0.0815             | 0.0172                 | 0.9834          | 0.0269             | 0.0405             | 0.2016                 | 0.9938          |
| Galerkin（2021）     | 0.0339                | 0.0878             | 0.0179                 | 0.9764          | 0.0074             | 0.0159             | 0.2336                 | 0.9951          |
| geo-FNO（2022）      | 0.1670                | 0.2378             | 0.0664                 | 0.8280          | 0.0361             | 0.0301             | 0.6161                 | 0.9257          |
| GNOT（2023）         | 0.0329                | 0.0798             | 0.0178                 | 0.9833          | 0.0049             | 0.0152             | 0.1992                 | 0.9942          |
| GINO（2023a）        | 0.0386                | 0.0810             | 0.0184                 | 0.9826          | 0.0297             | 0.0482             | 0.1821                 | 0.9958          |
| 3D-GeoCA（2024）     | 0.0319                | 0.0779             | 0.0159                 | 0.9842          | /                  | /                  | /                      | /               |
| Transolver（本文）   | **0.0207**            | **0.0745**         | **0.0103**             | **0.9935**      | **0.0037**         | **0.0142**         | **0.1030**             | **0.9978**      |

（注：“*”表示由于数据集为非结构化网格，部分基线模型不适用；典型神经算子（如U-NO、LSM）的非结构化网格处理能力基于geo-FNO（2022），但在复杂几何中性能严重退化；ONO、OFormer等Transformer类模型因海量网格点导致训练不稳定，未记录其性能；“/”表示该基线模型不适用于该任务）


#### 消融实验
除主要结果外，还对Transolver的设计进行了消融实验，结果如表4所示。总体而言，增加切片数量$M$可提升模型性能——这使模型能捕捉更细粒度的物理状态，但同时也会增加计算成本。为平衡效率与性能，在弹性力学、达西流任务中设$M=64$，在其他基准测试中从{32, 64}中选择$M$值。

需注意，当$M=1$时，物理注意力退化为全局池化算子，丢失所有物理关联，导致性能严重下降；而$M$过大（如1024）时，性能会略有下降——这可能是因为过大的$M$会导致物理域过度碎片化，使后续注意力计算面临过多令牌，引入干扰。原则上，最优切片数量取决于目标偏微分方程的物理特性，实验中$M$在32~256范围内易于调优。

此外，将可学习切片替换为固定大小（4×4）的规则方块会严重损害模型性能，即使对于原本离散为规则网格的达西流任务也是如此。该结果进一步验证了“捕捉物理状态”相比“仅在离散域中计算”的优势。

**表4：物理注意力机制的消融实验**  
| 消融设置            | 内存（GB） | 时间（秒/轮次） | 弹性力学（相对$L_2$） | 达西流（相对$L_2$） |
| ------------------- | ---------- | --------------- | --------------------- | ------------------- |
| 切片数量$M=1$       | 0.60       | 37.76           | 0.0148                | 0.0386              |
| $M=8$               | 0.60       | 37.82           | 0.0071                | 0.0096              |
| $M=16$              | 0.61       | 37.96           | 0.0067                | 0.0067              |
| $M=32$              | 0.62       | 38.00           | 0.0067                | 0.0063              |
| $M=64$              | 0.64       | 38.18           | 0.0064                | 0.0059              |
| $M=96$              | 0.68       | 38.31           | 0.0061                | 0.0055              |
| $M=128$             | 0.69       | 38.78           | 0.0058                | 0.0054              |
| $M=256$             | 0.81       | 39.13           | 0.0054                | 0.0050              |
| $M=512$             | 1.01       | 39.75           | 0.0059                | 0.0056              |
| $M=1024$            | 1.53       | 40.49           | 0.0068                | 0.0055              |
| 固定规则方块（4×4） | /          | /               | /                     | 0.0088              |

（注：效率指标基于1024个非结构化网格点、批次大小为1的输入计算；完整消融实验见附录C）


#### 效率分析
为进一步验证模型的实用性，图6对比了各模型的效率。可见，与其他Transformer类模型相比，Transolver在运行时间、GPU内存占用与模型参数方面均展现出优势：  
- 在弹性力学任务中，Transolver相比次优模型GNOT，误差降低25.6%（0.0064 vs 0.0086），参数数量减少5倍，运行速度提升1.3倍；  
- 对于大规模网格，线性复杂度的物理注意力机制优势更显著，Transolver在运行时间与性能上均超过Galerkin Transformer与OFormer。

（图5：弹性力学任务中物理注意力机制的可视化。(a)原始网格与重采样网格的Transolver最后一层切片权重；(b)Transolver与Galerkin Transformer（Cao, 2021）最后一层的注意力图。更多可视化结果见附录D.1）

（图6：弹性力学（972个网格点）与Shape-Net Car（32,186个网格点）任务的效率对比。指标基于批次大小为1、每轮次1000次迭代的实验；输入网格大小与效率的增长曲线见附录F）