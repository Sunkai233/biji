# 许可证信息
**License**: arXiv.org 永久非独占许可  
**arXiv**: 2508.17960v1 [eess.SP] 2025年8月25日  

# 统一变换器架构用于低延迟和可扩展的无线信号处理
**A Unified Transformer Architecture for Low-Latency and Scalable Wireless Signal Processing**  
**作者**: Yuto Kawai, Rajeev Koodli  
**机构**: 日本东京软银公司高级技术研究所  
**通信作者**: yuto.kawai@g.softbank.co.jp  

## 摘要
我们提出了一种基于变换器的统一架构，用于无线信号处理任务，提供了一种低延迟、任务自适应的替代传统接收器流水线的方法。与传统的模块化设计不同，我们的模型将信道估计、插值和解映射整合到一个单一的、紧凑的、注意力驱动的架构中，专为实时部署设计。该模型的结构通过简单修改最终投影层，允许动态适应多种输出格式，从而在接收器子系统中实现一致的复用。实验结果表明，该模型在不同用户数量、调制方案和导频配置下具有强大的泛化能力，同时满足实际系统施加的延迟约束。该架构在三种核心用例中进行了评估：(1) **端到端接收器**，取代了从导频符号到比特级决策的整个基带处理流水线；(2) **信道频率插值**，在符合3GPP标准的OAI+Aerial系统中实现和测试；(3) **信道估计**，模型从稀疏导频观测推断全频带信道响应。在所有用例中，我们的方法在准确性、鲁棒性和计算效率方面均优于经典基线。这项工作提出了一种可部署的、数据驱动的替代手工程PHY层模块的方法，为下一代无线通信系统中智能、软件定义的信号处理奠定了基础。

**索引词**: 5G移动通信，信道估计，深度学习，实时系统，无线接入网络

{

#### 这篇工作的核心点

作者提出了一种 **基于 Transformer（变换器）的新架构**，用于无线通信（比如 5G）里的信号处理。传统的无线接收机分成好几个独立的模块（信道估计 → 插值 → 解映射 → 解码），而这里作者把这些模块合并到一个统一的深度学习模型里。

------

#### 为什么要这样做？

1. **传统方法的痛点**
   - 模块多，流程复杂。
   - 每个模块是单独优化的，互相之间缺乏全局协调。
   - 实际运行时延可能比较大。
2. **新方法的优势**
   - 直接用一个“注意力机制驱动”的模型，把多个环节一起完成。
   - 架构紧凑，适合实时运行（低延迟）。
   - 模型只需要改最后一层，就能适配不同任务（比如输出比特、输出信道响应、输出插值结果）。

------

#### 模型能做什么？

作者在三个场景中测试了这个模型：

1. **端到端接收机**
   - 从导频符号直接推断出比特级结果，替代整个接收流水线。
2. **信道频率插值**
   - 在 3GPP 标准的 OAI+Aerial 系统中测试，从稀疏导频推断出完整频率信道。
3. **信道估计**
   - 直接根据导频符号，恢复全频带的信道响应。

}

## I. 引言
无线通信系统正在经历由移动流量激增、服务需求多样化和部署场景复杂性增加所驱动的范式转变。新兴应用——从需要近乎瞬时响应和完美可靠性的关键任务系统，到大规模传感器网络和沉浸式扩展现实（XR）——不仅要求高吞吐量和低延迟，还要求适应动态和异构信道条件的能力。这些趋势挑战了传统接收器的设计原则，传统接收器通常依赖于级联的信号处理模块——同步、信道估计、均衡、解映射和解码——使用具有手工调优启发式和强领域假设的确定性算法实现 [1, 2]。

虽然这种模块化设计在静态或适度动态的环境中表现良好，但在现代系统（如5G NR及更高级别）中，其局限性变得明显，这些系统中灵活的数字配置、MU-MIMO、动态调度和受干扰限制的部署是常见的。在这样的系统中，逐块优化可能导致次优的端到端性能，对导频模式或衰落统计的刚性假设常常在条件偏离设计时假设时导致脆弱性。此外，独立实现和调优每个模块使设计流水线复杂化，难以适应新的频谱带、载波聚合或硬件损伤。

在过去几年中，深度学习（DL）已成为这一范式的引人注目的替代方案 [3, 4, 5, 6, 7, 8, 9, 10, 11]。神经网络可以直接从数据中近似复杂的非线性映射，使其能够学习难以通过分析建模的统计模式。在物理层，基于DL的方法已被研究用于信道估计、均衡、解码，甚至端到端学习的通信系统，联合优化发送器和接收器设计。

从架构角度来看，卷积神经网络（CNNs）因其能够利用局部时频结构而被广泛使用，但它们通常受限于有限的感受野和固定的架构配置。相比之下，变换器架构 [12] 利用自注意力机制捕获时间、频率和空间维度的长距离依赖和结构化相关性，提供了对不同系统参数的更大适应性 [13]。这些特性与无线信道的特性高度契合，无线信道由于多普勒扩展、多径延迟和导频放置而表现出结构化相关性。

然而，大多数现有的基于变换器的无线研究仍停留在算法或仿真阶段，未能充分解决实时部署的约束——如延迟预算、内存和功耗限制以及与标准化无线协议栈的集成 [14, 15]。本文通过提出一种专为无线信号处理量身定制的基于变换器的架构，直接解决这一差距。与从语言或视觉任务的通用适应不同，我们的设计直接在资源元素上操作，结合了与OFDM对齐的位置编码，并在早期层保留信号幅度。该架构紧凑、模块化且可适应多种PHY层任务，无需重新设计。

我们验证了所提出的模型在三种代表性用例中的性能，每种用例突出显示了实际部署和架构灵活性的不同方面：

- **端到端接收器**：替换信道估计到解映射链的可插入式替代方案，可适应各种天线设置、调制方案和用户密度。
- **信道频率插值**：使用符合3GPP标准的协议栈 [16] 进行实时空中验证，强调在实际干扰条件下的部署准备。
- **信道估计**：无需架构更改的模块化PHY层评估，展示了共享变换器骨干的多样性。

这些结果共同表明，统一的注意力基础骨干可以作为下一代AI原生接收器的构建模块，支持对单个处理模块的细粒度推理和完整的端到端操作。

本文的其余部分组织如下：第二节详细调研了物理层设计中深度学习的相关工作。第三节介绍了所提出的变换器架构及其信号域适应。第四节详细描述了每个用例的实现和相应评估。第五节讨论了部署权衡、可扩展性和可解释性。第六节概述了未来研究方向，第七节总结了本文。

{

#### 引言通俗版

#### 1. 为什么要做这件事？

现在的无线通信（比如 5G，未来的 6G）面临很多新挑战：

- 流量越来越大，应用越来越多样（比如 **自动驾驶、远程手术、虚拟/扩展现实 XR**）。
- 不仅要 **高速率、低延迟**，还要能适应 **复杂、多变的信道环境**。

而传统接收机的工作方式是“模块化流水线”：

1. 同步
2. 信道估计
3. 均衡
4. 解映射
5. 解码

这些模块各自优化，看似合理，但在复杂环境里就容易出问题：

- 模块之间缺少整体协调，导致整体性能不够好。
- 需要很多人工假设（比如某种衰落模型），一旦环境不符合假设就会很脆弱。
- 每个模块要单独调试，遇到新频段、新硬件，就得重新设计，麻烦又慢。

------

#### 2. 深度学习能带来什么？

深度学习（DL）近年来在通信领域很火：

- 神经网络能直接从数据里学复杂的规律，而不用人工推公式。
- 研究者已经尝试过用 DL 做 **信道估计、均衡、解码**，甚至直接搞 **端到端通信系统**（发射器和接收器一起学）。

CNN（卷积神经网络）在物理层用得多，因为它能捕捉局部的时频结构。但它有缺点：

- 感受野有限，看不到长距离的依赖。
- 架构固定，适应性不强。

相比之下，**Transformer（变换器）** 很有优势：

- 用自注意力机制，能捕捉 **时间、频率、空间上的长距离依赖**。
- 能适应不同的系统参数和信道条件。
- 特别适合无线信道这种有多径、多普勒效应、导频稀疏等复杂结构的情况。

------

#### 3. 现实中的问题

不过，大部分基于 Transformer 的研究还停留在仿真层面，没有解决 **真正部署** 的难题：

- 延迟太高，达不到实时要求。
- 占用内存、电耗太大。
- 和标准通信协议（比如 3GPP）集成不好。

------

#### 4. 本文提出的新方法

作者提出了一种 **专门为无线信号处理设计的 Transformer 架构**：

- 直接在 OFDM 的 **资源单元** 上操作，和物理层信号结构贴合。
- 用特殊的位置编码和幅度保持策略，让网络更适合无线信号。
- 架构紧凑，延迟小，能同时处理多种物理层任务，不用每次都重新设计。

------

#### 5. 验证方法

作者在三类实际任务中验证了模型：

1. **端到端接收机**：替代从信道估计到解映射的整段链路，能适应不同天线、调制和用户数量。
2. **信道频率插值**：在 3GPP 标准的 OAI+Aerial 系统中做了实时测试，证明能抗干扰、可部署。
3. **信道估计**：直接从稀疏导频恢复全频带信道，不需要修改架构。

}



## II. 相关工作
深度学习（DL）方法在无线通信中迅速获得关注，为传统的基于块的物理层设计提供了一种数据驱动的替代方案 [1, 2]。早期研究主要集中在替换接收器流水线中的单个组件，如信道估计 [3, 4, 17]、均衡 [5, 6] 和解码 [7, 8]。这些系统通常利用卷积神经网络（CNNs），利用其捕获时频信号表示中局部空间和频谱相关性的能力。值得注意的是，DeepRx [18] 表明，完全卷积神经接收器可以取代传统的估计和检测模块，采用统一架构，在OFDM系统中实现比LMMSE基线更高的鲁棒性和更低的延迟。

为了应对5G NR中MU-MIMO系统和灵活导频分配的日益复杂性，Cammerer 等人 [19] 提出了一种基于混合CNN-GNN的端到端接收器。其模型在不同用户数量和导频模式下表现出色，凸显了将几何结构融入神经架构的益处。同时，另一研究流通过自编码器框架探索端到端学习 [9, 8, 7]。这些系统针对特定信道联合优化发送器和接收器，实现了定制调制方案，并在非线性或硬件受损环境中显示出优于经典设计的增益 [10, 11]。

然而，早期基于CNN或自编码器的模型往往难以捕获宽带信号、长符号持续时间或多天线空间结构的全局依赖。为了克服这些限制，研究人员开始将最初为自然语言处理（NLP）开发的变换器架构应用于无线信号处理任务。变换器中的自注意力机制提供了一种自然的方式来建模符号间和载波间的关系，使其非常适合多径衰落、干扰和非平稳性的无线环境。

Channelformer [20] 和 SigT [21] 是首批将变换器应用于信道估计和联合均衡任务的模型。这些模型在信道模型上的准确性和泛化能力优于CNN基线。Comm-Transformer [22] 将框架扩展到频域输入，表明注意力机制即使在稀疏导频的情况下也能优于经典插值。Leng 等人 [23] 的额外工作引入了尊重I/Q数据结构的复值变换器，改进了相位敏感系统中的估计和检测。

变换器还在毫米波和OTFS系统中进行了探索 [24, 25]，用于建模延迟-多普勒稀疏性和角度分辨率。结合CNN前端和变换器注意力后端的混合架构 [26, 27] 被提出作为延迟高效的替代方案，结合局部和全局特征提取。

最近，Khawaja 等人 [28] 提出了大型无线模型（LWM），一种基于变换器的基础模型，通过对大规模、多样化无线数据集进行掩码信道建模进行训练。LWM专注于学习可重用于下游任务的通用信道嵌入，在表示学习中显示出强大性能。然而，它并未针对延迟敏感的基带接收器部署，也未评估实时或空中（OTA）集成。

尽管取得了这些有前景的结果，大多数研究——包括LWM——在仿真中评估模型，未评估实时可行性或符合3GPP系统约束的兼容性。

变换器基接收器的实际部署面临几个挑战。自注意力的二次复杂性对长OFDM符号、大带宽或大规模MIMO阵列构成问题 [29, 30, 31]。此外，将这些模型集成到现实世界的无线协议栈（如受3GPP标准约束的协议栈）需要考虑硬件感知的设计和改进的可解释性。近期调查 [1, 14, 15] 和3GPP Release-18关于NR空中接口AI/ML的研究 [32, 33, 34] 强调了AI/ML在PHY和空中接口的潜力，同时指出在鲁棒部署、测试和大规模可靠性方面需要进一步工作。

为解决这些限制，我们提出了一种专为无线信号处理量身定制的统一变换器架构。与特定任务设计不同，我们的模型紧凑、模块化，并在仿真和实时OTA测试中得到验证。通过三种用例——端到端接收器、信道频率插值和信道估计——我们展示了模型在满足实际部署约束（如延迟、吞吐量和任务通用性）的同时，匹配或超越经典算法的能力。

{

#### 相关工作通俗版

#### 1. 深度学习进入无线通信

过去几年，深度学习（DL）在无线通信里越来越火，被用来替代传统的“模块化设计”方法。

- 早期研究主要是 **替代接收机流水线的某个环节**，比如：
  - **信道估计**：预测信道情况
  - **均衡**：消除信道失真
  - **解码**：把符号转成比特
- 很多研究用 **卷积神经网络（CNN）**，因为它擅长抓住时频信号中的局部规律。
- 比如 **DeepRx**，它用纯CNN替代传统接收机的多个模块，在OFDM系统里比经典的 LMMSE 方法更稳健、延迟更低。

------

#### 2. 更复杂的5G环境

5G 里面有很多新难点：

- **多用户多天线 (MU-MIMO)**
- **灵活的导频分配**
   这些情况让传统方法很难处理。
   于是，有人提出混合模型：
- **CNN + GNN**（图神经网络），比如 Cammerer 等人的工作，能同时适应不同的用户数量和导频模式。
- **端到端自编码器**，把发射机和接收机联合起来学，甚至能自动学出新的调制方式，比传统设计更能适应非线性或硬件缺陷。

------

#### 3. CNN 和自编码器的不足

这些方法的局限是：

- 对 **宽带信号** 或 **长符号持续时间** 效果不好。
- 难以处理 **多天线的空间结构**。
   换句话说，它们只能看局部，不能捕捉全局依赖。

------

#### 4. Transformer 的引入

于是，研究人员把 **最早用在自然语言处理的 Transformer** 搬到了无线通信领域。

- 自注意力机制能很好地建模 **符号之间、子载波之间的关系**。
- 对 **多径衰落、干扰、非平稳信道** 特别合适。

一些代表性工作：

- **Channelformer、SigT**：做信道估计和均衡，比CNN更准、更能泛化。
- **Comm-Transformer**：即使导频很稀疏，也能优于传统插值方法。
- **复数形式的Transformer**（Leng等人）：专门处理 I/Q 复信号，对相位敏感的任务更好。
- 在毫米波和 OTFS 系统里，Transformer 也被用来建模时延、多普勒和角度稀疏性。
- **混合架构**：CNN做前端特征提取，Transformer做后端长距离建模，这样能兼顾效率和准确性。

------

#### 5. 大规模无线模型

最近，有个趋势是做 **大模型**：

- **LWM（Large Wireless Model）**：类似语言大模型，用 Transformer 在海量无线数据上做预训练，学通用的“信道表示”，之后可以迁移到各种下游任务。
- 效果很好，但问题是：
  - 没有考虑实时部署（延迟、电耗）。
  - 没有和真实的 3GPP 协议栈深度集成。

------

#### 6. 现存挑战

虽然Transformer在无线通信里效果很亮眼，但真正部署时有很多困难：

- **计算复杂度高**（尤其是长OFDM符号、大带宽、大规模MIMO）。
- **如何接入3GPP标准协议栈**，还得考虑硬件限制。
- **可解释性不足**，实际系统难以直接采用。
   3GPP的 Release-18 已经开始关注 AI/ML 在物理层的应用，但也强调要解决鲁棒性、测试和大规模可靠性问题。

------

#### 7. 本文的突破

针对这些问题，作者提出了一个 **统一的、专为无线信号处理设计的 Transformer 架构**：

- 模型小巧、模块化，能适应多种任务。
- 不仅在仿真中测试，还在 **真实无线环境（OTA测试）** 中验证过。
- 三个用例：端到端接收机、信道频率插值、信道估计。
- 在满足 **实时延迟、吞吐量** 的条件下，性能可以和经典算法打平，甚至更好。

}

## III. 提出的变换器架构
所提出的基于变换器的架构是一个紧凑且延迟感知的模型，专为无线信号处理设计。与依赖于顺序和特定领域信号处理模块（如信道估计、均衡和解映射）的传统接收器不同，我们的架构将这些操作统一到一个单一的数据驱动模型中。其设计强调实际可部署性，在多种任务（包括端到端接收器、信道频率插值和信道估计）中提供高准确性和计算效率。

虽然该模型包含标准的变换器组件，如自注意力和前馈层，但其整体设计专为无线信号处理定制。与通用变换器架构不同，我们的模型以单个资源元素的粒度处理信号，省略了不适合物理层数据特性的架构组件——如早期归一化或基于补丁的标记化。相反，该架构反映了无线系统的独特需求，其中绝对信号幅度、逐元素分辨率和实时推理能力至关重要。这导致了一个任务自适应但计算效率高的模型，适合在5G及更高级别严格延迟约束下的部署。

### III-A. 架构概述
模型的输入由时频结构张量组成，可选地包括空间维度，如天线索引，如图1所示。这些张量沿时间和频率轴展平，形成资源元素（REs）的序列，代表单个OFDM符号和子载波。对每个RE独立应用密集投影，将其他维度（例如天线）的相关特征嵌入到共享特征空间中。这使模型能够将每个RE视为独立标记，同时保留逐元素预测所需的分辨率。

随后应用位置编码层，注入时间和频率上下文，允许注意力机制学习RE之间的依赖关系。与典型变换器不同，我们在早期阶段省略层归一化以保留信号幅度，这对于涉及信道估计和物理层重构的任务至关重要。

编码后的RE标记通过一个或多个多头自注意力（MHSA）层和前馈网络进行处理。这些层建模频率和时间维度的相关性，捕获多径传播和符号间干扰等效应。重要的是，实验结果表明，过度增加注意力头数并不会提高性能，从而允许我们保持架构简单性。

在变换器编码器之后，由层归一化、MLP和最终密集投影组成的一个轻量级后处理堆栈生成特定任务的输出。这些操作独立应用于RE，确保模型可用于逐元素回归（例如信道估计）和分类（例如比特解码）任务。

**输入**  
**重塑**  
**密集**  
+  
**位置编码**  
**层归一化**  
+  
**层归一化**  
**MLP**  
+  
**层归一化**  
**MLP**  
**密集**  
**重塑**  
**输出**  
× num_layers  
**多头注意力**  
× num_heads  

**图1**：所提出的延迟感知变换器架构概述。模型在资源元素级嵌入上操作，省略早期归一化，并通过特定任务的输出头支持多种PHY层任务。

**默认实例化**  
除非另有说明，我们使用四层编码器和每层四个注意力头的统一变换器进行实例化。这作为跨任务的一致参考配置，因其在我们初步实验中的普遍强大性能而选择，而不是特定任务优化的结果。在某些情况下——如信道频率插值——使用较轻的变体（例如，单层编码器），在相应特定任务部分中说明此类偏差。

### III-B. 任务适应性和部署
所提出架构的一个关键特性是其使用共享骨干支持多种无线信号处理任务的能力。这通过仅修改最终输出投影和选择适当的损失函数实现，而不更改核心模型结构。具体来说：

- **端到端接收器**：模型输出软比特或比特概率，使用二元交叉熵（BCE）损失进行训练，目标是均衡和解映射后的比特级决策。
- **信道频率插值**：模型预测未观测频率位置的复值信道系数，使用预测值与真实信道值之间的均方误差（MSE）损失进行计算。
- **信道估计**：模型重建时间和频率上的完整信道响应。此回归任务也使用MSE损失，应用于资源块内的所有子载波和OFDM符号。

尽管输出目标不同，底层架构保持不变。这种设计支持模块化部署——模型替换特定处理阶段——和端到端集成——模型包含多个模块，如信道估计和解映射。

训练以监督方式使用从模拟或真实空中信号导出的标记数据集进行。为了增强跨部署场景的泛化能力，我们应用了数据增强策略，如变化SNR水平、信道模型和天线排列。

模型还针对延迟敏感环境进行了优化。其轻量结构——有限的注意力头数和浅层深度——在OAI+Aerial平台 [16] 的实时OTA评估中实现了亚毫秒PUSCH流水线执行，满足5G NR系统中HARQ反馈和动态调度的时序要求。

{

#### 提出的变换器架构（通俗解释）

#### 1. 和传统接收机的区别

传统的无线接收机是“流水线式”的：

- 先做 **信道估计**
- 再做 **均衡**
- 然后做 **解映射**
- 最后才得到比特结果

而本文提出的 **变换器架构**，把这些环节 **合并到一个统一的神经网络里**，不再是一个个模块串联。这样做的好处是：

- **更简洁**（一个模型搞定多个任务）
- **更灵活**（可以适应不同任务，只需改最后输出层）
- **低延迟**（能满足 5G/6G 的实时要求）

------

#### 2. 架构的主要特点

虽然用的是标准 Transformer 的自注意力和前馈网络，但它专门针对无线信号处理做了改造：

- **操作粒度：资源元素（RE）**
   在无线系统里，最小的时频单元叫做 **资源元素**（一个子载波 × 一个 OFDM 符号）。
   模型就是在 RE 粒度上直接处理信号的，不像图像处理那样做“切 patch”。
- **保留幅度信息**
   无线信号的绝对幅度很重要（比如做信道估计时），所以模型 **省略了早期归一化层**，避免把幅度信息冲掉。
- **位置编码**
   在时间和频率维度上加上位置信息，让注意力机制能理解 RE 之间的依赖关系（比如符号间干扰、多径效应）。
- **轻量化设计**
  - 注意力头数不多（4个就够了），层数也少（默认4层）。
  - 保证计算效率，适合实时部署。

------

#### 3. 架构流程（简化版）

1. **输入**：接收信号的时频张量（可能带天线维度）。
2. **重塑 + 投影**：把每个 RE 映射到一个共享的特征空间。
3. **位置编码**：加入时间/频率位置信息。
4. **Transformer 编码器**：多头自注意力 + 前馈网络，建模时频相关性。
5. **后处理**：层归一化 + MLP + 最终投影，输出具体任务结果。

可以理解为：**输入是一串“时频单词”，Transformer 把它们理解成“上下文相关的信号”，再输出不同的任务结果。**

------

#### 4. 任务适应性

这个模型的强大之处在于：只要改输出层，就能适配不同任务：

- **端到端接收机**
  - 输出：比特概率
  - 损失函数：二元交叉熵（BCE）
- **信道频率插值**
  - 输出：未观测子载波的复数信道值
  - 损失函数：均方误差（MSE）
- **信道估计**
  - 输出：完整的信道响应（时频二维）
  - 损失函数：均方误差（MSE）

底层架构完全一样，只有最后一层输出不同。

------

#### 5. 训练与部署

- **训练**：用带标签的数据集（来自仿真或真实信号），加上数据增强（随机 SNR、信道模型、天线配置），提升泛化能力。
- **部署**：
  - 模型很轻量，延迟小。
  - 在 OAI+Aerial 平台做了真实的 OTA 测试，端到端处理可以在 **1 毫秒内完成**，满足 5G HARQ 等实时要求。

------

✅ **一句话总结**：
 这是一个 **为无线信号量身定制的 Transformer**，轻量、低延迟，可以“一套骨干，多种任务”，在实际 5G 系统里也能跑起来。

}

## IV. 实证验证
我们通过三种代表性用例验证了所提出的变换器架构，每种用例针对无线信号处理的不同方面，并在不同环境下进行评估：

- **端到端接收器（仿真）**：通过替换从信道估计到解映射的整个接收器链展示端到端能力。使用Sionna框架在符合3GPP的CDL-C信道上进行链路级仿真评估，突出显示对用户数量、导频结构和调制方案的适应性。
- **信道频率插值（OTA）**：通过在OAI+Aerial堆栈中进行空中（OTA）评估，验证实时推理性能。此任务强调在严格延迟和系统集成约束下的部署可行性。
- **信道估计（仿真）**：作为一个独立的回归任务，展示模型在无需架构修改的情况下对传统PHY层模块的适用性和通用性。通过基于Sionna的仿真与符合3GPP的CDL-C信道进行评估。

所有用例共享相同的核心变换器骨干。仅调整输出投影和损失函数以适应每个任务。这种设计表明，单一模型可以支持从比特级决策到信道重构的多种处理角色，涵盖仿真和现实世界的OTA环境，而无需重新训练整个系统。

以下小节详细描述了每个任务的配置、目标和评估，全面评估了模型在不同部署环境下的灵活性、效率和性能。

### IV-A. 端到端接收器
此任务评估了所提出的变换器作为全栈端到端接收器的能力，替换从信道估计到解映射和比特恢复的整个传统接收器链。模型直接推断每个资源元素（RE）传输比特的对数似然比（LLR），从原始接收信号实现完整的端到端解码，而无需中间模块。

我们研究了两个主要实验设置：

1. **单用户（1UE），导频固定**：用于与现有基线模型（例如，基于CNN、LS+MMSE）直接比较的控制设置。
2. **多用户（2UE），导频随机**：评估模型在用户间干扰和可扩展性方面的鲁棒性的实际MU-MIMO配置。

在这两个设置中，模型共享相同的变换器架构。输入以12子载波×14 OFDM符号的非重叠瓦片形式处理，确保对任意帧持续时间的可扩展性。输出维度由用户数量和调制顺序决定，模型训练为同时生成所有LLR比特。这允许灵活解码任何调制格式（例如，QPSK、64-QAM），通过仅选择与格雷编码信号空间对齐的相关比特——无需重新训练即可动态适应变化的MCS。

#### IV-A1. 实验设置
评估使用Sionna框架与符合3GPP的CDL-C信道进行。表I总结了仿真的关键参数。

**表I**：端到端接收器评估的仿真参数  
| 参数               | 值                                       |
| ------------------ | ---------------------------------------- |
| 载波频率           | 3.5 GHz                                  |
| 子载波间隔         | 30 kHz                                   |
| 每时隙OFDM符号数   | 14                                       |
| 每RB子载波数       | 12                                       |
| 调制方案           | 256-QAM                                  |
| 天线配置           | 上行：1或2个UE（每个1个Tx），基站：4个Rx |
| 信道模型           | CDL-C                                    |
| $$ E_b/N_0 $$ 范围 | 0–40 dB                                  |
| 训练样本           | 100k                                     |
| 损失函数           | 二元交叉熵（BCE）                        |
| 评估框架           | Sionna (TensorFlow)                      |

我们将基于变换器的端到端接收器与一系列基线进行比较：

- **基于CNN的端到端接收器**：Sionna框架提供的单用户模型参考实现1  
  1https://github.com/NVlabs/sionna  
  为确保公平比较，我们使用公开版本，未进行架构修改。
- **完美CSI**：使用真实信道系数结合MMSE检测的理想化参考。
- **LS估计+线性插值**：在导频位置通过最小二乘法（LS）进行信道估计，随后在时间和频率上进行二维线性插值。
- **LS估计+最近邻插值**：非导频位置分配最近的DMRS观测值。

注意，CNN基线仅在单用户设置中评估，因为提供的参考实现不支持多用户处理。虽然技术上可以扩展到MU-MIMO，但我们限制评估于公开版本以确保可重复性和公平性。

#### IV-A2. 实验结果
**1UE：导频固定基线比较**  
图2显示了单用户SIMO设置下的BLER。变换器显著优于基于LS的基线，并超越基于CNN的模型，接近完美CSI参考。

**参考说明**  
**图2**：单用户SIMO（1UE，4Rx）中的BLER。变换器与CNN、LS和完美CSI的比较。

**2UE：导频随机MU-MIMO评估**  
图3展示了2用户MU-MIMO设置的BLER性能。在没有任何专用分离模块的情况下，变换器仍实现接近完美CSI基线的强大性能，并显著优于传统的LS+MMSE流水线。

**参考说明**  
**图3**：2用户MU-MIMO中的BLER：变换器与LS和完美CSI的比较。

**2UE：架构敏感性（层深度）**  
为评估模型深度的影响，图4展示了在2用户MU-MIMO场景中，固定头数下1至4层变换器模型的BLER性能。从1层到2层性能显著提高，但进一步增加深度仅带来边际增益。2层模型已接近完美CSI界限，4层模型性能饱和。这些结果突出了所提出架构的关键优势：使用浅层、低延迟模型即可实现高性能——这对实时系统的实际部署至关重要。

**参考说明**  
**图4**：2用户MU-MIMO中不同变换器深度（1–4层）的BLER性能。

**2UE：架构敏感性（注意力头数）**  
图5展示了固定层深度下不同注意力头数（1–8头）的BLER曲线。模型在此范围内表现出稳定性能，即使单头配置也与多头变体性能相当。这种鲁棒性表明高头数并非必需，可进一步降低复杂性和延迟而不牺牲准确性。

**参考说明**  
**图5**：2用户MU-MIMO中不同注意力头数（1–8头）的BLER性能。

这些发现共同表明，所提出的变换器架构在现实MU-MIMO条件下保持高性能，同时对架构简化表现出惊人的容忍度。使用浅层深度和最少注意力头有效运行的能力使其成为可扩展、低延迟无线部署的实用选择。

### IV-B. 信道频率插值
我们接下来验证了变换器模型在信道频率插值任务中的多功能性，该任务要求在实际部署约束下实现细粒度的估计精度。与端到端接收器或信道估计不同（它们操作于完整端到端解码），此任务专注于从稀疏导频重构缺失的频域信道值，使其成为代表性的低级信号处理应用。

我们在OAI+Aerial框架下使用空中（OTA）条件部署模型，在SIMO设置（1 UE，4基站Rx）中评估实时推理性能。目标是从每个资源块内6个子载波和2个符号的稀疏DMRS导频恢复12个子载波和2个OFDM符号的完整信道响应。每个输入/输出被视为跨一个RB和一个时隙（12 SC × 14 sym）的单元，与5G NR数字配置一致。

变换器模型接收一个 $$ (6 \times 2 \times 2) $$ 输入张量——6个导频子载波 × 2个符号 × 2（实部和虚部）——并输出一个 $$ (12 \times 2 \times 2) $$ 张量，用于在相同2个OFDM符号上进行全频带插值。由于此任务中天线间相关性较弱，四根接收天线在训练期间被视为独立样本。

**表II**：频率插值任务的OTA参数  
| 参数       | 值                                |
| ---------- | --------------------------------- |
| 载波频率   | 3.5 GHz                           |
| 子载波间隔 | 30 kHz                            |
| DMRS模式   | $$ 6 \times 2 $$（子载波 × 符号） |
| 插值目标   | $$ 12 \times 2 $$                 |
| 天线配置   | 1 UE（1 Tx），1基站（4 Rx）       |
| 调制方案   | QPSK                              |
| 信道模型   | OTA测量                           |
| SNR范围    | OTA测量                           |
| 训练样本   | 220k                              |
| 损失函数   | MSE                               |
| 评估框架   | OAI+Aerial                        |

为准备OTA兼容的训练数据，我们采用混合仿真-捕获方法。传输信号 $$ x $$ 使用Sionna PUSCH发送器重新生成，输入从FAPI日志提取的捕获传输块（TB）。这允许我们恢复每资源元素的信道为 $$ \hat{h} = \frac{y}{x} $$，使用前传捕获的I/Q样本 $$ y $$。

为引入训练鲁棒性，我们通过注入受控AWGN噪声 $$ n $$ 增强数据，形成扰动输入 $$ y' = \frac{y + n}{x} $$，以原始 $$ \frac{y}{x} $$ 作为真实值。这种技术模拟了现实退化，迫使模型在可变干扰条件下泛化。

**室内**  
**OAI L2+**  
**Aerial**  
**RU**  
**UE**  
**FAPI DB**  
**FH DB**  
**Sionna**  
**PUSCH发送器**  
**信道计算** $$ h = \frac{y}{x} $$  
**添加AWGN** $$ h' = \frac{y + n}{x} $$  
**AI信道插值**  
**MSE评估**  
**传输信号** $$ x $$  
**PUSCH配置**  
**传输比特** $$ b $$  
**接收信号** $$ y $$  

**图6**：信道频率插值模型的训练流水线。

OTA评估在具有视线（LoS）配置的受控室内环境中进行。为模拟干扰，可编程信号发生器在PUSCH传输期间并发传输类OFDM噪声。我们将变换器模型与内部8层ResNet-based CNN基线进行比较，后者替换了默认Aerial PHY流水线，并执行端到端信道估计和频域插值。

为最小化延迟和资源消耗，此任务中使用的变换器模型配置为仅1层和1个注意力头，与其他任务中使用的较深的4层4头配置形成对比。这一设计选择反映了频率插值的相对简单性质，并强调模型对轻量级部署设置的适应性。所有推理测量均在NVIDIA GH200超级芯片上使用TensorRT进行。

**参考说明**  
**图7**：OTA评估：不同干扰水平下的上行吞吐量（变换器：1L1H，CNN基线）。

如图7所示，变换器模型在不同干扰水平下始终实现高于基于CNN基线的上行吞吐量。值得注意的是，尽管使用了高度紧凑的变换器配置，这一性能增益依然实现，进一步凸显了架构在低复杂性设置中的有效性。

虽然吞吐量是通信性能的关键指标，但处理延迟在现实世界部署中同样至关重要，特别是在5G及更高级别的时敏PUSCH链中。为此，我们测量了OTA实验期间每次PUSCH流水线调用的平均执行时间——即上行PUSCH链的端到端处理时间，包括模型块以及周围的预/后处理和张量转换。

**表III**：OTA评估期间的平均PUSCH流水线执行时间  
| 模型           | 平均PUSCH流水线时间 [μs] | 相对加速   |
| -------------- | ------------------------ | ---------- |
| 变换器（1L1H） | 337.70                   | 1.36× 更快 |
| CNN            | 458.84                   | 基线       |

如表III所示，紧凑的变换器模型实现了337.70 μs的较低平均PUSCH流水线时间，相较于CNN基线的458.84 μs，相当于1.36×的加速。这些结果表明，即使在严格的延迟和硬件约束下，所提出的变换器架构也能通过紧凑的模型占用空间减少端到端上行处理时间。

### IV-C. 信道估计
我们最后评估了所提出的变换器模型在信道估计任务中的性能——一项基本的PHY层操作，旨在从接收信号中恢复时间-频率资源块（RB）上的完整信道响应。此任务代表传统的信号处理问题，使我们能够验证模型在端到端或基于导频推理之外的架构通用性。

与频率插值任务（基于稀疏放置的导频重构缺失子载波）不同，信道估计旨在恢复整个时频信道矩阵，包括导频和数据资源元素。模型训练为推断RB内12个子载波和14个OFDM符号的整个复值信道表面。

模型的输入是一个RB的接收信号 $$ y $$，其中 $$ y $$ 隐式编码了无线信道、调制和噪声的影响。模型输出信道矩阵 $$ h $$ 的估计 $$ \hat{h} $$，其中每个复数条目由两个实值分量（实部和虚部）表示。因此，输出张量形状为每接收天线的 $$ (12 \times 14 \times 2) $$。

**表IV**：信道估计的仿真参数  
| 参数       | 值                          |
| ---------- | --------------------------- |
| 载波频率   | 3.5 GHz                     |
| 子载波间隔 | 30 kHz                      |
| RB大小     | 12 SC × 14 sym              |
| 天线配置   | 1 UE（1 Tx），1基站（4 Rx） |
| 调制方案   | 256-QAM                     |
| 信道模型   | CDL-C（3GPP）               |
| 损失函数   | 均方误差（MSE）             |
| 评估框架   | Sionna (TensorFlow)         |

为训练模型，我们采用监督学习设置，使用在不同 $$ E_b/N_0 $$ 条件下通过CDL-C模型生成的合成数据。真实信道 $$ h $$ 从仿真中解析计算，模型优化为最小化 $$ \hat{h} $$ 和 $$ h $$ 在整个RB上的MSE。

我们将模型与三个基线比较：

- **完美CSI**：使用真实信道系数作为参考（上限）。
- **LS估计+线性插值**：在DMRS位置应用最小二乘估计，随后在时间和频率上进行二维线性插值。
- **LS估计+最近邻插值**：使用最近导频分配填充非DMRS位置。

**参考说明**  
**图8**：仿真结果：不同方法下的信道估计BLER。

图8显示，变换器在所有 $$ E_b/N_0 $$ 下显著优于基于LS的基线，始终实现较低的估计误差。在较高 $$ E_b/N_0 $$ 下，模型性能接近完美CSI参考，表明它可以通过利用接收信号中的全局依赖，有效推断导频位置之外的信道结构。

这些结果证明了模型在低 $$ E_b/N_0 $$ 环境中的鲁棒性和泛化能力，强化了其作为从传统估计到端到端推理的无线信号处理任务通用架构的适用性。

## V. 讨论
本节分析了影响所提出变换器基接收器设计和部署的关键因素，包括架构权衡、训练行为、延迟约束和系统级集成。通过这些分析，我们提供了变换器模型在现实世界无线通信任务中的优势和局限性的见解。

### V-A. 变换器深度和注意力头数
变换器深度是模型表示能力的主要决定因素。在我们的实验中，我们观察到浅层配置——通常为一到四层——对于大多数任务足够，特别是在空间或时间信号多样性有限的场景（例如，单用户信道和短符号长度）。虽然更深的模型提供适度的性能增益，但在实时约束下，推理延迟和内存占用的增加往往超过了益处 [29, 13]。类似地，将注意力头数扩展到四以上显示出很少的益处，甚至可能导致过拟合，与之前对变换器中头冗余的观察一致 [35, 36]。这些观察表明，与语言或视觉任务不同，无线信号处理任务可能从架构简化和频率感知预处理中获益更多，而非通过扩展层或注意力头数。

### V-B. 延迟约束效率
满足亚毫秒延迟预算是O-RAN和URLLC等系统实际部署的关键要求。为此，我们的架构明确设计为最小化预处理开销、浅层变换器堆栈和标记高效输入格式。在NVIDIA GH200超级芯片上的运行时分析以及Aerial堆栈中的实时执行表明，推理时间远低于基站旁边的GPU装备边缘服务器的可接受范围。虽然我们的实验使用了高端数据中心GPU，但模型的紧凑性使其适合通过结构化剪枝、量化感知训练和硬件协同设计技术（如内核融合和TensorRT加速）在低功耗边缘GPU（例如，NVIDIA L4、Orin）上部署。

### V-C. 任务可扩展性和调制适应性
一个关键设计目标是支持多个接收器任务——如解映射、插值和估计——在共享变换器骨干内实现。这通过根据输出是软比特、信道状态矩阵或回归目标调整最终投影层和损失函数实现。模型还表现出调制适应性：当使用高阶星座（如256QAM）训练时，同一模型可以通过选择与格雷编码信号空间对齐的比特位置，泛化到低阶格式（如QPSK）。这使得单一模型能够跨适应调制和编码（AMC）方案部署，减少维护和存储开销。

### V-D. 系统集成和现实世界部署
除了仿真外，模型还在OAI+Aerial测试平台中通过与符合3GPP的基带堆栈集成进行了验证，展示了在受控但现实的射频环境中实时、空中操作的可行性。然而，在商业网络中的全面部署引入了额外要求：KPI可追溯性、调度鲁棒性、支持移动性和切换以及在干扰下的弹性。此外，管理ML生命周期的系统级流水线——如模型目录版本控制、区域感知微调和空中更新——随着学习基模块在RAN基础设施中的激增将变得越来越重要。

总体而言，我们的分析强调，变换器可以作为下一代接收器的统一处理模块，前提是架构决策基于特定领域的约束和部署要求。这些发现激励了进一步研究硬件感知设计、模块化和ML启用无线接入网络的生命周期管理。

## VI. 未来工作
基于本研究的发现，我们概述了即时下一步和更广泛的研究方向，旨在进一步增强基于变换器的架构在无线通信中的性能、效率和可部署性。这些努力旨在解决当前局限性，同时扩展到下一代无线系统中更多样化和复杂的场景。

### VI-A. 即时下一步
#### VI-A1. 扩展到非第一层任务
除了本工作中探索的第一层任务外，我们将评估所提出架构在非L1任务（例如，MAC层）中的泛化性，以评估其通用性并识别最佳性能所需的任务特定适应。

#### VI-A2. 改进位置编码
我们计划研究更适合结构化时频天线域的替代位置编码方案，目标是提高在多样化信道和导频配置下的性能。

#### VI-A3. 通过模型优化实现轻量级推理
为进一步降低推理延迟和能耗，我们将探索量化、剪枝和提前退出机制。这些方法将根据准确性-效率权衡及其对严格延迟预算下实时可部署性的影响进行评估。

#### VI-A4. 基于交叉注意力的信息压缩
我们将探索基于注意力的机制，选择性地将不太关键的输入特征总结为紧凑表示，从而在多任务操作时减少计算开销和功耗。

#### VI-A5. 任务集成效率评估
上述技术将在多个任务中联合评估，以量化运行时和能效的端到端增益，并为系统集成提供协同设计策略。

#### VI-A6. 信道动态鲁棒性
我们迄今的评估集中在低到中等移动性，尚未测试在高多普勒、快速瑞利衰落和其他快速变化条件下的鲁棒性。在当前资源网格（RG）输入设置中，此类变化可能在一个RG快照内捕获；然而，涉及多个连续RG或更长期依赖的场景——如跨时隙调度或HARQ过程——可能暴露变换器无状态设计和对位置编码依赖的局限性。潜在方向包括引入轻量机制以保持跨RG的时序上下文，或调整位置表示以在移动性引起的失真下保持稳定。

### VI-B. 更广泛的研究方向
#### VI-B1. 多模态和跨层学习
将多样化输入——CSI、SNR、移动性指标和调度元数据——整合到一个统一的学习流水线中，可以实现跨层优化策略并提高现实世界部署的鲁棒性。

#### VI-B2. 模型可解释性和可调试性
我们将检查注意力是否集中在导频位置，以及这些模式如何随干扰/移动性变化，并评估这些信号是否可以指导自适应导频设计或目标重新训练触发。

#### VI-B3. 标准化和系统级验证
扩展到具有真实流量配置的完全符合3GPP标准的场景评估，并开发分布式RAN部署的生命周期管理框架，对于操作采纳至关重要。

通过结合有针对性的短期努力和更广泛的探索性研究，我们旨在推进学习驱动的物理层技术，朝向未来无线系统中实用、高效和可信的部署迈进。

## VII. 结论
本文提出了一种统一的、延迟感知的基于变换器的架构，直接在资源网格上操作，并可使用紧凑的自注意力骨干替代多个PHY模块——信道估计、均衡和解映射。该设计针对严格延迟预算下的实时可行性，同时保持跨任务的适应性。

我们在三种代表性任务上验证了该方法：端到端接收器、信道频率插值和信道估计。在端到端接收器设置中，模型处理从导频观测到比特级决策的完整流水线，并在不同调制顺序和用户数量下保持强大性能。对于信道频率插值，模型集成到符合3GPP的OAI+Aerial堆栈中并进行空中评估，确认了现实世界的可行性。在信道估计中，模型从稀疏导频重构信道，并优于使用线性插值和最近邻插值的经典LS方法。

跨任务，单一骨干与轻量级任务特定头提供了鲁棒的准确性和推理效率，仅需最小的更改即可适应输出格式和目标。

开放挑战包括提高在快速变化操作条件（例如，高多普勒和突发干扰）下的泛化能力，通过压缩和提前退出策略增强严格延迟和能耗预算内的效率，优化多样化导频布局的位置表示，以及开发暴露导频信息利用方式的可解释性和监控工具。此外，需要标准化的KPI驱动的全栈评估和生命周期感知的部署实践，以弥合原型和生产之间的差距。

总之，我们的工作突出了任务自适应、基于注意力的架构在下一代通信系统中替代手工程信号处理链的潜力。通过在多种PHY层任务中应用相同的紧凑变换器骨干，并在仿真和OTA条件下验证其性能，我们展示了朝向5G及更高级别学习驱动、软件定义物理层的实用路径。

## 参考文献
[1] L. Dai, R. Jiao, F. Adachi, H. V. Poor, and L. Hanzo, “Deep learning for wireless communications: An emerging interdisciplinary paradigm,” IEEE Wireless Communications, vol. 27, no. 4, pp. 133–139, 2020.  
[2] C. Zhang, P. Patras, and H. Haddadi, “Deep learning in mobile and wireless networking: A survey,” IEEE Communications Surveys & Tutorials, vol. 21, no. 3, pp. 2224–2287, 2019.  
[3] H. Ye, G. Y. Li, and B.-H. Juang, “Power of deep learning for channel estimation and signal detection in ofdm systems,” IEEE Wireless Communications Letters, vol. 7, no. 1, pp. 114–117, 2018.  
[4] H. He, C.-K. Wen, S. Jin, and G. Y. Li, “Deep learning-based channel estimation for beamspace mmwave massive mimo systems,” IEEE Wireless Communications Letters, vol. 7, no. 5, pp. 852–855, 2018.  
[5] N. Samuel, T. Diskin, and A. Wiesel, “Learning to detect,” IEEE Transactions on Signal Processing, vol. 67, no. 10, pp. 2554–2564, 2019.  
[6] N. Shlezinger, R. Fu, and Y. C. Eldar, “Deepsic: Deep soft interference cancellation for multiuser mimo detection,” IEEE Transactions on Wireless Communications, vol. 20, no. 2, pp. 1349–1362, 2021.  
[7] S. Dorner, S. Cammerer, J. Hoydis, and S. t. Brink, “Deep learning based communication over the air,” IEEE Journal of Selected Topics in Signal Processing, vol. 12, no. 1, p. 132–143, Feb. 2018. [Online]. Available: http://dx.doi.org/10.1109/JSTSP.2017.2784180  
[8] A. Felix, S. Cammerer, S. Dörner, J. Hoydis, and S. Ten Brink, “Ofdm-autoencoder for end-to-end learning of communications systems,” in 2018 IEEE 19th International Workshop on Signal Processing Advances in Wireless Communications (SPAWC), 2018, pp. 1–5.  
[9] T. O’Shea and J. Hoydis, “An introduction to deep learning for the physical layer,” IEEE Transactions on Cognitive Communications and Networking, vol. 3, no. 4, pp. 563–575, 2017.  
[10] N. A. Letizia and A. M. Tonello, “Capacity-driven autoencoders for communications,” IEEE Open Journal of the Communications Society, vol. 2, pp. 1366–1378, 2021.  
[11] T. Raviv, S. Park, O. Simeone, Y. C. Eldar, and N. Shlezinger, “Online meta-learning for hybrid model-based deep receivers,” IEEE Transactions on Wireless Communications, vol. 22, no. 10, pp. 6415–6431, 2023.  
[12] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Ł. Kaiser, and I. Polosukhin, “Attention is all you need,” in Advances in Neural Information Processing Systems (NeurIPS). Curran Associates, 2017, pp. 5998–6008. [Online]. Available: https://arxiv.org/abs/1706.03762  
[13] J. Cai, F. Gan, X. Cao, and W. Liu, “Signal modulation classification based on the transformer network,” IEEE Transactions on Cognitive Communications and Networking, vol. 8, no. 3, pp. 1348–1357, 2022.  
[14] S. R. Doha and A. Abdelhadi, “Deep learning in wireless communication receiver: A survey,” 2025. [Online]. Available: https://arxiv.org/abs/2501.17184  
[15] J. Jiao, X. Sun, L. Fang, and J. Lyu, “An overview of wireless communication technology using deep learning,” China Communications, vol. 18, no. 12, pp. 1–36, 2021.  
[16] NVIDIA Corporation. (2025) Product description – aerial ran colab over-the-air (arc-ota). Accessed: 2025-08-11. [Online]. Available: https://docs.nvidia.com/aerial/aerial-ran-colab-ota/current/text/product_description/index.html  
[17] M. Soltani, V. Pourahmadi, A. Mirzaei, and H. Sheikhzadeh, “Deep learning-based channel estimation,” IEEE Communications Letters, vol. 23, no. 4, pp. 652–655, 2019.  
[18] M. Honkala, D. Korpi, and J. M. J. Huttunen, “Deeprx: Fully convolutional deep learning receiver,” IEEE Transactions on Wireless Communications, vol. 20, no. 6, pp. 3925–3940, 2021.  
[19] S. Cammerer, F. A. Aoudia, J. Hoydis, A. Oeldemann, A. Roessler, T. Mayer, and A. Keller, “A neural receiver for 5g nr multi-user mimo,” in 2023 IEEE Globecom Workshops (GC Wkshps), 2023, pp. 329–334.  
[20] D. Luan and J. S. Thompson, “Channelformer: Attention based neural solution for wireless channel estimation and effective online training,” IEEE Transactions on Wireless Communications, vol. 22, no. 10, pp. 6562–6577, 2023.  
[21] Z. Ren, N. Cheng, R. Sun, X. Wang, N. Lu, and W. Xu, “Sigt: An efficient end-to-end mimo-ofdm receiver framework based on transformer,” 2022. [Online]. Available: https://arxiv.org/abs/2211.09712  
[22] Y. Xie, K. C. Teh, and A. C. Kot, “Comm-transformer: A robust deep learning-based receiver for ofdm system under tdl channel,” IEEE Transactions on Communications, vol. 72, no. 4, pp. 2014–2026, 2024.  
[23] Y. Leng, Q. Lin, L.-Y. Yung, J. Lei, Y. Li, and Y.-C. Wu, “Unveiling the power of complex-valued transformers in wireless communications,” 2025. [Online]. Available: https://arxiv.org/abs/2502.11151  
[24] T. Sun, J. Lv, and T. Zhou, “A transformer-based channel estimation method for otfs systems,” Entropy, vol. 25, no. 10, 2023. [Online]. Available: https://www.mdpi.com/1099-4300/25/10/1423  
[25] J. Gao, M. Hu, C. Zhong, G. Y. Li, and Z. Zhang, “An attention-aided deep learning framework for massive mimo channel estimation,” IEEE Transactions on Wireless Communications, vol. 21, no. 3, pp. 1823–1835, 2022.  
[26] B. Yue, S. Qiu, C. Yang, L. Peng, and Y. Zhang, “Transformer-empowered receiver design of ofdm communication systems,” Computer Communications, vol. 228, p. 107960, 2024. [Online]. Available: https://www.sciencedirect.com/science/article/pii/S0140366424003074  
[27] A. Yang, P. Sun, T. Rakesh, B. Sun, and F. Qin, “Deep learning based ofdm channel estimation using frequency-time division and attention mechanism,” in 2021 IEEE Globecom Workshops (GC Wkshps), 2021, pp. 1–6.  
[28] S. Alikhani, G. Charan, and A. Alkhateeb, “Large wireless model (lwm): A foundation model for wireless channels,” 2025. [Online]. Available: https://arxiv.org/abs/2411.08872  
[29] Y. Tay, M. Dehghani, D. Bahri, and D. Metzler, “Efficient transformers: A survey,” ACM Computing Surveys, vol. 55, no. 6, 2022.  
[30] T. Dao, “Flashattention-2: Faster attention with better parallelism and work partitioning,” 2023.  
[31] T. Dao, D. Y. Fu, S. Ermon, A. Rudra, and C. Ré, “Flashattention: Fast and memory-efficient exact attention with io-awareness,” Advances in Neural Information Processing Systems, 2022.  
[32] “Study on artificial intelligence (ai)/machine learning (ml) for nr air interface,” 3GPP, Tech. Rep. TR 38.843, 2023, release 18 study item. [Online]. Available: https://www.3gpp.org/dynareport/38843.htm  
[33] X. Lin, “An overview of the 3gpp study on artificial intelligence for 5g new radio,” 2023. [Online]. Available: https://arxiv.org/abs/2308.05315  
[34] ——. (2025) An overview of ai in 3gpps ran release 18. IEEE Communications Society, ComSoc Technology News. [Online]. Available: https://www.comsoc.org/publications/ctn/overview-ai-3gpps-ran-release-18-enhancing-next-generation-connectivity  
[35] P. Michel, O. Levy, and G. Neubig, Are sixteen heads really better than one? Red Hook, NY, USA: Curran Associates Inc., 2019.  
[36] E. Voita, D. Talbot, F. Moiseev, R. Sennrich, and I. Titov, “Analyzing multi-head self-attention: Specialized heads do the heavy lifting, the rest can be pruned,” in Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, A. Korhonen, D. Traum, and L. Màrquez, Eds. Florence, Italy: Association for Computational Linguistics, Jul. 2019, pp. 5797–5808. [Online]. Available: https://aclanthology.org/P19-1580/