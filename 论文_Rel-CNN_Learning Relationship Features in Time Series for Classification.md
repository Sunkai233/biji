以下是论文《Rel-CNN: Learning Relationship Features in Time Series for Classification》的逐段翻译，格式为Typora支持的Markdown格式，公式使用Latex语法以`$$`包裹。翻译力求准确、简洁，同时保留学术语言的严谨性。由于原文较长，以下翻译逐段进行，并确保公式正确显示。

---

## Abstract

**摘要**

时间序列分类在现实世界中有着广泛的应用。由于其重要性，多年来提出了许多时间序列分类技术。其中，基于神经网络的方法因其能够自动从数据中提取潜在和判别性特征而受到广泛关注。在本文中，我们探索了关系特征（relationship features），它们为时间序列分析提供了宝贵的全局信息，并提出了一个通用的神经网络架构，即Rel-CNN，用于学习全局和局部子序列特征以进行时间序列分类。此外，我们提供了两种详细的模型设计：基于关系特征的卷积过滤（Relationship Feature based Convolution Filtering）和基于潜在关系特征的卷积过滤（Latent Relationship Feature based Convolution Filtering），并解决了这些模型中因参数过多导致的技术问题。我们在广泛使用的85个单变量“bake-off”数据集和8个多变量UEA数据集上评估了我们的模型和基线方法。实验结果表明，我们的Rel-CNN模型在平均准确率、平均宏F1分数和排名指标方面优于代表性的时间序列分类器。此外，Rel-CNN的集成版本在“bake-off”数据集上的平均排名、平均准确率和平均宏F1分数也优于最先进的集成分类器。

**关键词**：神经网络，时间序列分类，关系特征

{

这篇论文研究的是 **时间序列分类** —— 比如股票价格走势、心电图波形、传感器读数这种“随时间变化的数据”，我们要判断它属于哪一类。

过去很多方法要么依赖人工设计特征，要么在神经网络里只关注局部细节。作者提出要利用一种叫做 **“关系特征”**（relationship features）的信息。关系特征能描述时间序列中不同位置之间的整体关系，提供更全局的理解。

为此，作者提出了一个新的神经网络架构 **Rel-CNN**，它能同时学到：

- **局部特征**（小片段的细节模式），
- **全局特征**（长时间范围的关系信息）。

他们还设计了两种具体的实现方式：

1. **基于关系特征的卷积过滤**
2. **基于潜在关系特征的卷积过滤**

并解决了模型参数过多带来的训练难题。

实验方面，他们在 85 个常用单变量数据集和 8 个多变量数据集上进行了测试，发现 Rel-CNN 在准确率、宏 F1 分数和排名等指标上都超过了其他代表性方法。更进一步，多个 Rel-CNN 模型的集成版，在整体表现上也超过了当前最先进的集成分类器。

}

---

## 1 INTRODUCTION

**引言**

时间序列是一系列记录了各种现象随时间变化的观测值序列，涉及一个或多个变量，例如温度、湿度、价格等。在众多的时间序列挖掘任务中，时间序列分类（TSC）旨在从一个带标签的时间序列数据集中学习一个模型（称为分类器），以在现实场景中将未知时间序列映射到其标签类别。多年来，由于其广泛的应用[1], [2]，例如用于医疗诊断的脑电图信号分类[3]、用于音乐分析的音乐类型分类[4]以及基于传感器数据的人体活动识别[5]，TSC吸引了大量的研究努力。

有效的TSC的一个主要挑战是从时间序列数据中提取判别性特征。根据[6]，时间序列中的特征通常可分为两类：i) 局部子序列特征，ii) 全局特征。前者指的是在时间序列的某个时间区间内出现的特定局部模式，例如局部形状特征（shapelets）[7]；后者指仅通过观察整个时间序列区间才能观察到的某些内在属性或模式，例如周期性[8]、长期趋势[9]、熵[10]、平稳性[11]和自相关[12]。提取全局特征和局部子序列对于时间序列分类非常重要。例如，图1展示了两个行走用户在重力方向上的加速度随时间变化的情况。它们不同的波形（局部子序列特征）和不同的周期性（全局特征）可能有助于用户身份识别。

传统的特征工程依赖于手动识别特征、定义适当的相似性函数或设计特征提取算法[13], [14], [15]。近年来，由于神经网络（NN）能够从数据中自动提取潜在和判别性特征，它们在时间序列分类中获得了越来越多的关注[16], [17]。受卷积神经网络（CNN）在图像数据特征提取能力启发，时间序列被转换为图像以应用二维（2D）-CNN进行TSC[18], [19]。由于2D-CNN是为图像分类设计的，并不适合时间序列数据，因此探索了一维（1D）-CNN来提取局部子序列特征（例如波形），例如ResNet[20]、InceptionTime[21]、Omni-Scale CNN[22]等[22], [23]。这些工作还探索了使用堆叠的各种尺寸卷积滤波器的深度神经网络，以捕获不同尺度的特征用于TSC。虽然通过提取不同尺度的特征在TSC中取得了一些成功，但由于用于特征提取的层数有限和卷积滤波器尺寸有限，它们在捕获时间序列（特别是超长序列）的全局信息方面面临挑战。在这项工作中，我们旨在学习局部特征和全局信息以进行TSC。

为了解决学习全局信息的问题，在这项工作中，我们提出了探索关系特征的想法，通过明确地将一个时间点与其他所有时间点的关系作为该时间点的附加特征。关系特征捕获了任意两个时间点之间的相关性（或相似性），从而具有将全局信息（以相关性或相似性的形式）作为局部信息的效果。因此，结合原始时间序列中的局部模式，可以捕获“局部化的全局信息”中的全局模式。进一步推广上述想法，关系特征可以应用于两个时间区间的聚合观测值（而不仅仅是两个时间点）。我们认为并证明，通过关系特征，可以提取时间序列中的全局特征，例如周期性和长期趋势，以实现有效的TSC。

为了实现我们的想法，我们提出了一个端到端的框架，即Rel-CNN，用于TSC。如图2所示，Rel-CNN由多个堆叠的局部模式全局关系（Local Pattern Global Relationship, LPGR）提取块组成。为了探索关系特征的想法，LPGR块包含两个主要层：1) 关系层，生成来自前一个块输入特征的时间点/区间之间的关系特征；2) 基于1D-CNN的卷积层，从(a) 关系层的输入特征和(b) 关系层生成的关系特征中提取局部模式序列（例如频繁子序列特征），形成LPGR特征图。由于关系特征能够将全局信息作为时间点（或区间）的局部特征，卷积层能够有效地捕获局部子序列特征（来自(a)）和局部化的全局信息（来自(b)）在特征图中。此外，我们在Rel-CNN中堆叠多个LPGR块，以将时间点之间的关系特征推广到时间区间之间的关系特征。通过堆叠的LPGR块，提取的特征覆盖范围从单个时间点扩展到多点区间，并继续变长，这有助于在后续（更深层）块中提取和聚合同区间相关的关系。

受ResNet[20], [24]的启发，ResNet通过自动丢弃某些层来促进深层模型的训练效率，我们在每两个相邻的LPGR块之间添加了残差链接（Res-Link）（见图2）。通过从LPGR块i的输出到LPGR块(i+1)的输出添加Res-Link，我们将LPGR块i的输出特征图添加到LPGR块(i+1)的输出特征图，以馈送到下一层。最后，从最后一个LPGR块提取的LPGR特征图被馈送到堆叠的全连接网络进行分类。

为了实现Rel-CNN中的核心LPGR块，我们提出了两种不同的模型设计，即基于关系特征的卷积过滤（RFC）和基于潜在关系特征的卷积过滤（LRFC）。其中，前者通过使用预定义的关系测量直接在输入特征空间中考虑关系，而后者进一步将这些特征嵌入到潜在空间中，通过学习更复杂的关系函数生成潜在关系特征。此外，我们设计了一种层次卷积机制，以解决模型参数过多的问题，这显著阻碍了训练过程的效率，同时结合多尺度卷积来聚合局部子序列特征和局部化的全局特征。

我们总结了本文解决的主要问题：i) 提取全局特征的困难。为了解决这个问题，对于时间序列实例中的每个时间点，我们探索了关系特征的想法，将该时间点与其他时间点的关系作为该时间点的局部特征，从而促进全局特征提取；ii) 手动枚举所有潜在全局特征的困难。为了解决这个问题，我们在LRFC中探索了时间点之间的潜在关系的想法，这有助于自动学习各种关系；iii) 模型中参数过多的问题。为了解决这个问题，我们提出了层次卷积的设计，以有效减少Rel-CNN中的参数数量。

我们在85个单变量“bake-off”数据集[1]上评估了提出的Rel-CNN框架，与最先进的方法进行比较，包括非集成分类器和集成分类器。我们研究了不同参数设置的影响，并通过消融研究分析了Rel-CNN中不同组件的重要性。我们进一步在八个UEA多变量时间序列数据集上评估了非集成Rel-CNN模型与最先进方法的比较。实验结果表明，Rel-CNN框架（具有替代的LPGR设计）显著优于比较的基线非集成分类器（例如BOSS、ResNet等），并且集成Rel-CNN也优于基线集成分类器（例如HIVE-COTE、TS-CHIEF等）。

这项工作的主要贡献如下：

- **时间序列中关系特征的新颖想法**。我们提出了关系特征的概念，为时间序列分析提供了宝贵的全局信息。
- **用于时间序列分类的新端到端深度学习框架**。我们提出了Rel-CNN，以捕获不同尺度的局部子序列特征和全局关系特征用于TSC。
- **两种新颖的关系特征生成设计**。我们探索了在输入特征空间和潜在特征空间中生成关系特征的想法，用于LPGR块中的关系层。
- **新的层次卷积层**。我们采用1D-CNN作为LPGR中卷积的基础，并提出了层次卷积层，以结合多尺度卷积并解决模型参数过多的问题。
- **在“bake-off”数据集上的实证研究**。实验结果表明，Rel-CNN在各种指标下优于最先进的方法，特别是在平均排名（LRFC-Eud为2.824，而Inception为3.353）和85个数据集中排名第一的最高次数（LRFC-Eud为31次，而WEASEL为18次）方面。消融研究发现，原始时间序列和关系特征对于TSC都是必不可少的、信息的且互补的。

本文的其余部分组织如下。第2节回顾相关工作，第3节讨论研究问题，第4节描述提出的Rel-CNN框架，包括LPGR中关系层和卷积层的替代设计。第5节报告实验结果和发现，第6节总结本文。

{

## 通俗解释版引言

时间序列就是一组随时间变化的数据，比如温度、心电图、股票价格、人体加速度信号等等。**时间序列分类（TSC）** 的任务，就是根据已有的带标签数据，训练出一个模型，能自动判断一条新时间序列属于哪一类。
 👉 这在医疗（病人诊断）、音乐识别、运动检测等领域都有重要应用。

### 问题是什么？

做时间序列分类，关键是要从数据里提取出“有区分度的特征”。这些特征大概分两类：

1. **局部特征**：某一小段时间里的特定模式（比如心电图里的一段波形）。
2. **全局特征**：需要看整个时间序列才能发现的规律（比如周期性、长期趋势、稳定性）。

很多现有的深度学习方法（比如 1D 卷积 CNN）都擅长提取局部特征，但对 **全局信息** 的捕捉比较弱，尤其在时间序列很长的时候。

### 解决思路

这篇论文的作者提出了一个新想法：
 👉 **关系特征（Relationship Features）**：
 把一个时间点与序列中其他时间点的“相关性”当作新的特征，这样全局信息就能以“局部化的形式”输入模型。比如，两个时间点之间是否周期性重复、是否相关，这些关系就能帮模型理解整体结构。

### 方法：Rel-CNN

他们设计了一个新框架 **Rel-CNN**，主要由多个 **LPGR 块（Local Pattern Global Relationship）** 组成。

- **关系层**：生成不同时间点之间的关系特征（全局信息）。
- **卷积层**：结合原始特征和关系特征，提取局部模式和“局部化的全局信息”。
- 多个 LPGR 堆叠后，可以从点与点的关系扩展到区间与区间的关系，捕捉更复杂的全局模式。
- 借鉴 ResNet，他们还加了残差连接，避免模型太深难训练。

此外，他们提出了两种具体实现：

1. **RFC**：直接用预定义的关系度量。
2. **LRFC**：先把数据映射到潜在空间，再学习更复杂的关系。

同时设计了 **层次卷积**，既能结合多尺度特征，又避免模型参数过多、训练效率低的问题。

### 贡献总结

1. 提出了 **关系特征** 这个新思路，让模型能学到全局信息。
2. 设计了 **Rel-CNN 框架**，能同时提取局部和全局特征。
3. 提出了两种生成关系特征的方法（RFC 和 LRFC）。
4. 引入 **层次卷积** 来降低参数量并提升效果。
5. 在 85 个单变量数据集和 8 个多变量数据集上做了实验，效果显著超过现有最先进方法。

}

---

### 图表说明

- **图1**：用户加速度中的局部和全局特征。
- **图2**：Rel-CNN的网络架构。

---

## 2 RELATED WORK

**相关工作**

时间序列分类（TSC）方法通常分为基于实例的方法和基于特征的方法[6], [25]。基于实例的方法通常设计一个相似性函数，例如欧几里得距离[26]、编辑距离[27]、小波[28]和动态时间规整（DTW）[29]，以测量两个时间序列实例之间的相似性。因此，它们通过在历史数据集中选择前k个相似的时间序列实例进行分类。

另一方面，传统的基于特征的分类方法依赖于手动设计的特征提取算法[6], [25], [30], [31], [32], [33]和特征选择方法[34]来提取特征，其中特征可能指的是形状特征（更具体地说，使用时间序列与形状特征之间的距离作为特征）[7], [13], [30]、小波[31]、傅里叶变换[32]、DTW特征[33]、梅尔频率倒谱系数[35]、感知线性预测系数[36]、滤波器组[37]、符号傅里叶近似（SFA）符号[14]等。提取的特征随后被输入到机器学习模型中，例如支持向量机和决策树，进行分类。其中，形状特征和模式包（bag of patterns, BOP）的思想被广泛探索。对于形状特征，Mueen等人探索了时间序列到一组最优形状特征（最具代表性的时间序列子序列）的距离作为属性/特征，以构建决策树进行TSC[7]。此外，提出了形状特征变换[13]，以探索时间序列到各种形状特征的距离作为时间序列的特征，以在此基础上构建分类器。最近，提出了学习形状特征（LS）以合成生成最优形状特征[38], [39]。然而，基于形状特征的方法计算成本高，导致学习过程耗时长。对于BOP，基于SFA符号的包（BOSS）首先将滑动窗口中的每个时间序列子序列转换为基于时间序列观测变量值分布的SFA符号，然后利用SFA符号直方图之间的差异作为邻居间距离测量，采用最近邻分类器[14]。为了提高BOSS的效率，Schafer等人提出了一个改进版本，称为时间序列分类的单词提取（WEASEL），通过从每个滑动窗口中提取更具判别性的特征以进行时间序列分类[15]。然而，基于模式包的方法仍然需要较长的训练时间来生成和选择大量滑动窗口中的特征。总之，基于实例的方法和基于特征的方法高度依赖于手动设计的相似性函数或特征提取算法。

最近，由于神经网络在自动特征提取方面的优势，它们被应用于时间序列分类[17], [18], [19], [20], [21], [22], [40], [41]。由于二维卷积神经网络（2D-CNN）在图像分类特征提取方面的成功，提出了基于Gramian角场（GAF-CNN）和基于递归图（RP-CNN）的方法，将时间序列转换为图像，通过探索时间点之间的角度差异和时间序列相空间轨迹的递归性，然后应用2D-CNN模型对图像进行分类[18], [19]。这些方法主要关注将时间序列编码为图像以利用2D-CNN的能力，忽略了原始时间序列中的局部子序列特征。为了更好地从时间序列中捕获特征，最初为自然语言处理提出的1D-CNN[41]自然被用于人体活动识别[17]。此外，通过利用不同尺寸的卷积滤波器提取不同尺度的特征，深度1D-CNN被用于TSC[20], [21], [22]。其中，Fawaz等人将残差网络（ResNet）应用于TSC，通过构建残差连接跳过某些层以自动学习最优层数，以捕获小尺度和大尺度的特征[20]。此外，Fawaz等人提出将Inception模型（一种现有的CNN变体）应用于TSC，通过利用多个不同尺寸的卷积滤波器进行特征提取[21]。这些工作将每层的卷积滤波器尺寸视为参数，并通过交叉验证找到最优设置，导致模型调优过程耗时长。为了避免手动调整滤波器尺寸，Tang等人提出了Omni-scale 1D-CNN（OS-CNN），在模型的前两层学习一组素数作为滤波器尺寸，以提取所有可能尺度的特征用于TSC[22]。

由于集成模型在提高性能方面的成功，许多现有工作利用集成方法结合各种模型进行TSC。传统上，集成方法可分为两类：1) 结合同一模型但使用不同模型参数生成的特征（例如，基于不同k值的最优形状特征生成的特征），包括弹性集成（EE）[42]、形状特征变换集成（STC）[43]、时间序列森林（TSF）[44]、邻近森林（PF）[45]、随机区间光谱集成（RISE）[46]等；2) 结合不同模型（例如EE、STC、TSF等）并投票进行TSC，包括基于变换的层次投票集成（HIVE-COTE）[47]、时间序列异构和集成嵌入森林（TS-CHIEF）[48]等。最近，基于CNN的集成也被提出用于TSC。例如，InceptionTime结合了五个具有不同初始参数的Inception模型；RandOm Convolutional KErnel Transform（ROCKET）将随机卷积滤波器应用于时间序列，并将生成的特征输入到线性分类器进行TSC[49]；OS-CNN的集成版本结合了8个具有不同参数初始化的OS-CNN，称为OS-CNN-ENS(8)[22]。

在本文中，我们探索了关系特征以捕获局部子序列特征和全局特征用于TSC，并提出了定制的Rel-CNN模型设计以实现我们的想法。值得注意的是，TSF和RISE分别利用选定区间的汇总统计和光谱特征作为TSC的特征，当区间很长时可能提取一些全局特征。此外，ResNet、Inception和OS-CNN能够在深层中探索远距离特征。然而，这些方法并非设计为像我们在本文中那样明确提取“关系”以学习全局特征用于TSC。

{

#### 通俗解释版：相关工作

时间序列分类的方法，大体可以分为两大类：

#### 1. 基于实例的方法

这种方法的思路是：
 👉 **把新数据和历史数据逐个比对，看最像哪一类**。

- 常用的相似度计算方式有欧几里得距离、编辑距离、动态时间规整（DTW）、小波变换等。
- 举个例子，如果一个新心电图信号跟数据库里的某个“已知类别”的信号最接近，那就把它判成那一类。

缺点：需要定义一个好的“相似性函数”，而且效率不高。

------

#### 2. 基于特征的方法

这里会先从时间序列里提取一些特征，再丢给传统的机器学习分类器（比如 SVM、决策树）。

- 特征的例子有：小波特征、傅里叶特征、DTW特征、形状特征（shapelets）、梅尔倒谱系数（常用于语音）、符号傅里叶近似（SFA）等等。
- 比如 **形状特征方法** 就是挑出最有代表性的子序列，然后比较新数据与这些子序列的差异来分类。
- **模式包方法（bag of patterns, BOP）** 则是把子序列转成符号，然后统计符号直方图，再比对。代表方法有 BOSS 和 WEASEL。

缺点：这些方法依赖人工设计特征，计算成本高，训练也很慢。

------

#### 3. 基于神经网络的方法

神经网络的优势是能自动学习特征，不用人工设计。

- **2D-CNN 方法**：把时间序列转成图像（比如角度矩阵、递归图），再用图像识别的 CNN 模型来分类。缺点是没直接利用原始序列里的局部信息。
- **1D-CNN 方法**：直接在原始序列上做卷积，提取局部模式（像小波形），代表有 ResNet、InceptionTime、OS-CNN 等。
  - ResNet 会自动决定需要多少层卷积。
  - Inception 用多个不同大小的卷积核来抓不同尺度的特征。
  - OS-CNN 直接在前几层尝试各种可能的卷积核大小，避免人工调参。

这些方法比传统的要好，但在捕捉“全局信息”上还是有限。

------

#### 4. 集成方法

既然单一模型不够强，大家就把多个模型组合起来：

- 一类是用同一个模型但不同参数组合起来，比如 EE、STC、TSF、RISE。
- 另一类是把完全不同的模型投票结合，比如 HIVE-COTE、TS-CHIEF。
- 也有 CNN 的集成，比如 InceptionTime（5个Inception模型）、ROCKET（随机卷积+线性分类器）、OS-CNN-ENS（8个OS-CNN组合）。

集成通常比单个模型效果更好，但复杂度也更高。

------

#### 5. 本文的不同点

现有方法虽然有时能间接提取一些全局特征（比如 TSF、RISE 提取长区间统计特征；ResNet、Inception、OS-CNN 能学习到远距离依赖），但**没有一个方法是明确地、专门设计来提取“时间点之间关系”的**。

本文提出的 Rel-CNN 就是要通过 **关系特征** 把全局信息显式引入模型，同时也保留局部模式的学习能力。

}

---

## 3 PRELIMINARIES

**预备知识**

在本节中，我们正式定义了重要术语并设定了我们的研究目标。然后，我们讨论了主要关于全局特征的挑战，并提出了解决这些挑战的思路。

### 3.1 Problem Formulation

**问题定义**

我们首先提供时间序列的定义。

**定义1. 时间序列**。时间序列 $TS$ 由一系列以固定时间间隔采样的值组成，如下所示：

$$ TS = [\vec{v}_1, \vec{v}_2, \dots, \vec{v}_l] \tag{1} $$

其中，$l$ 是时间序列的长度，$\vec{v}_j$ 是记录时间点 $j$ 观测变量的向量。

注意，我们将向量 $\vec{v}_j$ 中的值视为时间点 $j$ 的原始特征。因此，时间序列实例 $TS$ 可以表示为一个 $l \times d$ 的特征矩阵，其中 $l$ 是时间序列长度，$d$ 是观测变量的数量。

接下来，我们正式定义时间序列分类。

**定义2. 时间序列分类**。设 $C$ 表示目标类别集合。给定一个带标签的时间序列数据集 $D = \{(TS_1, C_1), \dots, (TS_N, C_N)\}$，其中每个时间序列 $TS_i$ 被标记为 $C_i \in C$，时间序列分类（TSC）的挖掘任务是学习一个分类器 $c$，将未标记的时间序列实例 $TS$ 映射到其类别 $C \in C$。

在这项工作中，我们旨在提取时间序列中的局部子序列和全局特征用于TSC，其中全局特征指仅通过观察整个时间序列区间才能观察到的某些内在属性或模式，例如周期性、长期趋势等。为了实现这一目标，我们探索了关系特征的想法，以捕获时间点（和时间区间）对之间观测值的关系，从而帮助提取全局特征。关系特征正式定义如下。

**定义3. 关系特征**。给定一对时间点 $j$ 和 $k$，$f(p_j, p_k)$ 是一个关系特征，其中 $p_j$ 和 $p_k$ 分别表示与时间点 $j$ 和 $k$ 相关的特征，$f$ 是一个关系测量。关系特征 $f(p_j, p_k)$ 可以用作时间点 $j$ 和 $k$ 的附加特征。

**研究目标**。为了探索时间序列分类的关系特征，我们提出了Rel-CNN框架。我们的目标是设计有效的神经网络模型来实现Rel-CNN框架。

### 3.2 Problem Analysis

**问题分析**

Rel-CNN旨在提取时间序列中的局部子序列和全局特征用于分类，因此面临以下两个挑战：i) 提取全局特征需要模型观察整个时间序列实例，而不仅仅是局部子序列；ii) 显式识别和手动枚举所有潜在全局特征是困难的，特别是当其中一些可能是潜在的。

为了应对第一个挑战，我们认为通过比较时间点（或时间区间）之间的特征值可以揭示一些全局特征。这里我们以周期性和长期趋势为例进行讨论。图3a展示了 Venezia 的水位时间序列，虚线框标记了时间序列中周期性出现的相似序列（见框内模式）。为了说明周期性如何通过比较时间点之间的值来揭示，我们生成了一个关系特征矩阵 $S$（见图3b），其中 $S_{jk} = v_j - v_k$，$v_i$ 是时间点 $i$ 的水位。如图所示，周期性对应于45度的黑色斜线，例如，白框标记的斜线表示 $v_i \approx v_{i+24}$，其中 $i = 1, 2, \dots, 24$。此外，斜线的长度（对于框内斜线为24）暗示了周期性的间隔。

至于时间序列中的长期趋势，图4a展示了AEP能源客户平均每日能源消耗的下降趋势。该趋势通过随时间单调递减的值序列显示。通过使用差值函数生成关系特征矩阵 $S$（见图4b），下降趋势在 $S$ 中显示为一个特殊的模式，即从左到右逐渐变亮的水平红线（由虚线框标示）。值得注意的是，局部模式，例如局部趋势，也可能在关系特征矩阵中以特殊模式（例如，类似于长期趋势的较短线）表示。

对于第二个挑战，存在各种信息丰富的关系，但难以枚举以进行特征提取。此外，精确制定每个关系以针对特定局部子序列特征或全局特征是困难的。因此，一个想法是通过自动推导各种潜在空间中的特征关系矩阵来学习时间点值的潜在关系。

---

### 图表说明

- **图3**：周期性的关系特征矩阵。
- **图4**：长期趋势的关系特征矩阵。

{

#### 1. 时间序列和分类任务

- **时间序列**：就是一堆按照时间顺序记录下来的数据点。比如一周的气温、股价走势、心电图信号等等。
  - 每个时间点可能不仅是一个数，也可能是一组数（比如加速度有x、y、z三个方向）。
  - 所以整个时间序列可以看成一个「矩阵」，行表示时间点，列表示不同的观测变量。
- **时间序列分类**：就是给你一段时间序列，问它属于哪一类。
  - 举例：把心电图分成「正常」和「异常」，或者根据加速度信号识别人是在「走路」还是「跑步」。
  - 学术定义：我们用带标签的数据集训练一个分类器，让它能给新序列贴上正确的类别。

------

#### 2. 为什么要提取“关系特征”？

时间序列里有两类重要的信息：

1. **局部模式**：短时间内的形状，比如一个小波峰。
2. **全局特征**：只有观察整个时间段才能看出来的规律，比如周期性、长期趋势。

局部模式比较容易用卷积神经网络提取，但全局特征就比较难。
 于是作者提出了“关系特征”的想法：

- **关系特征**：就是比较不同时间点之间的关系。
  - 比如在第 5 秒和第 29 秒时，两者的数值很接近 → 这可能说明有 **周期性**。
  - 又比如从头到尾，后面的数值都比前面小 → 说明有 **长期下降趋势**。

简单说：关系特征 = “这个时间点和另一个时间点的比较结果”。

这样一来，原本只能通过观察“整个序列”才能发现的全局规律，就能被“局部化”地引入到每个点上，让模型更容易学到。

------

#### 3. 两个挑战

作者说，想要把关系特征用于分类，有两个主要困难：

1. **提取全局特征很难**：因为模型不能只看一小段，要能看懂整个时间序列。
   - 解决思路：用关系特征矩阵。比如：
     - **周期性** → 在矩阵上表现为对角线上的重复花纹。
     - **趋势** → 在矩阵上表现为颜色逐渐变化的线条。
     - （就像把时间序列转成一张“关系图”，里面藏着周期和趋势的形状）
2. **关系种类太多，没法人工列举**：
   - 有些关系比较直观，比如“差值”；但还有很多更复杂的潜在关系，人工很难一一写出来。
   - 解决思路：让神经网络自己去学，把这些关系嵌入到一个“潜在空间”里，让模型自动挖掘。

------

#### 4. 研究目标

作者的目标很明确：

- 建一个新的神经网络框架 **Rel-CNN**，专门用来同时捕捉局部模式和全局关系。
- 通过“关系特征”的设计，把全局规律引入到局部特征的学习中，让模型既能看懂小细节，又能把握大格局。

------

👉 一句话总结：
 传统方法提取全局特征很难，要么漏掉，要么得人工设计。Rel-CNN 的思路是：让时间点之间的关系自己说话，用“关系特征矩阵”把周期和趋势这类全局规律转化成“局部特征”，然后交给神经网络去学习。

}

---

## 4 DESIGN OF REL-CNN

**Rel-CNN的设计**

在本节中，我们首先介绍提出的Rel-CNN，这是一个端到端的神经网络框架，学习时间序列的局部子序列特征和全局特征用于TSC。我们提出了Rel-CNN的两种替代模型设计，并提出了层次卷积机制，以结合多尺度卷积并解决Rel-CNN中参数过多的问题。

### 4.1 Network Architecture of Rel-CNN

**Rel-CNN的网络架构**

Rel-CNN由 $M$ 个堆叠的局部模式全局关系（LPGR）提取块组成，随后是用于分类的堆叠全连接层，如图2所示。在Rel-CNN框架中，LPGR块旨在从其输入（可能是原始时间序列实例或前一个LPGR块生成的特征）中提取局部子序列和全局特征，包含关系层和卷积层。具体来说，给定一个表示为 $l \times d$ 矩阵的时间序列实例 $TS$，其中 $l$ 是时间序列长度，$d$ 是变量数量，Rel-CNN将 $TS$ 通过 $M$ 个LPGR块进行处理。设 $x_m$ 表示第 $m$ 个LPGR块 $LPGR_m$ 的输入，$h_m$ 表示 $x_m$ 的特征变量数量（即 $x_m$ 的形状为 $l \times h_m$）。$LPGR_m$ 的关系层以 $x_m$（即图2中的(a)）为输入，生成一个三维关系特征张量 $S_m$（一个 $l \times l \times n_m$ 的张量，包含 $n_m$ 个二维 $l \times l$ 关系特征矩阵，$n_m$ 在不同设计中可能不同），其中 $S_m^i$ 表示第 $i$ 个关系特征矩阵，$S_m^i_{jk}$ 表示从时间点 $j$ 和 $k$ 导出的第 $i$ 个关系特征。接下来，卷积层以 $S_m$（即图2中的(b)）和 $x_m$ 为输入（$S_m$ 被展平为一个二维 $l \times (l \times n_m)$ 矩阵并与 $x_m$ 拼接，形成一个形状为 $l \times (l \times n_m + h_m)$ 的矩阵）。使用多个不同尺寸的卷积滤波器，卷积层从 $x_m$ 中提取局部模式和从 $S_m$ 中提取全局特征，并最终形成一个矩阵 $x_{m+1}$（即图2中的(c)）作为 $LPGR_m$ 的输出。注意，我们在LPGR块之间添加了残差链接（即图2中的Res-Link），例如，将 $x_m$ 添加到 $x_{m+1}$ 以馈送到LPGR块 $(m+2)$，旨在自动学习忽略某些LPGR块，例如，通过学习将 $x_{m+1}$ 输出为零图来忽略LPGR块 $(m+1)$。因此，Rel-CNN即使在非常深的架构下也能高效训练。在 $M$ 个LPGR块之后，我们使用展平层和堆叠的全连接层将输出 $x_{M+1}$ 转换为时间序列 $TS$ 的嵌入，然后馈送到全连接层和softmax层进行分类。

为了实现Rel-CNN中的核心LPGR块，我们在卷积层中采用一维（1D）卷积，这是序列数据的自然选择，以提取局部模式同时保持特征的时间顺序。另一方面，我们为关系层提出了两种设计，即基于关系特征的卷积过滤（RFC）和基于潜在关系特征的卷积过滤（LRFC），它们以不同方式导出关系特征。在我们的设计中，RFC通过使用预定义的关系测量以直接方式学习关系特征，而LRFC旨在通过学习潜在关系测量（通过额外的潜在空间投影）来学习更复杂的关系特征。在接下来的章节中，我们详细描述了这些替代设计。

---

### 图表说明

- **图2**：Rel-CNN的网络架构。

---

### 4.2 Relationship Feature Based Convolution Filtering (RFC)

**基于关系特征的卷积过滤（RFC）**

RFC模型通过在原始输入上应用预定义的关系函数来导出关系特征，以促进全局特征提取。

如图5所示，$LPGR_m$ 的输入矩阵为 $x_m$，形状为 $l \times h_m$（在此例中为 $10 \times 3$），其中 $l$ 是时间序列长度，$h_m$ 是 $x_m$ 中每个时间点关联的特征变量数量，即每列表示某个特征变量的时间序列数据（以蓝色、橙色和绿色不同颜色显示）。给定 $x_m$，对于每个特征变量，关系层通过预定义的关系函数 $f(p, q)$ 生成每对时间点之间的关系特征，形成关系特征矩阵（分别见浅蓝色、橙色、绿色矩阵）。更具体地，对于第 $i$ 个特征变量（即 $x_m$ 的第 $i$ 列，记为 $x_m^{:i}$），$f$ 成对地以两个时间点的特征为输入来提取关系特征。因此，生成了一个 $l \times l$ 的关系特征矩阵 $S_m^i$，其中每个单元 $S_m^i_{jk} = f(x_m^{ji}, x_m^{ki})$。注意，我们用 $S$ 表示关系特征矩阵，用 $f$ 表示关系函数。$S$ 中的每个关系特征通过在输入矩阵的一对特征上应用 $f$ 生成。

关系函数 $f$ 旨在捕获两个时间点特征之间的相似性。因此，我们考虑常用的测量方法，例如差值函数 $f_{\text{diff}}(p, q) = p - q$，绝对差值函数 $f_{\text{abs}}(p, q) = |p - q|$，以及基于绝对差值的布尔函数，由阈值 $d$ 控制，如下定义：

$$ f_{\text{binary}}(p, q) = \begin{cases} 
0 & \text{if } |p - q| > d \\
1 & \text{if } |p - q| \leq d 
\end{cases} \tag{2} $$

其中，我们选择 $f_{\text{diff}}$ 作为默认关系特征函数，因为 $f_{\text{binary}}$ 依赖于适当设置阈值 $d$，可能导致信息丢失；而 $f_{\text{abs}}$ 由于不区分一对值中哪个更大，也可能导致信息丢失。

我们将 $x_m$ 和 $S_m$ 拼接成一个拼接特征图，作为LPGR中卷积层的输入。如图6所示，$x_m$ 的每列与其对应的关系特征矩阵形成一个 $l \times (l + 1)$ 的特征矩阵，所有这些矩阵形成拼接特征图。然后，我们在拼接特征图上应用 $h_{m+1}$ 个一维卷积滤波器，其中每个滤波器（见图6中的黑色框）在时间维度（从上到下）上移动的窗口上操作，生成一个新的特征变量（对应于输出特征矩阵的一列）。因此，输出特征矩阵包含与时间区间相关的特征（时间区间长度在后续块中增长），这有助于生成时间区间之间的关系特征，而不仅仅是时间点。

---

### 图表说明

- **图5**：RFC中 $LPGR_m$ 的关系层。
- **图6**：RFC中 $LPGR_m$ 的卷积层。

---

### 4.3 Latent Relationship Feature Based Convolution Filtering (LRFC)

**基于潜在关系特征的卷积过滤（LRFC）**

LRFC模型旨在通过将输入特征投影到不同潜在空间中，学习两个时间点/区间之间的潜在关系特征，而不是像RFC那样在原始特征空间中应用预定义函数。

具体来说，LRFC学习多个潜在关系函数，定义为潜在投影函数和成对相似性测量函数的组合，以生成各种关系特征矩阵。如图7所示，与RFC类似，$LPGR_m$ 的输入矩阵记为 $x_m$，形状为 $l \times h_m$。关系层学习 $n_m$ 个潜在关系函数（记为 $f_1, \dots, f_{n_m}$）来提取 $n_m$ 个关系特征。为了计算两个时间点 $j$ 和 $k$ 之间的第 $i$ 个关系特征，时间点 $j$ 和 $k$ 的两行特征变量（记为 $x_m^{j:}$ 和 $x_m^{k:}$）分别被输入到潜在关系函数 $f_i$ 中。

与RFC中的 $f$ 类似，LRFC中的 $f_i$ 也捕获两个时间点特征之间的某种相似性。为了学习复杂的相似性测量，$f_i$ 被设计为投影函数（将输入特征向量转换为潜在向量）和适用于潜在向量的成对差值函数的复合。想法是学习各种投影函数/矩阵以增加 $f$ 的多样性，以弥补相对简单的成对差值函数。因此，$f_i$ 首先通过一对投影矩阵 $Q_i$ 和 $K_i$ 将 $x_m^{j:}$ 和 $x_m^{k:}$ 投影为同一潜在空间中的两个潜在特征向量（即，将 $x_m^{j:}$ 和 $x_m^{k:}$ 转换为 $Q_i x_m^{j:}$ 和 $K_i x_m^{k:}$），然后在两个潜在特征向量上应用成对相似性测量函数 $g$，以最终提取潜在关系特征。因此，潜在关系函数 $f_i$ 如下：

$$ f_i(p, q) = g(Q_i p, K_i q) \tag{3} $$

由于 $g$ 测量向量之间的相似性而不是值，我们采用余弦相似性和欧几里得距离来导出 $f_i$，如下所示：

$$ f_i(p, q) = g_{\text{cos}}(Q_i p, K_i q) = \frac{\langle Q_i p, K_i q \rangle}{\|Q_i p\| \|K_i q\|} \tag{4} $$

或

$$ f_i(p, q) = g_{\text{eud}}(Q_i p, K_i q) = \|Q_i p - K_i q\| \tag{5} $$

因此，每个潜在关系函数 $f_i$ 生成一个 $l \times l$ 的关系特征矩阵 $S_m^i$，其中每个单元 $S_m^i_{jk} = f_i(x_m^{j:}, x_m^{k:})$。最终，$n_m$ 个关系特征矩阵形成张量 $S_m$。这种设计有两个优点：i) 使用两个投影矩阵（即 $Q_i$ 和 $K_i$）有助于提取不对称的潜在关系（因为两个时间点的时间顺序很重要）；ii) 学习投影矩阵 $Q$ 和 $K$ 减少了手动设计的工作并提高了模型容量。

对于卷积层，输入 $x_m$ 与所有关系特征矩阵 $S_m^i (i = 1, 2, \dots, n_m)$ 拼接（见图8），然后输入到 $h_{m+1}$ 个一维卷积滤波器中以形成输出，如RFC中所做。

---

### 图表说明

- **图7**：LRFC中 $LPGR_m$ 的关系层。
- **图8**：LRFC中 $LPGR_m$ 的卷积层。

---

### 4.4 Hierarchical Convolution

**层次卷积**

学习不同尺度的特征是之前工作探索的问题[20], [21], [22], [49]。虽然关系特征有助于提取时间序列中的全局信息，但Rel-CNN探索不同尺度的特征提取是有益的。然而，拼接特征图中的特征数量较多，导致卷积滤波器尺寸较大（见图6和图8），进而导致模型训练时间长、过拟合风险高和模型存储成本高。添加不同尺度的卷积滤波器进一步增加了要学习的参数数量。

为了解决因滤波器参数过多导致的问题，同时适应不同尺度的额外滤波器，我们提出了一个层次卷积层，将输入通道的顺序减少到与 $l$、$h_m$ 和 $n_m$ 成线性关系。提出的层次卷积层由两个子层组成。为了减少滤波器尺寸，我们在第一个子层的想法是在不同特征图上使用相同的滤波器（在拼接之前）通过权重共享。使用少量共享滤波器在单个特征图上执行1D卷积，我们能够通过拼接从卷积中提取的特征生成中间特征图。在第二个子层中，我们在中间特征图上使用多个不同尺寸的1D卷积滤波器来提取多尺度特征。值得注意的是，生成的中间特征图中每个时间点对应的特征数量减少。因此，用于多尺度卷积的滤波器尺寸（和参数数量）较小。因此，这种双层设计的总参数数量远小于原始设计。

图9展示了RFC的层次卷积层。如图所示，$x_m$ 的每列首先与其关系特征矩阵拼接，形成一个 $l \times (l + 1)$ 的特征矩阵，然后输入到第一个子层以提取中间特征。通过权重共享，应用于不同特征矩阵的滤波器是共享的。从输入特征图（以不同颜色显示）提取的特征形成中间特征图，然后输入到第二个子层进行多尺度卷积（共 $h_{m+1}$ 个滤波器）以生成输出LPGR特征矩阵。如图所示，窗口大小为2的红色滤波器和窗口大小为4的紫色滤波器用于提取相应尺度的特征。所有不同尺度的特征被输出以供后续LPGR块进一步处理，并最终用于TSC。

注意，第一个子层中的滤波器数量 $c$ 应较小，实验在第5节中证明其有效性。如图所示，两个子层的输入通道数分别为 $l + 1$ 和 $c \times h_m$，分别与 $l$ 或 $h_m$ 成线性关系。注意，层次卷积层也适用于LRFC。LRFC中两个子层的输入通道数分别为 $l + h_m$ 和 $c \times n_m$，与 $l$、$h_m$ 和 $n_m$ 成线性关系。

---

### 图表说明

- **图9**：RFC中的层次卷积层。

{

## 通俗解释版：Rel-CNN 的设计

这部分讲的就是 Rel-CNN 具体是怎么搭建的，它包含哪些模块，以及为什么要引入一些特殊设计（比如关系特征、潜在关系特征、层次卷积）。

------

### 1. Rel-CNN 的整体架构

- Rel-CNN 的核心积木叫 **LPGR 块**（Local Pattern Global Relationship）。
  - **Local Pattern（局部模式）** → 比如时间序列里的小波峰、小波谷。
  - **Global Relationship（全局关系）** → 比如周期性、趋势，这些需要比较不同时间点才能发现。
- 每个 LPGR 块有两层：
  1. **关系层**：生成关系特征（即“这个时间点和其他时间点之间的关系”）。
  2. **卷积层**：同时处理原始序列 + 关系特征，从中学到局部和全局规律。
- 架构特点：
  - **多层堆叠**：多个 LPGR 块连起来，信息越来越丰富。
  - **残差连接（Res-Link）**：像 ResNet 一样，如果某个 LPGR 块“没用”，网络可以自动跳过它。这样能防止模型太深时训练困难。
  - 最后，输出会送到全连接层和 softmax 层，得到分类结果。

------

### 2. 两种关系特征设计

#### (a) RFC（Relationship Feature based Convolution Filtering）

- 思路：直接用一些 **预定义的函数** 来算关系。
- 比如：
  - 差值：$p - q$
  - 绝对差：$|p - q|$
  - 二值化：如果差小于阈值，就设为 1，否则 0。
- 举个例子：
   如果输入是 10 个时间点 × 3 个特征（比如温度、湿度、气压），那就会得到 3 个关系矩阵，每个是 10×10 的表格，表示每两个时间点之间的差异。
- 这些关系矩阵再跟原始数据拼接在一起，输入到卷积层。这样，卷积层不仅能看到原始信号，还能看到“时间点之间的关系图”。

------

#### (b) LRFC（Latent Relationship Feature based Convolution Filtering）

- 思路：让模型自己去学关系，而不是用人手写的函数。
- 做法：
  - 先把时间点的特征通过两个投影矩阵（Q 和 K）分别投到潜在空间。
  - 然后在潜在空间里比较它们的相似性（比如用余弦相似度或欧几里得距离）。
- 好处：
  1. **能学更复杂的关系**，不局限于简单的差值。
  2. **能捕捉方向性**（因为 Q 和 K 可以不一样，所以比较是有顺序的，符合时间的因果性）。
  3. **自动化**，不用人工枚举所有可能的全局特征。

------

### 3. 层次卷积（Hierarchical Convolution）

- 问题：
  - 如果把原始特征 + 所有关系特征都拼起来，特征维度会特别大，卷积层的参数也会爆炸。
  - 这会导致训练慢、容易过拟合、模型太大。
- 解决办法：分两步走：
  1. **先降维**：在每个特征图上用同一组卷积（共享权重）提取基本信息 → 得到中间特征图。
  2. **再多尺度卷积**：在中间特征图上，用不同窗口大小的卷积（比如看 2 个点的趋势、4 个点的趋势…）来提取不同尺度的特征。
- 优点：
  - 参数数量大幅减少（因为共享卷积 + 分级处理）。
  - 还能保留多尺度信息（既看短期波动，也看长期趋势）。

------

### 4. 总结

Rel-CNN 的设计逻辑是：

1. **局部 + 全局结合**：通过关系特征，把全局规律转化成本地特征。
2. **两种关系特征方法**：RFC（固定规则）和 LRFC（自动学习）。
3. **层次卷积**：降低参数量，提高效率，还能捕捉多尺度模式。

这样，Rel-CNN 就既能抓住小的局部波动，又能理解整个时间序列的长程结构，从而提升分类效果。

}

---

## 5 PERFORMANCE EVALUATION

**性能评估**

在这里，我们在广泛使用的时间序列分类基准数据集，即单变量“bake-off” UCR/UEA数据集[1]上评估Rel-CNN与几种基线方法的性能。实证上，我们测试参数敏感性并对提出的模型进行消融研究，以验证各个组件的有效性。然后，我们分析Rel-CNN的计算成本和模型对数据规范化的敏感性。接下来，我们在准确率、排名（基于准确率）、宏F1、宏召回率和宏精确率方面比较提出的Rel-CNN模型与非集成基线。此外，我们构建了Rel-CNN的集成版本，与最先进的TSC集成模型进行比较。最后，我们在多变量时间序列数据集上评估Rel-CNN模型与其他基线，以比较它们在多变量TSC中的有效性。

### 5.1 Datasets

**数据集**

我们在UCR/UEA档案中的“bake-off”数据集上评估Rel-CNN模型，该数据集包括8种不同类型的85个时间序列数据集，即DEVICE、ECG、IMAGE、MOTION、SENSOR、SIMULATED、SOUND和SPECTRO。我们在表1中列出了“bake-off”数据集的一些基本统计信息，其中Size、Length和Class分别是每种类型数据集中大小、长度和类别数的范围。更具体地，在表1中，方括号中的两个数字是范围的下限和上限。例如，DEVICE的Size [200, 750]表示在6个DEVICE类型数据集中，最大的数据集有750个时间序列，最小的有200个时间序列。

注意，“bake-off”数据集仅包括规范化的单变量时间序列数据。为了测试Rel-CNN对数据规范化的敏感性，我们收集了三个额外的未规范化时间序列数据集（即Venezia Water Level、UserIdentification和HAR）。为了评估Rel-CNN在多变量TSC中的性能，我们进一步利用了UEA档案中的八个常用多变量时间序列数据集（即Epilepsy、FaceDetection、PenDigits、Heartbeat、Cricket、Handwriting、RacketSports和LSST）。

---

**表1：Bake-Off数据集统计**

| 类型      | 数量 | 大小         | 长度         | 类别数   |
| --------- | ---- | ------------ | ------------ | -------- |
| DEVICE    | 6    | [200, 750]   | [76, 720]    | [2, 10]  |
| ECG       | 7    | [200, 5000]  | [82, 750]    | [2, 42]  |
| IMAGE     | 29   | [40, 3300]   | [80, 1024]   | [2, 60]  |
| MOTION    | 14   | [166, 4478]  | [150, 1882]  | [2, 12]  |
| SENSOR    | 15   | [120, 7164]  | [84, 1024]   | [2, 11]  |
| SIMULATED | 6    | [200, 5000]  | [60, 1024]   | [2, 8]   |
| SOUND     | 1    | [2110, 2110] | [1024, 1024] | [39, 39] |
| SPECTRO   | 7    | [56, 983]    | [234, 570]   | [2, 5]   |

---

### 5.2 Baseline Methods for Comparison

**比较的基线方法**

我们将提出的Rel-CNN（包括RFC和LRFC）与以下TSC分类器作为基线进行比较。

**单最近邻动态时间规整（1NN DTW）**：基于动态时间规整距离作为时间序列相似性测量的传统时间序列分类器。对于多变量TSC评估，我们评估其变体1NN DTW(MD)[50]，专为多变量时间序列数据设计。

**SFA符号包（BOSS）[14]**：基于最近邻的传统分类器，使用从时间序列转换的SFA符号直方图之间的距离作为相似性测量。

**学习形状特征（LS）[38]**：基于从时间序列中学习的形状特征的传统分类器。

**ResNet[20]**：基于残差块的经典深度学习模型。

**时间序列分类的单词提取（WEASEL）[15]**：BOSS的升级版本，广泛用于TSC。

**Inception[21]**：在单层中提取多尺度特征的深度卷积神经网络。

**Omni-scale CNN（OS-CNN）[22]**：自动学习滤波器尺寸的深度卷积神经网络。由于“bake-off”数据集中大多数时间序列具有多个变量，我们使用其多变量版本。

对于Rel-CNN，我们评估了使用 $f_{\text{diff}}$ 的RFC以及使用两种相似性测量的LRFC，分别表示为LRFC-Cos和LRFC-Eud。

此外，我们评估了基于Rel-CNN构建的集成与最先进的集成模型的比较。以下，LRFC-Eud-Ens(n)表示包含 $n$ 个LRFC-Eud分类器的集成。

**时间序列森林（TSF）[44]**：一种树集成，结合熵增益和距离测量来评估每个节点的分割以构建用于TSC的森林。

**随机区间光谱集成（RISE）[46]**：一种树集成，每个树基于选定区间的傅里叶和部分自相关特征构建。

**邻近森林（PF）[45]**：一种随机邻近树的集成，每个节点使用示例而不是测试属性值进行分割。

**形状特征变换集成（STC）[43]**：基于形状特征的传统集成模型，以其可解释性著称。

**基于变换的层次投票集成（HIVE-COTE）[47]**：结合35种不同TSC分类器进行投票的集成模型。

**时间序列异构和集成嵌入森林（TS-CHIEF）[48]**：整合基于树的分类器（例如TSF和PF）的树集成。

**InceptionTime[21]**：结合五个不同配置的Inception分类器的集成。

**RandOm Convolutional KErnel Transform（ROCKET）[49]**：结合随机尺寸卷积滤波器模型的集成，用于分类。

**Omni-Scale卷积神经网络集成（八个）（OS-CNN-Ens(8)）[22]**：结合八个不同配置的OS-CNN的集成。

值得注意的是，我们评估的几种方法也探索了全局信息。其中，ResNet、Inception和OS-CNN能够在深层中提取全局信息。此外，与我们关系特征想法相关的基于区间的特征是TSF、RISE和HIVE-COTE的一部分。

---

### 5.3 Experiment Setup

**实验设置**

我们首先在85个“bake-off”数据集上评估所有模型。对于每个数据集（包括“训练数据”和“测试数据”），我们将“训练数据”随机分为90%和10%，分别用于训练和验证，仅使用测试数据进行评估。为了避免过拟合问题，模型参数调优和模型训练仅在训练集和验证集上进行。在评估中，我们展示了Rel-CNN在“测试数据”上的性能，不受过拟合影响。对于提出的Rel-CNN，我们在训练中采用Adam优化器，并将初始学习率设置为0.00001以训练模型。对于基线方法，我们调整参数以优化其性能。由于篇幅限制，这里不详细介绍。

通过广泛的参数调优，我们获得了以下最优设置。对于RFC和LRFC，我们有：a) 7个LPGR块，其中前四个LPGR块包括关系层，而最后三个块不包括；b) 层次卷积第一个子层中的权重共享滤波器数量 $c$ 统一设置为3；c) 每种尺寸的多尺度滤波器数量设置为256；d) 使用三种尺寸的多尺度滤波器，窗口大小分别为8、16和32。此外，在RFC中，使用差值函数 $f_{\text{diff}}(p, q) = p - q$ 来提取关系特征，而在LRFC中，使用欧几里得距离和余弦相似性。此外，在LRFC中，潜在特征空间的维度设置为输入特征变量数量的1/8。表2总结了Rel-CNN实验的默认参数设置。

在调优Rel-CNN模型后，我们展示了Rel-CNN对时间序列长度的计算成本。此外，我们收集了三个未规范化时间序列数据集，并在这些数据集上比较Rel-CNN在数据规范化前后在准确率方面的性能，以评估模型对数据规范化的敏感性。

在我们的评估中，我们使用准确率、宏F1、宏召回率和宏精确率作为评估指标。准确率和宏F1的观察和发现相似。由于篇幅限制，我们在本文中主要展示准确率的结果，其他指标的结果见附录，可在计算机学会数字图书馆找到，网址为 http://doi.ieeecomputersociety.org/10.1109/TKDE.2022.3186963。由于TSC数据集数量众多，单个数据集的结果未详细展示[1]。相反，我们报告了每种方法在所有数据集上的平均准确率（和其他指标）。为了评估每种方法与其他基线方法的竞争力，我们根据每个数据集的准确率对评估方法进行排名，并以平均排名衡量每种方法。此外，我们统计了每种方法在所有数据集中排名前1、前2和前3的次数，作为另一种竞争力衡量。此外，我们在RFC/LRFC与每个基线之间进行头对头比较，以Win/Tie/Loss计数。最后，我们在UEA档案中的八个多变量时间序列数据集上评估Rel-CNN与其他基线，测量所有模型的准确率、宏F1和排名。

---

**表2：Rel-CNN默认参数设置**

| 模型参数                 | 最优设置          |
| ------------------------ | ----------------- |
| LPGR块数量               | 共7个             |
| 关系层数量               | 前4个块           |
| 权重共享滤波器数量 $c$   | 每个块3个         |
| 每种尺寸多尺度滤波器数量 | 每个块256个       |
| 多尺度滤波器尺寸         | 每个块8、16和32   |
| 关系函数（RFC）          | $f_{\text{diff}}$ |
| 潜在特征空间维度（LRFC） | 输入特征数量 / 8  |

---

### 图表说明

- **图10**：RFC参数的影响。
- **图11**：LRFC-Eud参数的影响。
- **图12**：训练/测试时间与时间序列长度的关系。
- **图13**：规范化前后性能。

---

### 5.4 Parameter Sensitivity Tests on Rel-CNN

**Rel-CNN参数敏感性测试**

在本节中，我们对RFC和LRFC模型进行了一系列参数敏感性测试。首先，我们在“bake-off”数据集上调优Rel-CNN的RFC版本以获得最佳公共参数设置（见5.3节）。敏感性测试显示了这些参数对7种数据集类型的影响。以下，我们使用LPGR的RFC版本。i) **关系层数量**。由于潜在噪声，我们仅在Rel-CNN的早期层生成关系特征。这里我们测试了一个7层Rel-CNN，其中前 $k$ 层使用完整LPGR块，其余使用无关系层的LPGR块。将 $k$ 从2变化到7，图10a显示前4个LPGR块包含关系层表现最佳，这表明在非常深的块中包含关系层可能因参数过多和潜在噪声而损害模型性能。ii) **LPGR块数量**。我们评估了4到9层的Rel-CNN，其中前4层使用完整LPGR块，其余使用无关系层的LPGR。图10b显示7层Rel-CNN在所有数据集类型中实现稳定性能。iii) **权重共享滤波器数量 $c$**。我们测试了模型，将层次卷积中权重共享滤波器数量 $c$ 设置为1、3、5、7。图10c显示3个滤波器实现收敛性能，更多滤波器无助于模型，证实了我们关于小 $c$ 有效的主张。iv) **每种尺寸多尺度滤波器数量**。我们测试了模型，将每种尺寸的多尺度滤波器数量设置为128、256和512。图10d显示256时性能最佳，生成过多特征变量无助于性能。v) **多尺度滤波器尺寸**。我们从实验中得出结论，设置窗口大小为8、16和32的多尺度滤波器表现最佳。图10e显示了与其他三种设置的比较：最佳设置的四分之一（即2、4和8）、最佳设置的二分之一（即4、8和16）和最佳设置的两倍（即16、32和64）。如图所示，较大滤波器尺寸不一定提高模型性能。我们认为，由于关系特征揭示了全局信息，RFC无需非常大的滤波器尺寸即可实现出色性能。vi) 最后，我们测试了RFC使用三种不同关系函数，即差值函数 $f_{\text{diff}}(p, q) = p - q$，绝对差值函数 $f_{\text{abs}}(p, q) = |p - q|$ 和基于绝对差值的布尔函数，由阈值 $d$ 控制（即公式(2)）。图10f显示RFC与 $f_{\text{diff}}$ 表现最佳，而RFC与 $f_{\text{abs}}$ 优于RFC与 $f_{\text{binary}}$。这是因为 $f_{\text{abs}}$ 和 $f_{\text{binary}}$ 基于绝对差值，无法区分一对值中哪个更大，而 $f_{\text{diff}}$ 捕获了该信息。此外，$f_{\text{binary}}$ 缺少值差异的数量，且 $d$ 难以调优，导致性能不如 $f_{\text{abs}}$。因此，我们将 $f_{\text{diff}}$ 设置为RFC的默认关系函数。

我们还在LRFC-Eud版本上使用各种数据集进行了敏感性测试。结果显示，关系层数量、LPGR块数量、权重共享滤波器数量、多尺度滤波器数量和多尺度滤波器尺寸对LRFC的影响与RFC类似（见图11a、11b、11c、11d和11e）。我们还检查了潜在空间维度，通过将其设置为输入特征变量的分数。图11f显示1/8实现最佳性能。

---

### 5.5 Ablation Studies on Rel-CNN

**Rel-CNN消融研究**

在本节中，我们进行消融研究，以证明Rel-CNN中各种想法对性能的重要性。以RFC为例，我们考虑五种变体：1) **Comp** 是包含所有部分的完整RFC版本；2) **NoRaw** 是不包括原始时间序列或前一个LPGR块输出特征的RFC变体（即，仅使用生成的关系特征进行卷积）；3) **NoRel** 是不包括关系特征进行卷积的RFC变体（即，仅使用原始时间序列进行卷积）；4) **NoHie** 是不应用层次卷积的RFC变体，即移除层次卷积的权重共享子层，而直接应用多尺度卷积；5) **NoMS** 是不应用多尺度卷积的RFC变体，即层次卷积第二个子层中的滤波器使用相同窗口大小。

在表3中，第一行显示了研究的RFC变体在所有数据集上的平均准确率。如表所示，NoRaw性能下降最多，与Comp相比下降了4.99%，而NoRel、NoHie和NoMS分别下降了4.29%、2.68%和0.38%。观察表明，原始特征和关系特征在Rel-CNN中都扮演重要角色，是信息的且互补的。这验证了我们探索关系特征并包括原始特征和前一个LPGR块生成的特征进行卷积的想法。我们还观察到NoHie导致的明显性能下降，验证了我们设计层次卷积以减少过多参数的做法。另一方面，由于不应用多尺度卷积（在先前工作[21], [22]中广泛探索）的性能下降相对较小，我们得出结论，由于Rel-CNN中的关系特征和堆叠架构，RFC已经能够提取不同尺度的特征。我们还在LRFC-Cos和LRFC-Eud上进行了消融研究。如表3所示，结果表明与RFC类似的结论。

---

**表3：Bake-Off数据集上的消融研究结果**

| 基础Rel-CNN | Comp   | NoRaw  | NoRel  | NoHie  | NoMS   |
| ----------- | ------ | ------ | ------ | ------ | ------ |
| RFC         | 0.8407 | 0.7908 | 0.7978 | 0.8139 | 0.8369 |
| LRFC-Cos    | 0.8445 | 0.7926 | 0.8010 | 0.8160 | 0.8403 |
| LRFC-Eud    | 0.8499 | 0.8002 | 0.8010 | 0.8209 | 0.8456 |

---

### 5.6 Computational Cost of Rel-CNN

**Rel-CNN的计算成本**

在本节中，我们评估了提出的Rel-CNN模型在计算成本方面的可扩展性。更具体地，我们收集了RFC在85个数据集上的平均训练时间和测试时间，以分析其随时间序列长度增加的增长趋势。由于不同时间序列数据集的“训练数据”和“测试数据”中时间序列实例数量不同，我们通过将总训练和测试时间除以训练数据和测试数据中的时间序列实例数量，计算每个时间序列实例的平均训练和测试时间。因此，从所有85个数据集中，我们绘制了85个（平均训练时间，时间序列长度）的点和85个（平均测试时间，时间序列长度）的点，分别在图12a和12b中。如图12a所示，平均训练时间与时间序列长度之间没有显著相关性。原因可能是训练时间表示Rel-CNN收敛所需的时间，这取决于许多因素，包括模型参数的初始化、优化器的选择等。该分析表明时间序列长度不是训练时间的决定因素。类似地，如图12b所示，测试时间与时间序列长度相关，即测试时间随时间序列长度增加而增加，增长率略高于线性。

---

### 图表说明

- **图12**：训练/测试时间与时间序列长度的关系。

---

### 5.7 Model Sensitivity to Normalization

**模型对规范化的敏感性**

在本节中，我们在三个数据集（即Venezia Water Level、UserIdentification和Human Activity Recognition）上测试模型对数据规范化的敏感性，这些数据集从Kaggle和UCI网站收集。

**Venezia Water Level (WL)** 收集了1983年1月1日至2015年12月31日期间Venezia的每小时水位记录。我们随机抽样50K个时间序列，每个时间序列包括50个时间点（每小时1个时间点）。由于水位具有每日周期性，50小时包括两个完整周期。我们用季节标签对时间序列进行季节分类。

**User Identification From Walking Activity (UI)** 收集了22名参与者在预定义路径上行走时的传感器数据[51]。我们随机抽样22K个时间序列，每个时间序列记录100个连续时间点的三轴加速度。该数据集用于用户身份分类。

**Human-Activity-Recognition (HAR)** 收集了30名志愿者进行六种活动（即行走、上楼、下楼、坐下、站立和躺下）的传感器数据[52]。我们随机抽样10K个时间序列，每个时间序列记录100个时间点的三轴加速度和陀螺仪，用于活动分类。

我们在三个数据集上比较了Rel-CNN模型在数据规范化前后在准确率方面的性能。如图13所示，我们观察到RFC、LRFC-Cos和LRFC-Eud的性能在规范化后一致改善，这验证了在使用Rel-CNN模型之前应用规范化的必要性。特别是在HAR数据集上，规范化后，LRFC-Cos和LRFC-Eud的性能提升比RFC更大，这表明LRFC模型对规范化更敏感。

---

### 图表说明

- **图13**：规范化前后性能。

---

### 5.8 Comparison With Non-Ensemble Classifiers

**与非集成分类器的比较**

在本节中，我们在85个单变量“bake-off”数据集上实证评估了提出的Rel-CNN模型与最先进的非集成分类器。首先，我们比较了RFC、LRFC-Cos和LRFC-Eud与基线在准确率方面的表现，并观察它们在所有基线中的排名（基于准确率）。然后，我们比较了所有模型在85个“bake-off”数据集上的准确率分布。为了处理类不平衡对准确率的影响，我们进一步以平均宏F1、宏召回率和宏精确率评估所有模型以进行比较。最后，我们在RFC/LRFC与每个基线之间进行头对头比较，以密切观察它们在各种数据集中的表现与强大竞争者的比较。

如表4所示，除了平均准确率和平均排名外，我们还统计了每个模型在“bake-off”数据集上排名前1、前2和前3的次数。对于平局模型，我们遵循广泛采用的方法[21], [22]，将其排名分配为它们应占排名的平均值，例如，如果一个数据集中两个最佳模型性能相同，它们都将被排名为1.5。在基线中，我们观察到1NN-DTW表现最差，平均排名最高，平均准确率最低，这表明由于其简单设计（仅基于最近邻做出决策），1NN-DTW不具竞争力。尽管如此，它在5个数据集中表现最佳，并在6个和8个数据集中分别排名前2和前3。此外，我们观察到三个传统基于特征的基线，LS、BOSS和WEASEL的平均准确率分别为78.74%、81.02%和83.34%（高于1NN-DTW的73.78%），平均排名为5.329、4.765和3.659（低于1NN-DTW的6.847），这表明基于特征的基线由于设计的特征提取方法（即形状特征和模式包）优于1NN-DTW。其中，WEASEL表现尤为出色，在所有指标上提升了一个档次。由于自动特征提取和深度神经网络中查看远距离特征的能力，ResNet、Inception和OS-CNN实现了82.20%、83.94%和83.70%的平均准确率，通常优于传统基于特征的模型。这些模型的平均排名也显示了它们相对于传统模型的优势（尽管它们在赢得第一排名的次数上不如WEASEL）。RFC、LRFC-Cos和LRFC-Eud，Rel-CNN的三个变体，分别与上述基线进行比较和排名，准确率分别为84.07%、84.45%和84.99%，均优于基线。其中，LRFC-Eud在所有指标上表现最佳，而LRFC-Cos优于RFC。在排名方面，LRFC-Cos和LRFC-Eud明显优于所有基线。如表所示，LRFC-Cos的最佳平均排名为3.118（对比Inception的3.329，第二最佳），LRFC-Eud的最佳平均排名为2.824（对比Inception的3.353）。此外，LRFC-Cos在26、37和51次中分别排名第一、前2和前3，对比WEASEL的19、34和50次（WEASEL和Inception分别为第二最佳模型）。LRFC-Eud更为出色，在31、43和57次中分别排名第一、前2和前3，对比WEASEL的18、32和48次（第二最佳模型）。这些观察表明Rel-CNN与现有TSC模型相比的竞争力和对各种数据集和应用的鲁棒性。

从比较中，我们做出了一个值得讨论的有趣观察。虽然RFC实现了最高的平均准确率84.07%（对比Inception的83.94%，第二最佳模型），并且RFC在26次中排名第一（对比Inception的14次），但RFC的平均排名（3.329）不如Inception（3.235）。我们进一步深入实验结果，发现虽然RFC在85个数据集中有48个排名前3，但Inception在这方面也表现很好（85个数据集中有52个排名前3）。另一方面，RFC在一些数据集中表现不佳，1次排名第八，8次排名第七，6次排名第六。相反，Inception从未排名第八，4次排名第七，5次排名第六。换句话说，Inception在较少数据集中排名较差。为了解决LRFC可能在一些数据集中表现不佳的担忧，我们统计了LRFC-Eud排名较差的数据集，发现LRFC-Eud仅1次排名第八，3次排名第七，5次排名第六，与Inception类似（排名第七4次，排名第六5次）。总之，LRFC-Eud和Inception的排名较差情况很少，但LRFC-Eud在“bake-off”数据集中比Inception更多次实现卓越性能（即31次排名第一，对比Inception的13次）。

基于准确率的平均排名，我们还利用关键差异（CD）图来分析RFC、LRFC-Cos、LRFC-Eud与所有基线之间的性能差异（分别如图14a、14b和14c所示）。如图所示，RFC是与基线比较时的第二最佳方法，而LRFC-Cos和LRFC-Eud优于所有其他基线。我们观察到RFC和LRFC-Cos在统计上显著优于1NN-DTW、LS和BOSS。更重要的是，LRFC-Eud显著优于ResNet，而ResNet未被任何其他最先进方法显著优于。

除了比较模型排名外，我们还通过图15中的小提琴图可视化了所有85个数据集上模型性能（准确率）的分布。如图所示，RFC、LRFC-Cos和LRFC-Eud的第一（下）四分位数（即小提琴底部第一个虚线）始终高于所有基线。注意，第一四分位数以下的区域（即尾部）表示模型在困难数据集上的准确率表现。因此，Rel-CNN模型在一些困难数据集上的表现优于基线模型。我们还观察到Rel-CNN模型的第三（上）四分位数高于基线模型，这表明Rel-CNN模型在相对容易的数据集上也优于基线。

我们注意到85个“bake-off”数据集的类不平衡问题，即对多数类的分类偏差可能夸大准确率。因此，我们还以宏F1评估所有模型，宏F1以宏平均方式聚合同类别的F1分数（即每个类别平等贡献）。为了进一步分析宏F1中两个不同组件的影响，我们还以所有85个“bake-off”数据集的平均宏召回率和宏精确率评估所有模型。如表4倒数第三列所示，Rel-CNN模型始终优于所有基线，LRFC-Eud（最佳Rel-CNN模型）通过将平均宏F1从82.27%提高到82.89%优于所有基线。如表4最后两列所示，我们观察到所有三个Rel-CNN模型在召回率和精确率方面均优于1NN-DTW、LS、BOSS、WEASEL和OS-CNN。虽然Rel-CNN模型的召回率与Inception相似甚至低于ResNet，但所有三个Rel-CNN模型的精确率高于这些模型（例如，Inception的85.23%对比RFC的85.87%）。

最后，我们在每个Rel-CNN模型与基线模型之间进行头对头比较，通过在85个“bake-off”数据集中统计Win/Tie/Loss的数量，以观察提出的Rel-CNN模型如何与单个基线竞争。头对头比较，专注于两个比较模型，可能避免其他模型在排名中造成的潜在干扰。如表5所示，我们观察到RFC、LRFC-Cos和LRFC-Eud通过实现显著更高的Win计数超过Loss，令人信服地优于所有基线，这再次证明了Rel-CNN的竞争力和鲁棒性。

---

**表4：TSC非集成分类器比较；（k=1,2,3表示前k名）**

| 模型      | 准确率 | 排名  | k=1  | k=2  | k=3  | 排名  | k=1  | k=2  | k=3  | 排名  | k=1  | k=2  | k=3  | 宏F1  | 宏召回率 | 宏精确率 |
| --------- | ------ | ----- | ---- | ---- | ---- | ----- | ---- | ---- | ---- | ----- | ---- | ---- | ---- | ----- | -------- | -------- |
| 1NN-DTW   | 73.78  | 6.847 | 5    | 6    | 8    | 6.859 | 5    | 6    | 8    | 6.882 | 5    | 6    | 8    | 71.31 | 70.86    | 76.40    |
| LS        | 78.74  | 5.329 | 9    | 11   | 18   | 5.353 | 9    | 11   | 17   | 5.365 | 9    | 11   | 17   | 76.18 | 74.10    | 80.14    |
| BOSS      | 81.02  | 4.765 | 12   | 22   | 30   | 4.753 | 14   | 21   | 30   | 4.812 | 12   | 21   | 30   | 78.79 | 77.78    | 85.36    |
| WEASEL    | 83.34  | 3.659 | 21   | 32   | 43   | 3.694 | 19   | 34   | 42   | 3.729 | 18   | 32   | 43   | 81.69 | 80.86    | 84.76    |
| ResNet    | 82.20  | 3.965 | 17   | 26   | 35   | 3.976 | 18   | 26   | 35   | 4.024 | 17   | 26   | 34   | 80.57 | 82.36    | 82.11    |
| Inception | 83.94  | 3.235 | 14   | 33   | 52   | 3.329 | 12   | 32   | 50   | 3.353 | 13   | 30   | 48   | 82.27 | 81.42    | 85.23    |
| OS-CNN    | 83.70  | 3.494 | 17   | 30   | 41   | 3.529 | 18   | 29   | 43   | 3.588 | 17   | 27   | 41   | 82.02 | 81.09    | 84.66    |
| RFC       | 84.07  | 3.329 | 26   | 35   | 48   | -     | -    | -    | -    | -     | -    | -    | -    | 82.40 | 81.18    | 85.87    |
| LRFC-Cos  | 84.45  | -     | -    | -    | -    | 3.118 | 26   | 37   | 51   | -     | -    | -    | -    | 82.67 | 81.41    | 86.54    |
| LRFC-Eud  | 84.99  | -     | -    | -    | -    | -     | -    | -    | -    | 2.824 | 31   | 43   | 57   | 82.89 | 81.96    | 85.95    |

---

**表5：Bake-Off数据集上非集成分类器的头对头比较**

| Win/Tie/Loss | RFC     | LRFC-Cos | LRFC-Eud |
| ------------ | ------- | -------- | -------- |
| 1NN-DTW      | 75/3/7  | 76/3/6   | 78/3/4   |
| LS           | 62/4/19 | 64/5/16  | 65/5/15  |
| BOSS         | 57/4/24 | 55/7/23  | 60/6/19  |
| WEASEL       | 46/5/34 | 49/6/30  | 52/7/26  |
| ResNet       | 47/5/33 | 48/6/31  | 52/5/28  |
| Inception    | 42/2/41 | 43/8/34  | 45/9/31  |
| OS-CNN       | 41/8/36 | 46/4/35  | 51/4/30  |

---

### 图表说明

- **图14**：非集成分类器比较的关键差异图（基于准确率）。
- **图15**：非集成分类器的小提琴图。

---

### 5.9 Comparison With Ensemble Classifiers

**与集成分类器的比较**

集成方法在分类任务（包括TSC）中被广泛使用。在本节中，我们基于LRFC-Eud（最佳Rel-CNN变体）构建了一个集成分类器，记为LRFC-Eud-ENS(n)，其中 $n$ 是集成的LRFC-Eud分类器数量，与最先进的TSC集成分类器进行比较。使用 $n$ 个随机初始化的LRFC-Eud分类器，LRFC-Eud-ENS(n)采用多数投票进行分类，使用平局类别的平均概率作为平局的决胜者。

我们在“bake-off”数据集上评估LRFC-Eud-ENS(n)，将 $n$ 从1、3、5、7变化到9，以观察这些LRFC-Eud集成分类器在平均准确率、平均排名、第一排名、前2排名和前3排名方面的表现。如表6所示，LRFC-Eud集成分类器随 $n$ 增大逐渐表现更好，平均准确率和平均排名增加。显然，LRFC-Eud-ENS(9) 在所有指标上表现最佳，而LRFC-Eud-ENS(7) 已经表现得相当好。

接下来，我们将最佳的LRFC-Eud集成分类器LRFC-Eud-ENS(9)与代表性集成分类器进行比较。如表7所示，我们观察到LRFC-Eud-ENS(9) 在所有指标上优于所有基线集成模型。值得注意的是，LRFC-Eud-ENS(3)（86.48%准确率）已经优于InceptionTime（86.28%准确率），后者结合了五个不同配置的Inception模型，是文献中报告的最佳TSC分类器。如图16所示，我们观察到LRFC-Eud-ENS(9)显著优于TSF、PF、RISE和STC，进一步验证了其有效性。类似于非集成模型，我们在图17中通过小提琴图可视化了集成模型性能分布。如图所示，LRFC-Eud-ENS(9)具有最高的第三（上）四分位数，表明其在分类容易数据集上的优势。然而，LRFC-Eud-ENS(9)的第一（下）四分位数与HIVE-COTE、TS-CHIEF、InceptionTime和ROCKET相似，表明LRFC-Eud-ENS(9)在困难问题上并未明显优于基线。

而不是简单地集成不同参数初始化的LRFC模型，进一步改进集成模型的一个想法是将LRFC-Eud与其他分类器结合形成新的集成，这是未来的工作。

---

**表6：LRFC-Eud集成比较**

| 模型            | 排名  | 第一 | 前2  | 前3  | 准确率 |
| --------------- | ----- | ---- | ---- | ---- | ------ |
| LRFC-Eud-ENS(1) | 3.447 | 17   | 23   | 32   | 84.99  |
| LRFC-Eud-ENS(3) | 3.165 | 19   | 24   | 39   | 86.48  |
| LRFC-Eud-ENS(5) | 2.965 | 32   | 39   | 52   | 86.61  |
| LRFC-Eud-ENS(7) | 2.118 | 34   | 59   | 72   | 86.89  |
| LRFC-Eud-ENS(9) | 1.997 | 38   | 60   | 79   | 86.92  |

---

**表7：TSC集成分类器比较**

| 模型            | 第一 | 前2  | 前3  | 准确率 | 宏F1  |
| --------------- | ---- | ---- | ---- | ------ | ----- |
| TSF             | 0    | 0    | 2    | 78.98  | 73.99 |
| RISE            | 0    | 1    | 6    | 80.13  | 74.08 |
| PF              | 3    | 8    | 9    | 83.27  | 78.94 |
| STC             | 5    | 9    | 14   | 84.04  | 78.85 |
| HIVE-COTE       | 11   | 17   | 27   | 86.07  | 81.10 |
| TS-CHIEF        | 13   | 25   | 37   | 85.99  | 81.42 |
| InceptionTime   | 7    | 18   | 35   | 86.28  | 82.75 |
| ROCKET          | 11   | 21   | 40   | 86.19  | 81.80 |
| OS-CNN-ENS(8)   | 11   | 32   | 41   | 84.77  | 81.89 |
| LRFC-Eud-ENS(9) | 46   | 53   | 56   | 86.92  | 82.77 |

---

### 图表说明

- **图16**：集成分类器比较的关键差异图。
- **图17**：集成分类器的小提琴图。

---

### 5.10 Multi-Variate Time Series Classification

**多变量时间序列分类**

上述所有实验均在单变量时间序列上进行。然而，Rel-CNN可以自然应用于多变量TSC的通用情况。在本节中，我们在八个广泛使用的多变量时间序列数据集（包括Epilepsy、FaceDetection、PenDigits、Heartbeat、Cricket、Handwriting、RacketSports和LSST）上评估RFC、LRFC-Cos和LRFC-Eud与最先进的非集成TSC基线的性能。注意，所有数据集在评估前已规范化。更具体地，我们将Rel-CNN模型与1-NN DTW（多维）、WEASEL、ResNet、Inception和OS-CNN进行比较。

如表8所示，我们以平均准确率评估所有模型。我们进一步通过图18中的关键差异图显示比较，其中LRFC-Eud在平均排名方面优于所有基线，显著优于OS-CNN、1NN-DTW(MD)和WEASEL。

---

**表8：多变量时间序列数据集上的评估**

| 准确率 | 1NN-DTW | WEASEL | ResNet | OS-CNN | Inception | RFC   | LRFC-Cos | LRFC-Eud |
| ------ | ------- | ------ | ------ | ------ | --------- | ----- | -------- | -------- |
| CR     | 99.32   | 98.66  | 99.32  | 98.95  | 99.40     | 99.60 | 99.56    | 99.39    |
| EP     | 96.31   | 98.92  | 99.18  | 98.44  | 99.26     | 99.13 | 99.30    | 99.48    |
| FD     | 52.87   | 54.33  | 62.93  | 60.87  | 63.72     | 63.86 | 64.25    | 64.79    |
| HW     | 60.45   | 53.15  | 59.74  | 54.98  | 56.13     | 56.34 | 55.92    | 56.83    |
| HB     | 72.37   | 72.68  | 63.86  | 70.71  | 72.76     | 73.48 | 74.02    | 74.21    |
| LSST   | 54.75   | 62.81  |        |        |           |       |          |          |